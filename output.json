[
  {
    "title": "Retrieval-Guided Reinforcement Learning for Boolean Circuit Minimization",
    "authors": "Animesh Basak Chowdhury, Marco Romanelli, Benjamin Tan, Ramesh Karri, Siddharth Garg",
    "abstract": "  Logic synthesis, a pivotal stage in chip design, entails optimizing chip\nspecifications encoded in hardware description languages like Verilog into\nhighly efficient implementations using Boolean logic gates. The process\ninvolves a sequential application of logic minimization heuristics (``synthesis\nrecipe\"), with their arrangement significantly impacting crucial metrics such\nas area and delay. Addressing the challenge posed by the broad spectrum of\ndesign complexities - from variations of past designs (e.g., adders and\nmultipliers) to entirely novel configurations (e.g., innovative processor\ninstructions) - requires a nuanced `synthesis recipe` guided by human expertise\nand intuition. This study conducts a thorough examination of learning and\nsearch techniques for logic synthesis, unearthing a surprising revelation:\npre-trained agents, when confronted with entirely novel designs, may veer off\ncourse, detrimentally affecting the search trajectory. We present ABC-RL, a\nmeticulously tuned $\\alpha$ parameter that adeptly adjusts recommendations from\npre-trained agents during the search process. Computed based on similarity\nscores through nearest neighbor retrieval from the training dataset, ABC-RL\nyields superior synthesis recipes tailored for a wide array of hardware\ndesigns. Our findings showcase substantial enhancements in the\nQuality-of-result (QoR) of synthesized circuits, boasting improvements of up to\n24.8% compared to state-of-the-art techniques. Furthermore, ABC-RL achieves an\nimpressive up to 9x reduction in runtime (iso-QoR) when compared to current\nstate-of-the-art methodologies.\n",
    "link": "http://arxiv.org/abs/2401.12205v1"
  },
  {
    "title": "Unsupervised Machine Learning for the Classification of Astrophysical\n  X-ray Sources",
    "authors": "V\u00edctor Samuel P\u00e9rez-D\u00edaz, Juan Rafael Mart\u00ednez-Galarza, Alexander Caicedo, Raffaele D'Abrusco",
    "abstract": "  The automatic classification of X-ray detections is a necessary step in\nextracting astrophysical information from compiled catalogs of astrophysical\nsources. Classification is useful for the study of individual objects,\nstatistics for population studies, as well as for anomaly detection, i.e., the\nidentification of new unexplored phenomena, including transients and spectrally\nextreme sources. Despite the importance of this task, classification remains\nchallenging in X-ray astronomy due to the lack of optical counterparts and\nrepresentative training sets. We develop an alternative methodology that\nemploys an unsupervised machine learning approach to provide probabilistic\nclasses to Chandra Source Catalog sources with a limited number of labeled\nsources, and without ancillary information from optical and infrared catalogs.\nWe provide a catalog of probabilistic classes for 8,756 sources, comprising a\ntotal of 14,507 detections, and demonstrate the success of the method at\nidentifying emission from young stellar objects, as well as distinguishing\nbetween small-scale and large-scale compact accretors with a significant level\nof confidence. We investigate the consistency between the distribution of\nfeatures among classified objects and well-established astrophysical hypotheses\nsuch as the unified AGN model. This provides interpretability to the\nprobabilistic classifier. Code and tables are available publicly through\nGitHub. We provide a web playground for readers to explore our final\nclassification at https://umlcaxs-playground.streamlit.app.\n",
    "link": "http://arxiv.org/abs/2401.12203v1"
  },
  {
    "title": "OK-Robot: What Really Matters in Integrating Open-Knowledge Models for\n  Robotics",
    "authors": "Peiqi Liu, Yaswanth Orru, Chris Paxton, Nur Muhammad Mahi Shafiullah, Lerrel Pinto",
    "abstract": "  Remarkable progress has been made in recent years in the fields of vision,\nlanguage, and robotics. We now have vision models capable of recognizing\nobjects based on language queries, navigation systems that can effectively\ncontrol mobile systems, and grasping models that can handle a wide range of\nobjects. Despite these advancements, general-purpose applications of robotics\nstill lag behind, even though they rely on these fundamental capabilities of\nrecognition, navigation, and grasping. In this paper, we adopt a systems-first\napproach to develop a new Open Knowledge-based robotics framework called\nOK-Robot. By combining Vision-Language Models (VLMs) for object detection,\nnavigation primitives for movement, and grasping primitives for object\nmanipulation, OK-Robot offers a integrated solution for pick-and-drop\noperations without requiring any training. To evaluate its performance, we run\nOK-Robot in 10 real-world home environments. The results demonstrate that\nOK-Robot achieves a 58.5% success rate in open-ended pick-and-drop tasks,\nrepresenting a new state-of-the-art in Open Vocabulary Mobile Manipulation\n(OVMM) with nearly 1.8x the performance of prior work. On cleaner, uncluttered\nenvironments, OK-Robot's performance increases to 82%. However, the most\nimportant insight gained from OK-Robot is the critical role of nuanced details\nwhen combining Open Knowledge systems like VLMs with robotic modules. Videos of\nour experiments are available on our website: https://ok-robot.github.io\n",
    "link": "http://arxiv.org/abs/2401.12202v1"
  },
  {
    "title": "Text Embedding Inversion Attacks on Multilingual Language Models",
    "authors": "Yiyi Chen, Heather Lent, Johannes Bjerva",
    "abstract": "  Representing textual information as real-numbered embeddings has become the\nnorm in NLP. Moreover, with the rise of public interest in large language\nmodels (LLMs), Embeddings as a Service (EaaS) has rapidly gained traction as a\nbusiness model. This is not without outstanding security risks, as previous\nresearch has demonstrated that sensitive data can be reconstructed from\nembeddings, even without knowledge of the underlying model that generated them.\nHowever, such work is limited by its sole focus on English, leaving all other\nlanguages vulnerable to attacks by malicious actors. %As many international and\nmultilingual companies leverage EaaS, there is an urgent need for research into\nmultilingual LLM security. To this end, this work investigates LLM security\nfrom the perspective of multilingual embedding inversion. Concretely, we define\nthe problem of black-box multilingual and cross-lingual inversion attacks, with\nspecial attention to a cross-domain scenario. Our findings reveal that\nmultilingual models are potentially more vulnerable to inversion attacks than\ntheir monolingual counterparts. This stems from the reduced data requirements\nfor achieving comparable inversion performance in settings where the underlying\nlanguage is not known a-priori. To our knowledge, this work is the first to\ndelve into multilinguality within the context of inversion attacks, and our\nfindings highlight the need for further investigation and enhanced defenses in\nthe area of NLP Security.\n",
    "link": "http://arxiv.org/abs/2401.12192v1"
  },
  {
    "title": "WARM: On the Benefits of Weight Averaged Reward Models",
    "authors": "Alexandre Ram\u00e9, Nino Vieillard, L\u00e9onard Hussenot, Robert Dadashi, Geoffrey Cideron, Olivier Bachem, Johan Ferret",
    "abstract": "  Aligning large language models (LLMs) with human preferences through\nreinforcement learning (RLHF) can lead to reward hacking, where LLMs exploit\nfailures in the reward model (RM) to achieve seemingly high rewards without\nmeeting the underlying objectives. We identify two primary challenges when\ndesigning RMs to mitigate reward hacking: distribution shifts during the RL\nprocess and inconsistencies in human preferences. As a solution, we propose\nWeight Averaged Reward Models (WARM), first fine-tuning multiple RMs, then\naveraging them in the weight space. This strategy follows the observation that\nfine-tuned weights remain linearly mode connected when sharing the same\npre-training. By averaging weights, WARM improves efficiency compared to the\ntraditional ensembling of predictions, while improving reliability under\ndistribution shifts and robustness to preference inconsistencies. Our\nexperiments on summarization tasks, using best-of-N and RL methods, shows that\nWARM improves the overall quality and alignment of LLM predictions; for\nexample, a policy RL fine-tuned with WARM has a 79.4% win rate against a policy\nRL fine-tuned with a single RM.\n",
    "link": "http://arxiv.org/abs/2401.12187v1"
  },
  {
    "title": "Universal Neurons in GPT2 Language Models",
    "authors": "Wes Gurnee, Theo Horsley, Zifan Carl Guo, Tara Rezaei Kheirkhah, Qinyi Sun, Will Hathaway, Neel Nanda, Dimitris Bertsimas",
    "abstract": "  A basic question within the emerging field of mechanistic interpretability is\nthe degree to which neural networks learn the same underlying mechanisms. In\nother words, are neural mechanisms universal across different models? In this\nwork, we study the universality of individual neurons across GPT2 models\ntrained from different initial random seeds, motivated by the hypothesis that\nuniversal neurons are likely to be interpretable. In particular, we compute\npairwise correlations of neuron activations over 100 million tokens for every\nneuron pair across five different seeds and find that 1-5\\% of neurons are\nuniversal, that is, pairs of neurons which consistently activate on the same\ninputs. We then study these universal neurons in detail, finding that they\nusually have clear interpretations and taxonomize them into a small number of\nneuron families. We conclude by studying patterns in neuron weights to\nestablish several universal functional roles of neurons in simple circuits:\ndeactivating attention heads, changing the entropy of the next token\ndistribution, and predicting the next token to (not) be within a particular\nset.\n",
    "link": "http://arxiv.org/abs/2401.12181v1"
  },
  {
    "title": "DITTO: Diffusion Inference-Time T-Optimization for Music Generation",
    "authors": "Zachary Novack, Julian McAuley, Taylor Berg-Kirkpatrick, Nicholas J. Bryan",
    "abstract": "  We propose Diffusion Inference-Time T-Optimization (DITTO), a general-purpose\nframe-work for controlling pre-trained text-to-music diffusion models at\ninference-time via optimizing initial noise latents. Our method can be used to\noptimize through any differentiable feature matching loss to achieve a target\n(stylized) output and leverages gradient checkpointing for memory efficiency.\nWe demonstrate a surprisingly wide-range of applications for music generation\nincluding inpainting, outpainting, and looping as well as intensity, melody,\nand musical structure control - all without ever fine-tuning the underlying\nmodel. When we compare our approach against related training, guidance, and\noptimization-based methods, we find DITTO achieves state-of-the-art performance\non nearly all tasks, including outperforming comparable approaches on\ncontrollability, audio quality, and computational efficiency, thus opening the\ndoor for high-quality, flexible, training-free control of diffusion models.\nSound examples can be found at https://DITTO-Music.github.io/web/.\n",
    "link": "http://arxiv.org/abs/2401.12179v1"
  },
  {
    "title": "In-Context Learning for Extreme Multi-Label Classification",
    "authors": "Karel D'Oosterlinck, Omar Khattab, Fran\u00e7ois Remy, Thomas Demeester, Chris Develder, Christopher Potts",
    "abstract": "  Multi-label classification problems with thousands of classes are hard to\nsolve with in-context learning alone, as language models (LMs) might lack prior\nknowledge about the precise classes or how to assign them, and it is generally\ninfeasible to demonstrate every class in a prompt. We propose a general\nprogram, $\\texttt{Infer--Retrieve--Rank}$, that defines multi-step interactions\nbetween LMs and retrievers to efficiently tackle such problems. We implement\nthis program using the $\\texttt{DSPy}$ programming model, which specifies\nin-context systems in a declarative manner, and use $\\texttt{DSPy}$ optimizers\nto tune it towards specific datasets by bootstrapping only tens of few-shot\nexamples. Our primary extreme classification program, optimized separately for\neach task, attains state-of-the-art results across three benchmarks (HOUSE,\nTECH, TECHWOLF). We apply the same program to a benchmark with vastly different\ncharacteristics and attain competitive performance as well (BioDEX). Unlike\nprior work, our proposed solution requires no finetuning, is easily applicable\nto new tasks, alleviates prompt engineering, and requires only tens of labeled\nexamples. Our code is public at https://github.com/KarelDO/xmc.dspy.\n",
    "link": "http://arxiv.org/abs/2401.12178v1"
  },
  {
    "title": "Broiler-Net: A Deep Convolutional Framework for Broiler Behavior\n  Analysis in Poultry Houses",
    "authors": "Tahereh Zarrat Ehsan, Seyed Mehdi Mohtavipour",
    "abstract": "  Detecting anomalies in poultry houses is crucial for maintaining optimal\nchicken health conditions, minimizing economic losses and bolstering\nprofitability. This paper presents a novel real-time framework for analyzing\nchicken behavior in cage-free poultry houses to detect abnormal behaviors.\nSpecifically, two significant abnormalities, namely inactive broiler and\nhuddling behavior, are investigated in this study. The proposed framework\ncomprises three key steps: (1) chicken detection utilizing a state-of-the-art\ndeep learning model, (2) tracking individual chickens across consecutive frames\nwith a fast tracker module, and (3) detecting abnormal behaviors within the\nvideo stream. Experimental studies are conducted to evaluate the efficacy of\nthe proposed algorithm in accurately assessing chicken behavior. The results\nillustrate that our framework provides a precise and efficient solution for\nreal-time anomaly detection, facilitating timely interventions to maintain\nchicken health and enhance overall productivity on poultry farms. Github:\nhttps://github.com/TaherehZarratEhsan/Chicken-Behavior-Analysis\n",
    "link": "http://arxiv.org/abs/2401.12176v1"
  },
  {
    "title": "Natural Strategic Ability in Stochastic Multi-Agent Systems",
    "authors": "Rapha\u00ebl Berthon, Joost-Pieter Katoen, Munyque Mittelmann, Aniello Murano",
    "abstract": "  Strategies synthesized using formal methods can be complex and often require\ninfinite memory, which does not correspond to the expected behavior when trying\nto model Multi-Agent Systems (MAS). To capture such behaviors, natural\nstrategies are a recently proposed framework striking a balance between the\nability of agents to strategize with memory and the model-checking complexity,\nbut until now has been restricted to fully deterministic settings. For the\nfirst time, we consider the probabilistic temporal logics PATL and PATL* under\nnatural strategies (NatPATL and NatPATL*, resp.). As main result we show that,\nin stochastic MAS, NatPATL model-checking is NP-complete when the active\ncoalition is restricted to deterministic strategies. We also give a 2NEXPTIME\ncomplexity result for NatPATL* with the same restriction. In the unrestricted\ncase, we give an EXPSPACE complexity for NatPATL and 3EXPSPACE complexity for\nNatPATL*.\n",
    "link": "http://arxiv.org/abs/2401.12170v1"
  },
  {
    "title": "Semi-supervised segmentation of land cover images using nonlinear\n  canonical correlation analysis with multiple features and t-SNE",
    "authors": "Hong Wei, James Xiao, Yichao Zhang, Xia Hong",
    "abstract": "  Image segmentation is a clustering task whereby each pixel is assigned a\ncluster label. Remote sensing data usually consists of multiple bands of\nspectral images in which there exist semantically meaningful land cover\nsubregions, co-registered with other source data such as LIDAR (LIght Detection\nAnd Ranging) data, where available. This suggests that, in order to account for\nspatial correlation between pixels, a feature vector associated with each pixel\nmay be a vectorized tensor representing the multiple bands and a local patch as\nappropriate. Similarly, multiple types of texture features based on a pixel's\nlocal patch would also be beneficial for encoding locally statistical\ninformation and spatial variations, without necessarily labelling pixel-wise a\nlarge amount of ground truth, then training a supervised model, which is\nsometimes impractical. In this work, by resorting to label only a small\nquantity of pixels, a new semi-supervised segmentation approach is proposed.\nInitially, over all pixels, an image data matrix is created in high dimensional\nfeature space. Then, t-SNE projects the high dimensional data onto 3D\nembedding. By using radial basis functions as input features, which use the\nlabelled data samples as centres, to pair with the output class labels, a\nmodified canonical correlation analysis algorithm, referred to as RBF-CCA, is\nintroduced which learns the associated projection matrix via the small labelled\ndata set. The associated canonical variables, obtained for the full image, are\napplied by k-means clustering algorithm. The proposed semi-supervised RBF-CCA\nalgorithm has been implemented on several remotely sensed multispectral images,\ndemonstrating excellent segmentation results.\n",
    "link": "http://arxiv.org/abs/2401.12164v1"
  },
  {
    "title": "Evaluation of QCNN-LSTM for Disability Forecasting in Multiple Sclerosis\n  Using Sequential Multisequence MRI",
    "authors": "John D. Mayfield, Issam El Naqa",
    "abstract": "  Introduction Quantum Convolutional Neural Network (QCNN)-Long Short-Term\nMemory (LSTM) models were studied to provide sequential relationships for each\ntimepoint in MRIs of patients with Multiple Sclerosis (MS). In this pilot\nstudy, we compared three QCNN-LSTM models for binary classification of MS\ndisability benchmarked against classical neural network architectures. Our\nhypothesis is that quantum models will provide competitive performance. Methods\nMatrix Product State (MPS), reverse Multistate Entanglement Renormalization\nAnsatz (MERA), and Tree-Tensor Network (TTN) circuits were paired with LSTM\nlayer to process near-annual MRI data of patients diagnosed with MS. These were\nbenchmarked against a Visual Geometry Group (VGG)-LSTM and a Video Vision\nTransformer (ViViT). Predicted logits were measured against ground truth labels\nof each patient's Extended Disability Severity Score (EDSS) using binary\ncross-entropy loss. Training/validation/holdout testing was partitioned using\n5-fold cross validation with a total split of 60:20:20. Levene's test of\nvariance was used to measure statistical difference and Student's t-test for\npaired model differences in mean. Results The MPS-LSTM, reverse MERA-LSTM, and\nTTN-LSTM had holdout testing ROC-AUC of 0.70, 0.77, and 0.81, respectively\n(p-value 0.915). VGG16-LSTM and ViViT performed similarly with ROC-AUC of 0.73\nand 0.77, respectively (p-value 0.631). Overall variance and mean were not\nstatistically significant (p-value 0.713), however, time to train was\nsignificantly faster for the QCNN-LSTMs (39.4 sec per fold vs. 224 and 218,\nrespectively, p-value &lt;0.001). Conclusion QCNN-LSTM models perform\ncompetitively to their classical counterparts with greater efficiency in train\ntime. Clinically, these can add value in terms of efficiency to time-dependent\ndeep learning prediction of disease progression based upon medical imaging.\n",
    "link": "http://arxiv.org/abs/2401.12132v1"
  },
  {
    "title": "Extracting Formulae in Many-Valued Logic from Deep Neural Networks",
    "authors": "Yani Zhang, Helmut B\u00f6lcskei",
    "abstract": "  We propose a new perspective on deep ReLU networks, namely as circuit\ncounterparts of Lukasiewicz infinite-valued logic -- a many-valued (MV)\ngeneralization of Boolean logic. An algorithm for extracting formulae in MV\nlogic from deep ReLU networks is presented. As the algorithm applies to\nnetworks with general, in particular also real-valued, weights, it can be used\nto extract logical formulae from deep ReLU networks trained on data.\n",
    "link": "http://arxiv.org/abs/2401.12113v1"
  },
  {
    "title": "On-Time Delivery in Crowdshipping Systems: An Agent-Based Approach Using\n  Streaming Data",
    "authors": "Jeremias D\u00f6tterl, Ralf Bruns, J\u00fcrgen Dunkel, Sascha Ossowski",
    "abstract": "  In parcel delivery, the \"last mile\" from the parcel hub to the customer is\ncostly, especially for time-sensitive delivery tasks that have to be completed\nwithin hours after arrival. Recently, crowdshipping has attracted increased\nattention as a new alternative to traditional delivery modes. In crowdshipping,\nprivate citizens (\"the crowd\") perform short detours in their daily lives to\ncontribute to parcel delivery in exchange for small incentives. However,\nachieving desirable crowd behavior is challenging as the crowd is highly\ndynamic and consists of autonomous, self-interested individuals. Leveraging\ncrowdshipping for time-sensitive deliveries remains an open challenge. In this\npaper, we present an agent-based approach to on-time parcel delivery with\ncrowds. Our system performs data stream processing on the couriers' smartphone\nsensor data to predict delivery delays. Whenever a delay is predicted, the\nsystem attempts to forge an agreement for transferring the parcel from the\ncurrent deliverer to a more promising courier nearby. Our experiments show that\nthrough accurate delay predictions and purposeful task transfers many delays\ncan be prevented that would occur without our approach.\n",
    "link": "http://arxiv.org/abs/2401.12108v1"
  },
  {
    "title": "West-of-N: Synthetic Preference Generation for Improved Reward Modeling",
    "authors": "Aliz\u00e9e Pace, Jonathan Mallinson, Eric Malmi, Sebastian Krause, Aliaksei Severyn",
    "abstract": "  The success of reinforcement learning from human feedback (RLHF) in language\nmodel alignment is strongly dependent on the quality of the underlying reward\nmodel. In this paper, we present a novel approach to improve reward model\nquality by generating synthetic preference data, thereby augmenting the\ntraining dataset with on-policy, high-quality preference pairs. Motivated by\nthe promising results of Best-of-N sampling strategies in language model\ntraining, we extend their application to reward model training. This results in\na self-training strategy to generate preference pairs by selecting the best and\nworst candidates in a pool of responses to a given query. Empirically, we find\nthat this approach improves the performance of any reward model, with an effect\ncomparable to the addition of a similar quantity of human preference data. This\nwork opens up new avenues of research for improving RLHF for language model\nalignment, by offering synthetic preference generation as a solution to reward\nmodeling challenges.\n",
    "link": "http://arxiv.org/abs/2401.12086v1"
  },
  {
    "title": "Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated\n  Text",
    "authors": "Abhimanyu Hans, Avi Schwarzschild, Valeriia Cherepanova, Hamid Kazemi, Aniruddha Saha, Micah Goldblum, Jonas Geiping, Tom Goldstein",
    "abstract": "  Detecting text generated by modern large language models is thought to be\nhard, as both LLMs and humans can exhibit a wide range of complex behaviors.\nHowever, we find that a score based on contrasting two closely related language\nmodels is highly accurate at separating human-generated and machine-generated\ntext. Based on this mechanism, we propose a novel LLM detector that only\nrequires simple calculations using a pair of pre-trained LLMs. The method,\ncalled Binoculars, achieves state-of-the-art accuracy without any training\ndata. It is capable of spotting machine text from a range of modern LLMs\nwithout any model-specific modifications. We comprehensively evaluate\nBinoculars on a number of text sources and in varied situations. Over a wide\nrange of document types, Binoculars detects over 90% of generated samples from\nChatGPT (and other LLMs) at a false positive rate of 0.01%, despite not being\ntrained on any ChatGPT data.\n",
    "link": "http://arxiv.org/abs/2401.12070v1"
  },
  {
    "title": "CloSe: A 3D Clothing Segmentation Dataset and Model",
    "authors": "Dimitrije Anti\u0107, Garvita Tiwari, Batuhan Ozcomlekci, Riccardo Marin, Gerard Pons-Moll",
    "abstract": "  3D Clothing modeling and datasets play crucial role in the entertainment,\nanimation, and digital fashion industries. Existing work often lacks detailed\nsemantic understanding or uses synthetic datasets, lacking realism and\npersonalization. To address this, we first introduce CloSe-D: a novel\nlarge-scale dataset containing 3D clothing segmentation of 3167 scans, covering\na range of 18 distinct clothing classes. Additionally, we propose CloSe-Net,\nthe first learning-based 3D clothing segmentation model for fine-grained\nsegmentation from colored point clouds. CloSe-Net uses local point features,\nbody-clothing correlation, and a garment-class and point features-based\nattention module, improving performance over baselines and prior work. The\nproposed attention module enables our model to learn appearance and\ngeometry-dependent clothing prior from data. We further validate the efficacy\nof our approach by successfully segmenting publicly available datasets of\npeople in clothing. We also introduce CloSe-T, a 3D interactive tool for\nrefining segmentation labels. Combining the tool with CloSe-T in a continual\nlearning setup demonstrates improved generalization on real-world data.\nDataset, model, and tool can be found at\nhttps://virtualhumans.mpi-inf.mpg.de/close3dv24/.\n",
    "link": "http://arxiv.org/abs/2401.12051v1"
  },
  {
    "title": "MINT: A wrapper to make multi-modal and multi-image AI models\n  interactive",
    "authors": "Jan Freyberg, Abhijit Guha Roy, Terry Spitz, Beverly Freeman, Mike Schaekermann, Patricia Strachan, Eva Schnider, Renee Wong, Dale R Webster, Alan Karthikesalingam, Yun Liu, Krishnamurthy Dvijotham, Umesh Telang",
    "abstract": "  During the diagnostic process, doctors incorporate multimodal information\nincluding imaging and the medical history - and similarly medical AI\ndevelopment has increasingly become multimodal. In this paper we tackle a more\nsubtle challenge: doctors take a targeted medical history to obtain only the\nmost pertinent pieces of information; how do we enable AI to do the same? We\ndevelop a wrapper method named MINT (Make your model INTeractive) that\nautomatically determines what pieces of information are most valuable at each\nstep, and ask for only the most useful information. We demonstrate the efficacy\nof MINT wrapping a skin disease prediction model, where multiple images and a\nset of optional answers to $25$ standard metadata questions (i.e., structured\nmedical history) are used by a multi-modal deep network to provide a\ndifferential diagnosis. We show that MINT can identify whether metadata inputs\nare needed and if so, which question to ask next. We also demonstrate that when\ncollecting multiple images, MINT can identify if an additional image would be\nbeneficial, and if so, which type of image to capture. We showed that MINT\nreduces the number of metadata and image inputs needed by 82% and 36.2%\nrespectively, while maintaining predictive performance. Using real-world AI\ndermatology system data, we show that needing fewer inputs can retain users\nthat may otherwise fail to complete the system submission and drop off without\na diagnosis. Qualitative examples show MINT can closely mimic the step-by-step\ndecision making process of a clinical workflow and how this is different for\nstraight forward cases versus more difficult, ambiguous cases. Finally we\ndemonstrate how MINT is robust to different underlying multi-model classifiers\nand can be easily adapted to user requirements without significant model\nre-training.\n",
    "link": "http://arxiv.org/abs/2401.12032v1"
  },
  {
    "title": "Multimodal Visual-Tactile Representation Learning through\n  Self-Supervised Contrastive Pre-Training",
    "authors": "Vedant Dave, Fotios Lygerakis, Elmar Rueckert",
    "abstract": "  The rapidly evolving field of robotics necessitates methods that can\nfacilitate the fusion of multiple modalities. Specifically, when it comes to\ninteracting with tangible objects, effectively combining visual and tactile\nsensory data is key to understanding and navigating the complex dynamics of the\nphysical world, enabling a more nuanced and adaptable response to changing\nenvironments. Nevertheless, much of the earlier work in merging these two\nsensory modalities has relied on supervised methods utilizing datasets labeled\nby humans.This paper introduces MViTac, a novel methodology that leverages\ncontrastive learning to integrate vision and touch sensations in a\nself-supervised fashion. By availing both sensory inputs, MViTac leverages\nintra and inter-modality losses for learning representations, resulting in\nenhanced material property classification and more adept grasping prediction.\nThrough a series of experiments, we showcase the effectiveness of our method\nand its superiority over existing state-of-the-art self-supervised and\nsupervised techniques. In evaluating our methodology, we focus on two distinct\ntasks: material classification and grasping success prediction. Our results\nindicate that MViTac facilitates the development of improved modality encoders,\nyielding more robust representations as evidenced by linear probing\nassessments.\n",
    "link": "http://arxiv.org/abs/2401.12024v1"
  },
  {
    "title": "Robustness to distribution shifts of compressed networks for edge\n  devices",
    "authors": "Lulan Shen, Ali Edalati, Brett Meyer, Warren Gross, James J. Clark",
    "abstract": "  It is necessary to develop efficient DNNs deployed on edge devices with\nlimited computation resources. However, the compressed networks often execute\nnew tasks in the target domain, which is different from the source domain where\nthe original network is trained. It is important to investigate the robustness\nof compressed networks in two types of data distribution shifts: domain shifts\nand adversarial perturbations. In this study, we discover that compressed\nmodels are less robust to distribution shifts than their original networks.\nInterestingly, larger networks are more vulnerable to losing robustness than\nsmaller ones, even when they are compressed to a similar size as the smaller\nnetworks. Furthermore, compact networks obtained by knowledge distillation are\nmuch more robust to distribution shifts than pruned networks. Finally,\npost-training quantization is a reliable method for achieving significant\nrobustness to distribution shifts, and it outperforms both pruned and distilled\nmodels in terms of robustness.\n",
    "link": "http://arxiv.org/abs/2401.12014v1"
  },
  {
    "title": "Tensor-view Topological Graph Neural Network",
    "authors": "Tao Wen, Elynn Chen, Yuzhou Chen",
    "abstract": "  Graph classification is an important learning task for graph-structured data.\nGraph neural networks (GNNs) have recently gained growing attention in graph\nlearning and have shown significant improvements in many important graph\nproblems. Despite their state-of-the-art performances, existing GNNs only use\nlocal information from a very limited neighborhood around each node, suffering\nfrom loss of multi-modal information and overheads of excessive computation. To\naddress these issues, we propose a novel Tensor-view Topological Graph Neural\nNetwork (TTG-NN), a class of simple yet effective topological deep learning\nbuilt upon persistent homology, graph convolution, and tensor operations. This\nnew method incorporates tensor learning to simultaneously capture Tensor-view\nTopological (TT), as well as Tensor-view Graph (TG) structural information on\nboth local and global levels. Computationally, to fully exploit graph topology\nand structure, we propose two flexible TT and TG representation learning\nmodules that disentangle feature tensor aggregation and transformation and\nlearn to preserve multi-modal structure with less computation. Theoretically,\nwe derive high probability bounds on both the out-of-sample and in-sample mean\nsquared approximation errors for our proposed Tensor Transformation Layer\n(TTL). Real data experiments show that the proposed TTG-NN outperforms 20\nstate-of-the-art methods on various graph benchmarks.\n",
    "link": "http://arxiv.org/abs/2401.12007v1"
  },
  {
    "title": "Bridging Evolutionary Algorithms and Reinforcement Learning: A\n  Comprehensive Survey",
    "authors": "Pengyi Li, Jianye Hao, Hongyao Tang, Xian Fu, Yan Zheng, Ke Tang",
    "abstract": "  Evolutionary Reinforcement Learning (ERL), which integrates Evolutionary\nAlgorithms (EAs) and Reinforcement Learning (RL) for optimization, has\ndemonstrated remarkable performance advancements. By fusing the strengths of\nboth approaches, ERL has emerged as a promising research direction. This survey\noffers a comprehensive overview of the diverse research branches in ERL.\nSpecifically, we systematically summarize recent advancements in relevant\nalgorithms and identify three primary research directions: EA-assisted\noptimization of RL, RL-assisted optimization of EA, and synergistic\noptimization of EA and RL. Following that, we conduct an in-depth analysis of\neach research direction, organizing multiple research branches. We elucidate\nthe problems that each branch aims to tackle and how the integration of EA and\nRL addresses these challenges. In conclusion, we discuss potential challenges\nand prospective future research directions across various research directions.\n",
    "link": "http://arxiv.org/abs/2401.11963v1"
  },
  {
    "title": "CMMMU: A Chinese Massive Multi-discipline Multimodal Understanding\n  Benchmark",
    "authors": "Ge Zhang, Xinrun Du, Bei Chen, Yiming Liang, Tongxu Luo, Tianyu Zheng, Kang Zhu, Yuyang Cheng, Chunpu Xu, Shuyue Guo, Haoran Zhang, Xingwei Qu, Junjie Wang, Ruibin Yuan, Yizhi Li, Zekun Wang, Yudong Liu, Yu-Hsuan Tsai, Fengji Zhang, Chenghua Lin, Wenhao Huang, Wenhu Chen, Jie Fu",
    "abstract": "  As the capabilities of large multimodal models (LMMs) continue to advance,\nevaluating the performance of LMMs emerges as an increasing need. Additionally,\nthere is an even larger gap in evaluating the advanced knowledge and reasoning\nabilities of LMMs in non-English contexts such as Chinese. We introduce CMMMU,\na new Chinese Massive Multi-discipline Multimodal Understanding benchmark\ndesigned to evaluate LMMs on tasks demanding college-level subject knowledge\nand deliberate reasoning in a Chinese context. CMMMU is inspired by and\nstrictly follows the annotation and analysis pattern of MMMU.\n  CMMMU includes 12k manually collected multimodal questions from college\nexams, quizzes, and textbooks, covering six core disciplines: Art &amp; Design,\nBusiness, Science, Health &amp; Medicine, Humanities &amp; Social Science, and Tech &amp;\nEngineering, like its companion, MMMU. These questions span 30 subjects and\ncomprise 39 highly heterogeneous image types, such as charts, diagrams, maps,\ntables, music sheets, and chemical structures.\n  CMMMU focuses on complex perception and reasoning with domain-specific\nknowledge in the Chinese context. We evaluate 11 open-source LLMs and one\nproprietary GPT-4V(ision). Even GPT-4V only achieves accuracies of 42%,\nindicating a large space for improvement. CMMMU will boost the community to\nbuild the next-generation LMMs towards expert artificial intelligence and\npromote the democratization of LMMs by providing diverse language contexts.\n",
    "link": "http://arxiv.org/abs/2401.11944v1"
  },
  {
    "title": "Large receptive field strategy and important feature extraction strategy\n  in 3D object detection",
    "authors": "Leichao Cui, Xiuxian Li, Min Meng",
    "abstract": "  The enhancement of 3D object detection is pivotal for precise environmental\nperception and improved task execution capabilities in autonomous driving.\nLiDAR point clouds, offering accurate depth information, serve as a crucial\ninformation for this purpose. Our study focuses on key challenges in 3D target\ndetection. To tackle the challenge of expanding the receptive field of a 3D\nconvolutional kernel, we introduce the Dynamic Feature Fusion Module (DFFM).\nThis module achieves adaptive expansion of the 3D convolutional kernel's\nreceptive field, balancing the expansion with acceptable computational loads.\nThis innovation reduces operations, expands the receptive field, and allows the\nmodel to dynamically adjust to different object requirements. Simultaneously,\nwe identify redundant information in 3D features. Employing the Feature\nSelection Module (FSM) quantitatively evaluates and eliminates non-important\nfeatures, achieving the separation of output box fitting and feature\nextraction. This innovation enables the detector to focus on critical features,\nresulting in model compression, reduced computational burden, and minimized\ncandidate frame interference. Extensive experiments confirm that both DFFM and\nFSM not only enhance current benchmarks, particularly in small target\ndetection, but also accelerate network performance. Importantly, these modules\nexhibit effective complementarity.\n",
    "link": "http://arxiv.org/abs/2401.11913v1"
  },
  {
    "title": "Blinded by Generated Contexts: How Language Models Merge Generated and\n  Retrieved Contexts for Open-Domain QA?",
    "authors": "Hexiang Tan, Fei Sun, Wanli Yang, Yuanzhuo Wang, Qi Cao, Xueqi Cheng",
    "abstract": "  While auxiliary information has become a key to enhance Large Language Models\n(LLMs), relatively little is known about how well LLMs merge these contexts,\nspecifically generated and retrieved. To study this, we formulate a task\nspecifically designed to identify whether the answers, derived from the\nintegration of generated and retrieved contexts, are attributed to either\ngenerated or retrieved contexts. To support this task, we develop a methodology\nto construct datasets with conflicting contexts, where each question is paired\nwith both generated and retrieved contexts, yet only one of them contains the\ncorrect answer. Our experiments reveal a significant bias in LLMs towards\ngenerated contexts, as evidenced across state-of-the-art open (Llama2-7b/13b)\nand closed (GPT 3.5/4) systems. We further identify two key factors\ncontributing to this bias: i) Contexts generated by LLMs typically show greater\nsimilarity to the questions, increasing their likelihood of selection; ii) The\nsegmentation process used in retrieved contexts disrupts their completeness,\nthereby hindering their full utilization in LLMs. Our analysis enhances the\nunderstanding of how LLMs merge diverse contexts, offering valuable insights\nfor advancing current augmentation methods for LLMs.\n",
    "link": "http://arxiv.org/abs/2401.11911v1"
  },
  {
    "title": "Solving with GeoGebra Discovery an Austrian Mathematics Olympiad\n  problem: Lessons Learned",
    "authors": "Bel\u00e9n Ari\u00f1o-Morera, Zolt\u00e1n Kov\u00e1cs, Tom\u00e1s Recio, Piedad Tolmos",
    "abstract": "  We address, through the automated reasoning tools in GeoGebra Discovery, a\nproblem from a regional phase of the Austrian Mathematics Olympiad 2023. Trying\nto solve this problem gives rise to four different kind of feedback: the almost\ninstantaneous, automated solution of the proposed problem; the measure of its\ncomplexity, according to some recent proposals; the automated discovery of a\ngeneralization of the given assertion, showing that the same statement is true\nover more general polygons than those mentioned in the problem; and the\ndifficulties associated to the analysis of the surprising and involved high\nnumber of degenerate cases that appear when using the LocusEquation command in\nthis problem. In our communication we will describe and reflect on these\ndiverse issues, enhancing its exemplar role for showing some of the advantages,\nproblems, and current fields of development of GeoGebra Discovery.\n",
    "link": "http://arxiv.org/abs/2401.11906v1"
  },
  {
    "title": "Considerations on Approaches and Metrics in Automated Theorem\n  Generation/Finding in Geometry",
    "authors": "Pedro Quaresma, Pierluigi Graziani, Stefano M. Nicoletti",
    "abstract": "  The pursue of what are properties that can be identified to permit an\nautomated reasoning program to generate and find new and interesting theorems\nis an interesting research goal (pun intended). The automatic discovery of new\ntheorems is a goal in itself, and it has been addressed in specific areas, with\ndifferent methods. The separation of the \"weeds\", uninteresting, trivial facts,\nfrom the \"wheat\", new and interesting facts, is much harder, but is also being\naddressed by different authors using different approaches. In this paper we\nwill focus on geometry. We present and discuss different approaches for the\nautomatic discovery of geometric theorems (and properties), and different\nmetrics to find the interesting theorems among all those that were generated.\nAfter this description we will introduce the first result of this article: an\nundecidability result proving that having an algorithmic procedure that decides\nfor every possible Turing Machine that produces theorems, whether it is able to\nproduce also interesting theorems, is an undecidable problem. Consequently, we\nwill argue that judging whether a theorem prover is able to produce interesting\ntheorems remains a non deterministic task, at best a task to be addressed by\nprogram based in an algorithm guided by heuristics criteria. Therefore, as a\nhuman, to satisfy this task two things are necessary: an expert survey that\nsheds light on what a theorem prover/finder of interesting geometric theorems\nis, and - to enable this analysis - other surveys that clarify metrics and\napproaches related to the interestingness of geometric theorems. In the\nconclusion of this article we will introduce the structure of two of these\nsurveys - the second result of this article - and we will discuss some future\nwork.\n",
    "link": "http://arxiv.org/abs/2401.11905v1"
  },
  {
    "title": "Automation of Triangle Ruler-and-Compass Constructions Using Constraint\n  Solvers",
    "authors": "Milan Bankovi\u0107",
    "abstract": "  In this paper, we present an approach to automated solving of triangle\nruler-and-compass construction problems using finite-domain constraint solvers.\nThe constraint model is described in the MiniZinc modeling language, and is\nbased on the automated planning. The main benefit of using general constraint\nsolvers for such purpose, instead of developing dedicated tools, is that we can\nrely on the efficient search that is already implemented within the solver,\nenabling us to focus on geometric aspects of the problem. We may also use the\nsolver's built-in optimization capabilities to search for the shortest possible\nconstructions. We evaluate our approach on 74 solvable problems from the\nWernick's list, and compare it to the dedicated triangle construction solver\nArgoTriCS. The results show that our approach is comparable to dedicated tools,\nwhile it requires much less effort to implement. Also, our model often finds\nshorter constructions, thanks to the optimization capabilities offered by the\nconstraint solvers.\n",
    "link": "http://arxiv.org/abs/2401.11903v1"
  },
  {
    "title": "Showing Proofs, Assessing Difficulty with GeoGebra Discovery",
    "authors": "Zolt\u00e1n Kov\u00e1cs, Tom\u00e1s Recio, M. Pilar V\u00e9lez",
    "abstract": "  In our contribution we describe some on-going improvements concerning the\nAutomated Reasoning Tools developed in GeoGebra Discovery, providing different\nexamples of the performance of these new features. We describe the new\nShowProof command, that outputs both the sequence of the different steps\nperformed by GeoGebra Discovery to confirm a certain statement, as well as a\nnumber intending to grade the difficulty or interest of the assertion. The\nproposal of this assessment measure, involving the comparison of the expression\nof the thesis (or conclusion) as a combination of the hypotheses, will be\ndeveloped.\n",
    "link": "http://arxiv.org/abs/2401.11900v1"
  },
  {
    "title": "Automated Completion of Statements and Proofs in Synthetic Geometry: an\n  Approach based on Constraint Solving",
    "authors": "Salwa Tabet Gonzalez, Predrag Jani\u010di\u0107, Julien Narboux",
    "abstract": "  Conjecturing and theorem proving are activities at the center of mathematical\npractice and are difficult to separate. In this paper, we propose a framework\nfor completing incomplete conjectures and incomplete proofs. The framework can\nturn a conjecture with missing assumptions and with an under-specified goal\ninto a proper theorem. Also, the proposed framework can help in completing a\nproof sketch into a human-readable and machine-checkable proof. Our approach is\nfocused on synthetic geometry, and uses coherent logic and constraint solving.\nThe proposed approach is uniform for all three kinds of tasks, flexible and, to\nour knowledge, unique such approach.\n",
    "link": "http://arxiv.org/abs/2401.11898v1"
  },
  {
    "title": "PsySafe: A Comprehensive Framework for Psychological-based Attack,\n  Defense, and Evaluation of Multi-agent System Safety",
    "authors": "Zaibin Zhang, Yongting Zhang, Lijun Li, Hongzhi Gao, Lijun Wang, Huchuan Lu, Feng Zhao, Yu Qiao, Jing Shao",
    "abstract": "  Multi-agent systems, augmented with Large Language Models (LLMs), demonstrate\nsignificant capabilities for collective intelligence. However, the potential\nmisuse of this intelligence for malicious purposes presents significant risks.\nTo date, comprehensive research on the safety issues associated with\nmulti-agent systems remains limited. From the perspective of agent psychology,\nwe discover that the dark psychological states of agents can lead to severe\nsafety issues. To address these issues, we propose a comprehensive framework\ngrounded in agent psychology. In our framework, we focus on three aspects:\nidentifying how dark personality traits in agents might lead to risky\nbehaviors, designing defense strategies to mitigate these risks, and evaluating\nthe safety of multi-agent systems from both psychological and behavioral\nperspectives. Our experiments reveal several intriguing phenomena, such as the\ncollective dangerous behaviors among agents, agents' propensity for\nself-reflection when engaging in dangerous behavior, and the correlation\nbetween agents' psychological assessments and their dangerous behaviors. We\nanticipate that our framework and observations will provide valuable insights\nfor further research into the safety of multi-agent systems. We will make our\ndata and code publicly accessible at https:/github.com/AI4Good24/PsySafe.\n",
    "link": "http://arxiv.org/abs/2401.11880v1"
  },
  {
    "title": "Toward Semantic Interoperability of Electronic Health Records",
    "authors": "Idoia Berges, Jes\u00fas Berm\u00fadez, Arantza Illarramendi",
    "abstract": "  Although the goal of achieving semantic interoperability of electronic health\nrecords (EHRs) is pursued by many researchers, it has not been accomplished\nyet. In this paper, we present a proposal that smoothes out the way toward the\nachievement of that goal. In particular, our study focuses on medical diagnoses\nstatements. In summary, the main contributions of our ontology-based proposal\nare the following: first, it includes a canonical ontology whose EHR-related\nterms focus on semantic aspects. As a result, their descriptions are\nindependent of languages and technology aspects used in different organizations\nto represent EHRs. Moreover, those terms are related to their corresponding\ncodes in well-known medical terminologies. Second, it deals with modules that\nallow obtaining rich ontological representations of EHR information managed by\nproprietary models of health information systems. The features of one specific\nmodule are shown as reference. Third, it considers the necessary mapping axioms\nbetween ontological terms enhanced with so-called path mappings. This feature\nsmoothes out structural differences between heterogeneous EHR representations,\nallowing proper alignment of information.\n",
    "link": "http://arxiv.org/abs/2401.11865v1"
  },
  {
    "title": "Improving Small Language Models' Mathematical Reasoning via Mix Thoughts\n  Distillation",
    "authors": "Xunyu Zhu, Jian Li, Yong Liu, Can Ma, Weiping Wang",
    "abstract": "  This work addresses the challenge of democratizing advanced Large Language\nModels (LLMs) by compressing their mathematical reasoning capabilities into\nsub-billion parameter Small Language Models (SLMs) without compromising\nperformance. We introduce Equation-of-Thought Distillation (EoTD), a novel\ntechnique that encapsulates the reasoning process into equation-based\nrepresentations to construct an EoTD dataset for fine-tuning SLMs.\nAdditionally, we propose the Mix Thoughts Distillation (MTD) framework to\nenhance the reasoning performance of SLMs. This involves creating a reasoning\ndataset with multiple thought processes and using it for fine-tuning. Our\nexperimental findings demonstrate that EoTD significantly boosts the reasoning\nabilities of SLMs, while MTD enables these models to achieve state-of-the-art\nreasoning performance.\n",
    "link": "http://arxiv.org/abs/2401.11864v1"
  },
  {
    "title": "A Review of Physics-Informed Machine Learning Methods with Applications\n  to Condition Monitoring and Anomaly Detection",
    "authors": "Yuandi Wu, Brett Sicard, Stephen Andrew Gadsden",
    "abstract": "  This study presents a comprehensive overview of PIML techniques in the\ncontext of condition monitoring. The central concept driving PIML is the\nincorporation of known physical laws and constraints into machine learning\nalgorithms, enabling them to learn from available data while remaining\nconsistent with physical principles. Through fusing domain knowledge with\ndata-driven learning, PIML methods offer enhanced accuracy and interpretability\nin comparison to purely data-driven approaches. In this comprehensive survey,\ndetailed examinations are performed with regard to the methodology by which\nknown physical principles are integrated within machine learning frameworks, as\nwell as their suitability for specific tasks within condition monitoring.\nIncorporation of physical knowledge into the ML model may be realized in a\nvariety of methods, with each having its unique advantages and drawbacks. The\ndistinct advantages and limitations of each methodology for the integration of\nphysics within data-driven models are detailed, considering factors such as\ncomputational efficiency, model interpretability, and generalizability to\ndifferent systems in condition monitoring and fault detection. Several case\nstudies and works of literature utilizing this emerging concept are presented\nto demonstrate the efficacy of PIML in condition monitoring applications. From\nthe literature reviewed, the versatility and potential of PIML in condition\nmonitoring may be demonstrated. Novel PIML methods offer an innovative solution\nfor addressing the complexities of condition monitoring and associated\nchallenges. This comprehensive survey helps form the foundation for future work\nin the field. As the technology continues to advance, PIML is expected to play\na crucial role in enhancing maintenance strategies, system reliability, and\noverall operational efficiency in engineering systems.\n",
    "link": "http://arxiv.org/abs/2401.11860v1"
  },
  {
    "title": "The Right Model for the Job: An Evaluation of Legal Multi-Label\n  Classification Baselines",
    "authors": "Martina Forster, Claudia Schulz, Prudhvi Nokku, Melicaalsadat Mirsafian, Jaykumar Kasundra, Stavroula Skylaki",
    "abstract": "  Multi-Label Classification (MLC) is a common task in the legal domain, where\nmore than one label may be assigned to a legal document. A wide range of\nmethods can be applied, ranging from traditional ML approaches to the latest\nTransformer-based architectures. In this work, we perform an evaluation of\ndifferent MLC methods using two public legal datasets, POSTURE50K and\nEURLEX57K. By varying the amount of training data and the number of labels, we\nexplore the comparative advantage offered by different approaches in relation\nto the dataset properties. Our findings highlight DistilRoBERTa and LegalBERT\nas performing consistently well in legal MLC with reasonable computational\ndemands. T5 also demonstrates comparable performance while offering advantages\nas a generative model in the presence of changing label sets. Finally, we show\nthat the CrossEncoder exhibits potential for notable macro-F1 score\nimprovements, albeit with increased computational costs.\n",
    "link": "http://arxiv.org/abs/2401.11852v1"
  },
  {
    "title": "BETA: Binarized Energy-Efficient Transformer Accelerator at the Edge",
    "authors": "Yuhao Ji, Chao Fang, Zhongfeng Wang",
    "abstract": "  Existing binary Transformers are promising in edge deployment due to their\ncompact model size, low computational complexity, and considerable inference\naccuracy.However, deploying binary Transformers faces challenges on prior\nprocessors due to inefficient execution of quantized matrix multiplication\n(QMM) and the energy consumption overhead caused by multi-precision\nactivations.To tackle the challenges above, we first develop a computation flow\nabstraction method for binary Transformers to improve QMM execution efficiency\nby optimizing the computation order.Furthermore, a binarized energy-efficient\nTransformer accelerator, namely BETA, is proposed to boost the efficient\ndeployment at the edge.Notably, BETA features a configurable QMM engine,\naccommodating diverse activation precisions of binary Transformers and offering\nhigh-parallelism and high-speed for QMMs with impressive energy\nefficiency.Experimental results evaluated on ZCU102 FPGA show BETA achieves an\naverage energy efficiency of 174 GOPS/W, which is 1.76~21.92x higher than prior\nFPGA-based accelerators, showing BETA's good potential for edge Transformer\nacceleration.\n",
    "link": "http://arxiv.org/abs/2401.11851v1"
  },
  {
    "title": "Self-Labeling the Job Shop Scheduling Problem",
    "authors": "Andrea Corsini, Angelo Porrello, Simone Calderara, Mauro Dell'Amico",
    "abstract": "  In this work, we propose a Self-Supervised training strategy specifically\ndesigned for combinatorial problems. One of the main obstacles in applying\nsupervised paradigms to such problems is the requirement of expensive target\nsolutions as ground-truth, often produced with costly exact solvers. Inspired\nby Semi- and Self-Supervised learning, we show that it is possible to easily\ntrain generative models by sampling multiple solutions and using the best one\naccording to the problem objective as a pseudo-label. In this way, we\niteratively improve the model generation capability by relying only on its\nself-supervision, completely removing the need for optimality information. We\nprove the effectiveness of this Self-Labeling strategy on the Job Shop\nScheduling (JSP), a complex combinatorial problem that is receiving much\nattention from the Reinforcement Learning community. We propose a generative\nmodel based on the well-known Pointer Network and train it with our strategy.\nExperiments on two popular benchmarks demonstrate the potential of this\napproach as the resulting models outperform constructive heuristics and current\nstate-of-the-art Reinforcement Learning proposals.\n",
    "link": "http://arxiv.org/abs/2401.11849v1"
  },
  {
    "title": "ExtruOnt: An ontology for describing a type of manufacturing machine for\n  Industry 4.0 systems",
    "authors": "V\u00edctor Julio Ram\u00edrez-Dur\u00e1n, Idoia Berges, Arantza Illarramendi",
    "abstract": "  Semantically rich descriptions of manufacturing machines, offered in a\nmachine-interpretable code, can provide interesting benefits in Industry 4.0\nscenarios. However, the lack of that type of descriptions is evident. In this\npaper we present the development effort made to build an ontology, called\nExtruOnt, for describing a type of manufacturing machine, more precisely, a\ntype that performs an extrusion process (extruder). Although the scope of the\nontology is restricted to a concrete domain, it could be used as a model for\nthe development of other ontologies for describing manufacturing machines in\nIndustry 4.0 scenarios. The terms of the ExtruOnt ontology provide different\ntypes of information related with an extruder, which are reflected in distinct\nmodules that constitute the ontology. Thus, it contains classes and properties\nfor expressing descriptions about components of an extruder, spatial\nconnections, features, and 3D representations of those components, and finally\nthe sensors used to capture indicators about the performance of this type of\nmachine. The ontology development process has been carried out in close\ncollaboration with domain experts.\n",
    "link": "http://arxiv.org/abs/2401.11848v1"
  },
  {
    "title": "Adaptive Fusion of Multi-view Remote Sensing data for Optimal Sub-field\n  Crop Yield Prediction",
    "authors": "Francisco Mena, Deepak Pathak, Hiba Najjar, Cristhian Sanchez, Patrick Helber, Benjamin Bischke, Peter Habelitz, Miro Miranda, Jayanth Siddamsetty, Marlon Nuske, Marcela Charfuelan, Diego Arenas, Michaela Vollmer, Andreas Dengel",
    "abstract": "  Accurate crop yield prediction is of utmost importance for informed\ndecision-making in agriculture, aiding farmers, and industry stakeholders.\nHowever, this task is complex and depends on multiple factors, such as\nenvironmental conditions, soil properties, and management practices. Combining\nheterogeneous data views poses a fusion challenge, like identifying the\nview-specific contribution to the predictive task. We present a novel\nmulti-view learning approach to predict crop yield for different crops\n(soybean, wheat, rapeseed) and regions (Argentina, Uruguay, and Germany). Our\nmulti-view input data includes multi-spectral optical images from Sentinel-2\nsatellites and weather data as dynamic features during the crop growing season,\ncomplemented by static features like soil properties and topographic\ninformation. To effectively fuse the data, we introduce a Multi-view Gated\nFusion (MVGF) model, comprising dedicated view-encoders and a Gated Unit (GU)\nmodule. The view-encoders handle the heterogeneity of data sources with varying\ntemporal resolutions by learning a view-specific representation. These\nrepresentations are adaptively fused via a weighted sum. The fusion weights are\ncomputed for each sample by the GU using a concatenation of the\nview-representations. The MVGF model is trained at sub-field level with 10 m\nresolution pixels. Our evaluations show that the MVGF outperforms conventional\nmodels on the same task, achieving the best results by incorporating all the\ndata sources, unlike the usual fusion results in the literature. For Argentina,\nthe MVGF model achieves an R2 value of 0.68 at sub-field yield prediction,\nwhile at field level evaluation (comparing field averages), it reaches around\n0.80 across different countries. The GU module learned different weights based\non the country and crop-type, aligning with the variable significance of each\ndata source to the prediction task.\n",
    "link": "http://arxiv.org/abs/2401.11844v1"
  },
  {
    "title": "Learning to Approximate Adaptive Kernel Convolution on Graphs",
    "authors": "Jaeyoon Sim, Sooyeon Jeon, InJun Choi, Guorong Wu, Won Hwa Kim",
    "abstract": "  Various Graph Neural Networks (GNNs) have been successful in analyzing data\nin non-Euclidean spaces, however, they have limitations such as oversmoothing,\ni.e., information becomes excessively averaged as the number of hidden layers\nincreases. The issue stems from the intrinsic formulation of conventional graph\nconvolution where the nodal features are aggregated from a direct neighborhood\nper layer across the entire nodes in the graph. As setting different number of\nhidden layers per node is infeasible, recent works leverage a diffusion kernel\nto redefine the graph structure and incorporate information from farther nodes.\nUnfortunately, such approaches suffer from heavy diagonalization of a graph\nLaplacian or learning a large transform matrix. In this regards, we propose a\ndiffusion learning framework, where the range of feature aggregation is\ncontrolled by the scale of a diffusion kernel. For efficient computation, we\nderive closed-form derivatives of approximations of the graph convolution with\nrespect to the scale, so that node-wise range can be adaptively learned. With a\ndownstream classifier, the entire framework is made trainable in an end-to-end\nmanner. Our model is tested on various standard datasets for node-wise\nclassification for the state-of-the-art performance, and it is also validated\non a real-world brain network data for graph classifications to demonstrate its\npracticality for Alzheimer classification.\n",
    "link": "http://arxiv.org/abs/2401.11840v1"
  },
  {
    "title": "SuperCLUE-Math6: Graded Multi-Step Math Reasoning Benchmark for LLMs in\n  Chinese",
    "authors": "Liang Xu, Hang Xue, Lei Zhu, Kangkang Zhao",
    "abstract": "  We introduce SuperCLUE-Math6(SC-Math6), a new benchmark dataset to evaluate\nthe mathematical reasoning abilities of Chinese language models. SC-Math6 is\ndesigned as an upgraded Chinese version of the GSM8K dataset with enhanced\ndifficulty, diversity, and application scope. It consists of over 2000\nmathematical word problems requiring multi-step reasoning and providing natural\nlanguage solutions. We propose an innovative scheme to quantify the reasoning\ncapability of large models based on performance over problems with different\nreasoning steps. Experiments on 12 representative Chinese models demonstrate a\nclear stratification of reasoning levels, with top models like GPT-4 showing\nsuperior performance. SC-Math6 fills the gap in Chinese mathematical reasoning\nbenchmarks and provides a comprehensive testbed to advance the intelligence of\nChinese language models.\n",
    "link": "http://arxiv.org/abs/2401.11819v1"
  },
  {
    "title": "Hallucination is Inevitable: An Innate Limitation of Large Language\n  Models",
    "authors": "Ziwei Xu, Sanjay Jain, Mohan Kankanhalli",
    "abstract": "  Hallucination has been widely recognized to be a significant drawback for\nlarge language models (LLMs). There have been many works that attempt to reduce\nthe extent of hallucination. These efforts have mostly been empirical so far,\nwhich cannot answer the fundamental question whether it can be completely\neliminated. In this paper, we formalize the problem and show that it is\nimpossible to eliminate hallucination in LLMs. Specifically, we define a formal\nworld where hallucination is defined as inconsistencies between a computable\nLLM and a computable ground truth function. By employing results from learning\ntheory, we show that LLMs cannot learn all of the computable functions and will\ntherefore always hallucinate. Since the formal world is a part of the real\nworld which is much more complicated, hallucinations are also inevitable for\nreal world LLMs. Furthermore, for real world LLMs constrained by provable time\ncomplexity, we describe the hallucination-prone tasks and empirically validate\nour claims. Finally, using the formal world framework, we discuss the possible\nmechanisms and efficacies of existing hallucination mitigators as well as the\npractical implications on the safe deployment of LLMs.\n",
    "link": "http://arxiv.org/abs/2401.11817v1"
  },
  {
    "title": "Symbrain: A large-scale dataset of MRI images for neonatal brain\n  symmetry analysis",
    "authors": "Arnaud Gucciardi, Safouane El Ghazouali, Francesca Venturini, Vida Groznik, Umberto Michelucci",
    "abstract": "  This paper presents an annotated dataset of brain MRI images designed to\nadvance the field of brain symmetry study. Magnetic resonance imaging (MRI) has\ngained interest in analyzing brain symmetry in neonatal infants, and challenges\nremain due to the vast size differences between fetal and adult brains.\nClassification methods for brain structural MRI use scales and visual cues to\nassess hemisphere symmetry, which can help diagnose neonatal patients by\ncomparing hemispheres and anatomical regions of interest in the brain. Using\nthe Developing Human Connectome Project dataset, this work presents a dataset\ncomprising cerebral images extracted as slices across selected portions of\ninterest for clinical evaluation . All the extracted images are annotated with\nthe brain's midline. All the extracted images are annotated with the brain's\nmidline. From the assumption that a decrease in symmetry is directly related to\npossible clinical pathologies, the dataset can contribute to a more precise\ndiagnosis because it can be used to train deep learning model application in\nneonatal cerebral MRI anomaly detection from postnatal infant scans thanks to\ncomputer vision. Such models learn to identify and classify anomalies by\nidentifying potential asymmetrical patterns in medical MRI images. Furthermore,\nthis dataset can contribute to the research and development of methods using\nthe relative symmetry of the two brain hemispheres for crucial diagnosis and\ntreatment planning.\n",
    "link": "http://arxiv.org/abs/2401.11814v1"
  },
  {
    "title": "Generalization and Informativeness of Conformal Prediction",
    "authors": "Matteo Zecchin, Sangwoo Park, Osvaldo Simeone, Fredrik Hellstr\u00f6m",
    "abstract": "  The safe integration of machine learning modules in decision-making processes\nhinges on their ability to quantify uncertainty. A popular technique to achieve\nthis goal is conformal prediction (CP), which transforms an arbitrary base\npredictor into a set predictor with coverage guarantees. While CP certifies the\npredicted set to contain the target quantity with a user-defined tolerance, it\ndoes not provide control over the average size of the predicted sets, i.e.,\nover the informativeness of the prediction. In this work, a theoretical\nconnection is established between the generalization properties of the base\npredictor and the informativeness of the resulting CP prediction sets. To this\nend, an upper bound is derived on the expected size of the CP set predictor\nthat builds on generalization error bounds for the base predictor. The derived\nupper bound provides insights into the dependence of the average size of the CP\nset predictor on the amount of calibration data, the target reliability, and\nthe generalization performance of the base predictor. The theoretical insights\nare validated using simple numerical regression and classification tasks.\n",
    "link": "http://arxiv.org/abs/2401.11810v1"
  },
  {
    "title": "Knowledge Distillation on Spatial-Temporal Graph Convolutional Network\n  for Traffic Prediction",
    "authors": "Mohammad Izadi, Mehran Safayani, Abdolreza Mirzaei",
    "abstract": "  Efficient real-time traffic prediction is crucial for reducing transportation\ntime. To predict traffic conditions, we employ a spatio-temporal graph neural\nnetwork (ST-GNN) to model our real-time traffic data as temporal graphs.\nDespite its capabilities, it often encounters challenges in delivering\nefficient real-time predictions for real-world traffic data. Recognizing the\nsignificance of timely prediction due to the dynamic nature of real-time data,\nwe employ knowledge distillation (KD) as a solution to enhance the execution\ntime of ST-GNNs for traffic prediction. In this paper, We introduce a cost\nfunction designed to train a network with fewer parameters (the student) using\ndistilled data from a complex network (the teacher) while maintaining its\naccuracy close to that of the teacher. We use knowledge distillation,\nincorporating spatial-temporal correlations from the teacher network to enable\nthe student to learn the complex patterns perceived by the teacher. However, a\nchallenge arises in determining the student network architecture rather than\nconsidering it inadvertently. To address this challenge, we propose an\nalgorithm that utilizes the cost function to calculate pruning scores,\naddressing small network architecture search issues, and jointly fine-tunes the\nnetwork resulting from each pruning stage using KD. Ultimately, we evaluate our\nproposed ideas on two real-world datasets, PeMSD7 and PeMSD8. The results\nindicate that our method can maintain the student's accuracy close to that of\nthe teacher, even with the retention of only $3\\%$ of network parameters.\n",
    "link": "http://arxiv.org/abs/2401.11798v1"
  },
  {
    "title": "Safe and Generalized end-to-end Autonomous Driving System with\n  Reinforcement Learning and Demonstrations",
    "authors": "Zuojin Tang, Xiaoyu Chen, YongQiang Li, Jianyu Chen",
    "abstract": "  An intelligent driving system should be capable of dynamically formulating\nappropriate driving strategies based on the current environment and vehicle\nstatus, while ensuring the security and reliability of the system. However,\nexisting methods based on reinforcement learning and imitation learning suffer\nfrom low safety, poor generalization, and inefficient sampling. Additionally,\nthey cannot accurately predict future driving trajectories, and the accurate\nprediction of future driving trajectories is a precondition for making optimal\ndecisions. To solve these problems, in this paper, we introduce a Safe and\nGeneralized end-to-end Autonomous Driving System (SGADS) for complex and\nvarious scenarios. Our SGADS incorporates variational inference with\nnormalizing flows, enabling the intelligent vehicle to accurately predict\nfuture driving trajectories. Moreover, we propose the formulation of robust\nsafety constraints. Furthermore, we combine reinforcement learning with\ndemonstrations to augment search process of the agent. The experimental results\ndemonstrate that our SGADS can significantly improve safety performance,\nexhibit strong generalization, and enhance the training efficiency of\nintelligent vehicles in complex urban scenarios compared to existing methods.\n",
    "link": "http://arxiv.org/abs/2401.11792v1"
  },
  {
    "title": "LightDiC: A Simple yet Effective Approach for Large-scale Digraph\n  Representation Learning",
    "authors": "Xunkai Li, Meihao Liao, Zhengyu Wu, Daohan Su, Wentao Zhang, Rong-Hua Li, Guoren Wang",
    "abstract": "  Most existing graph neural networks (GNNs) are limited to undirected graphs,\nwhose restricted scope of the captured relational information hinders their\nexpressive capabilities and deployments in real-world scenarios. Compared with\nundirected graphs, directed graphs (digraphs) fit the demand for modeling more\ncomplex topological systems by capturing more intricate relationships between\nnodes, such as formulating transportation and financial networks. While some\ndirected GNNs have been introduced, their inspiration mainly comes from deep\nlearning architectures, which lead to redundant complexity and computation,\nmaking them inapplicable to large-scale databases. To address these issues, we\npropose LightDiC, a scalable variant of the digraph convolution based on the\nmagnetic Laplacian. Since topology-related computations are conducted solely\nduring offline pre-processing, LightDiC achieves exceptional scalability,\nenabling downstream predictions to be trained separately without incurring\nrecursive computational costs. Theoretical analysis shows that LightDiC\nutilizes directed information to achieve message passing based on the complex\nfield, which corresponds to the proximal gradient descent process of the\nDirichlet energy optimization function from the perspective of digraph signal\ndenoising, ensuring its expressiveness. Experimental results demonstrate that\nLightDiC performs comparably well or even outperforms other SOTA methods in\nvarious downstream tasks, with fewer learnable parameters and higher training\nefficiency. Notably, LightDiC is the first DiGNN to provide satisfactory\nresults in the most representative large-scale database (ogbn-papers100M).\n",
    "link": "http://arxiv.org/abs/2401.11772v1"
  },
  {
    "title": "FedGTA: Topology-aware Averaging for Federated Graph Learning",
    "authors": "Xunkai Li, Zhengyu Wu, Wentao Zhang, Yinlin Zhu, Rong-Hua Li, Guoren Wang",
    "abstract": "  Federated Graph Learning (FGL) is a distributed machine learning paradigm\nthat enables collaborative training on large-scale subgraphs across multiple\nlocal systems. Existing FGL studies fall into two categories: (i) FGL\nOptimization, which improves multi-client training in existing machine learning\nmodels; (ii) FGL Model, which enhances performance with complex local models\nand multi-client interactions. However, most FGL optimization strategies are\ndesigned specifically for the computer vision domain and ignore graph\nstructure, presenting dissatisfied performance and slow convergence. Meanwhile,\ncomplex local model architectures in FGL Models studies lack scalability for\nhandling large-scale subgraphs and have deployment limitations. To address\nthese issues, we propose Federated Graph Topology-aware Aggregation (FedGTA), a\npersonalized optimization strategy that optimizes through topology-aware local\nsmoothing confidence and mixed neighbor features. During experiments, we deploy\nFedGTA in 12 multi-scale real-world datasets with the Louvain and Metis split.\nThis allows us to evaluate the performance and robustness of FedGTA across a\nrange of scenarios. Extensive experiments demonstrate that FedGTA achieves\nstate-of-the-art performance while exhibiting high scalability and efficiency.\nThe experiment includes ogbn-papers100M, the most representative large-scale\ngraph database so that we can verify the applicability of our method to\nlarge-scale graph learning. To the best of our knowledge, our study is the\nfirst to bridge large-scale graph learning with FGL using this optimization\nstrategy, contributing to the development of efficient and scalable FGL\nmethods.\n",
    "link": "http://arxiv.org/abs/2401.11755v1"
  },
  {
    "title": "From Knowledge Organization to Knowledge Representation and Back",
    "authors": "Fausto Giunchiglia, Mayukh Bagchi, Subhashis Das",
    "abstract": "  Knowledge Organization (KO) and Knowledge Representation (KR) have been the\ntwo mainstream methodologies of knowledge modelling in the Information Science\ncommunity and the Artificial Intelligence community, respectively. The\nfacet-analytical tradition of KO has developed an exhaustive set of guiding\ncanons for ensuring quality in organising and managing knowledge but has\nremained limited in terms of technology-driven activities to expand its scope\nand services beyond the bibliographic universe of knowledge. KR, on the other\nhand, boasts of a robust ecosystem of technologies and technology-driven\nservice design which can be tailored to model any entity or scale to any\nservice in the entire universe of knowledge. This paper elucidates both the\nfacet-analytical KO and KR methodologies in detail and provides a functional\nmapping between them. Out of the mapping, the paper proposes an integrated\nKR-enriched KO methodology with all the standard components of a KO methodology\nplus the advanced technologies provided by the KR approach. The practical\nbenefits of the methodological integration has been exemplified through the\nflagship application of the Digital University at the University of Trento,\nItaly.\n",
    "link": "http://arxiv.org/abs/2401.11753v1"
  },
  {
    "title": "AdaFGL: A New Paradigm for Federated Node Classification with Topology\n  Heterogeneity",
    "authors": "Xunkai Li, Zhengyu Wu, Wentao Zhang, Henan Sun, Rong-Hua Li, Guoren Wang",
    "abstract": "  Recently, Federated Graph Learning (FGL) has attracted significant attention\nas a distributed framework based on graph neural networks, primarily due to its\ncapability to break data silos. Existing FGL studies employ community split on\nthe homophilous global graph by default to simulate federated semi-supervised\nnode classification settings. Such a strategy assumes the consistency of\ntopology between the multi-client subgraphs and the global graph, where\nconnected nodes are highly likely to possess similar feature distributions and\nthe same label. However, in real-world implementations, the varying\nperspectives of local data engineering result in various subgraph topologies,\nposing unique heterogeneity challenges in FGL. Unlike the well-known label\nNon-independent identical distribution (Non-iid) problems in federated\nlearning, FGL heterogeneity essentially reveals the topological divergence\namong multiple clients, namely homophily or heterophily. To simulate and handle\nthis unique challenge, we introduce the concept of structure Non-iid split and\nthen present a new paradigm called \\underline{Ada}ptive \\underline{F}ederated\n\\underline{G}raph \\underline{L}earning (AdaFGL), a decoupled two-step\npersonalized approach. To begin with, AdaFGL employs standard multi-client\nfederated collaborative training to acquire the federated knowledge extractor\nby aggregating uploaded models in the final round at the server. Then, each\nclient conducts personalized training based on the local subgraph and the\nfederated knowledge extractor. Extensive experiments on the 12 graph benchmark\ndatasets validate the superior performance of AdaFGL over state-of-the-art\nbaselines. Specifically, in terms of test accuracy, our proposed AdaFGL\noutperforms baselines by significant margins of 3.24\\% and 5.57\\% on community\nsplit and structure Non-iid split, respectively.\n",
    "link": "http://arxiv.org/abs/2401.11750v1"
  }
]