[
  {
    "title": "Theory of Mind abilities of Large Language Models in Human-Robot\n  Interaction : An Illusion?",
    "authors": "Mudit Verma, Siddhant Bhambri, Subbarao Kambhampati",
    "abstract": "  Large Language Models have shown exceptional generative abilities in various\nnatural language and generation tasks. However, possible anthropomorphization\nand leniency towards failure cases have propelled discussions on emergent\nabilities of Large Language Models especially on Theory of Mind (ToM) abilities\nin Large Language Models. While several false-belief tests exists to verify the\nability to infer and maintain mental models of another entity, we study a\nspecial application of ToM abilities that has higher stakes and possibly\nirreversible consequences : Human Robot Interaction. In this work, we explore\nthe task of Perceived Behavior Recognition, where a robot employs a Large\nLanguage Model (LLM) to assess the robot's generated behavior in a manner\nsimilar to human observer. We focus on four behavior types, namely -\nexplicable, legible, predictable, and obfuscatory behavior which have been\nextensively used to synthesize interpretable robot behaviors. The LLMs goal is,\ntherefore to be a human proxy to the agent, and to answer how a certain agent\nbehavior would be perceived by the human in the loop, for example \"Given a\nrobot's behavior X, would the human observer find it explicable?\". We conduct a\nhuman subject study to verify that the users are able to correctly answer such\na question in the curated situations (robot setting and plan) across five\ndomains. A first analysis of the belief test yields extremely positive results\ninflating ones expectations of LLMs possessing ToM abilities. We then propose\nand perform a suite of perturbation tests which breaks this illusion, i.e.\nInconsistent Belief, Uninformative Context and Conviction Test. We conclude\nthat, the high score of LLMs on vanilla prompts showcases its potential use in\nHRI settings, however to possess ToM demands invariance to trivial or\nirrelevant perturbations in the context which LLMs lack.\n",
    "link": "http://arxiv.org/abs/2401.05302v1"
  },
  {
    "title": "I am a Strange Dataset: Metalinguistic Tests for Language Models",
    "authors": "Tristan Thrush, Jared Moore, Miguel Monares, Christopher Potts, Douwe Kiela",
    "abstract": "  Statements involving metalinguistic self-reference (\"This paper has six\nsections.\") are prevalent in many domains. Can large language models (LLMs)\nhandle such language? In this paper, we present \"I am a Strange Dataset\", a new\ndataset for addressing this question. There are two subtasks: generation and\nverification. In generation, models continue statements like \"The penultimate\nword in this sentence is\" (where a correct continuation is \"is\"). In\nverification, models judge the truth of statements like \"The penultimate word\nin this sentence is sentence.\" (false). We also provide minimally different\nmetalinguistic non-self-reference examples to complement the main dataset by\nprobing for whether models can handle metalinguistic language at all. The\ndataset is hand-crafted by experts and validated by non-expert annotators. We\ntest a variety of open-source LLMs (7B to 70B parameters) as well as\nclosed-source LLMs through APIs. All models perform close to chance across both\nsubtasks and even on the non-self-referential metalinguistic control data,\nthough we find some steady improvement with model scale. GPT 4 is the only\nmodel to consistently do significantly better than chance, and it is still only\nin the 60% range, while our untrained human annotators score well in the 89-93%\nrange. The dataset and evaluation toolkit are available at\nhttps://github.com/TristanThrush/i-am-a-strange-dataset.\n",
    "link": "http://arxiv.org/abs/2401.05300v1"
  },
  {
    "title": "INACIA: Integrating Large Language Models in Brazilian Audit Courts:\n  Opportunities and Challenges",
    "authors": "Jayr Pereira, Andre Assumpcao, Julio Trecenti, Luiz Airosa, Caio Lente, Jhonatan Cl\u00e9to, Guilherme Dobins, Rodrigo Nogueira, Luis Mitchell, Roberto Lotufo",
    "abstract": "  This paper introduces INACIA (Instru\\c{c}\\~ao Assistida com Intelig\\^encia\nArtificial), a groundbreaking system designed to integrate Large Language\nModels (LLMs) into the operational framework of Brazilian Federal Court of\nAccounts (TCU). The system automates various stages of case analysis, including\nbasic information extraction, admissibility examination, Periculum in mora and\nFumus boni iuris analyses, and recommendations generation. Through a series of\nexperiments, we demonstrate INACIA's potential in extracting relevant\ninformation from case documents, evaluating its legal plausibility, and\ngenerating judicial recommendations. Utilizing a validation dataset alongside\nLLMs, our evaluation methodology presents an innovative approach to assessing\nsystem performance, correlating highly with human judgment. The results\nhighlight INACIA's proficiency in handling complex legal tasks, indicating its\nsuitability for augmenting efficiency and judicial fairness within legal\nsystems. The paper also discusses potential enhancements and future\napplications, positioning INACIA as a model for worldwide AI integration in\nlegal domains.\n",
    "link": "http://arxiv.org/abs/2401.05273v1"
  },
  {
    "title": "AUTOACT: Automatic Agent Learning from Scratch via Self-Planning",
    "authors": "Shuofei Qiao, Ningyu Zhang, Runnan Fang, Yujie Luo, Wangchunshu Zhou, Yuchen Eleanor Jiang, Chengfei Lv, Huajun Chen",
    "abstract": "  Language agents have achieved considerable performance on various complex\ntasks. Despite the incessant exploration in this field, existing language agent\nsystems still struggle with costly, non-reproducible data reliance and face the\nchallenge of compelling a single model for multiple functions. To this end, we\nintroduce AutoAct, an automatic agent learning framework that does not rely on\nlarge-scale annotated data and synthetic trajectories from closed-source models\n(e.g., GPT-4). Given limited data with a tool library, AutoAct first\nautomatically synthesizes planning trajectories without any assistance from\nhumans or strong closed-source models. Then, AutoAct leverages a\ndivision-of-labor strategy to automatically differentiate based on the target\ntask information and synthesized trajectories, producing a sub-agent group to\ncomplete the task. We conduct comprehensive experiments with different LLMs,\nwhich demonstrates that AutoAct yields better or parallel performance compared\nto various strong baselines. We even notice that AutoAct, when using the\nLlama-2-13b model, can achieve performance comparable to that of the\nGPT-3.5-Turbo agent. Code will be available at\nhttps://github.com/zjunlp/AutoAct.\n",
    "link": "http://arxiv.org/abs/2401.05268v1"
  },
  {
    "title": "ReACT: Reinforcement Learning for Controller Parametrization using\n  B-Spline Geometries",
    "authors": "Thomas Rudolf, Daniel Fl\u00f6gel, Tobias Sch\u00fcrmann, Simon S\u00fc\u00df, Stefan Schwab, S\u00f6ren Hohmann",
    "abstract": "  Robust and performant controllers are essential for industrial applications.\nHowever, deriving controller parameters for complex and nonlinear systems is\nchallenging and time-consuming. To facilitate automatic controller\nparametrization, this work presents a novel approach using deep reinforcement\nlearning (DRL) with N-dimensional B-spline geometries (BSGs). We focus on the\ncontrol of parameter-variant systems, a class of systems with complex behavior\nwhich depends on the operating conditions. For this system class,\ngain-scheduling control structures are widely used in applications across\nindustries due to well-known design principles. Facilitating the expensive\ncontroller parametrization task regarding these control structures, we deploy\nan DRL agent. Based on control system observations, the agent autonomously\ndecides how to adapt the controller parameters. We make the adaptation process\nmore efficient by introducing BSGs to map the controller parameters which may\ndepend on numerous operating conditions. To preprocess time-series data and\nextract a fixed-length feature vector, we use a long short-term memory (LSTM)\nneural networks. Furthermore, this work contributes actor regularizations that\nare relevant to real-world environments which differ from training.\nAccordingly, we apply dropout layer normalization to the actor and critic\nnetworks of the truncated quantile critic (TQC) algorithm. To show our\napproach's working principle and effectiveness, we train and evaluate the DRL\nagent on the parametrization task of an industrial control structure with\nparameter lookup tables.\n",
    "link": "http://arxiv.org/abs/2401.05251v1"
  },
  {
    "title": "Do Vision and Language Encoders Represent the World Similarly?",
    "authors": "Mayug Maniparambil, Raiymbek Akshulakov, Yasser Abdelaziz Dahou Djilali, Sanath Narayan, Mohamed El Amine Seddik, Karttikeya Mangalam, Noel E. O'Connor",
    "abstract": "  Aligned text-image encoders such as CLIP have become the de facto model for\nvision-language tasks. Furthermore, modality-specific encoders achieve\nimpressive performances in their respective domains. This raises a central\nquestion: does an alignment exist between uni-modal vision and language\nencoders since they fundamentally represent the same physical world? Analyzing\nthe latent spaces structure of vision and language models on image-caption\nbenchmarks using the Centered Kernel Alignment (CKA), we find that the\nrepresentation spaces of unaligned and aligned encoders are semantically\nsimilar. In the absence of statistical similarity in aligned encoders like\nCLIP, we show that a possible matching of unaligned encoders exists without any\ntraining. We frame this as a seeded graph-matching problem exploiting the\nsemantic similarity between graphs and propose two methods - a Fast Quadratic\nAssignment Problem optimization, and a novel localized CKA metric-based\nmatching/retrieval. We demonstrate the effectiveness of this on several\ndownstream tasks including cross-lingual, cross-domain caption matching and\nimage classification.\n",
    "link": "http://arxiv.org/abs/2401.05224v1"
  },
  {
    "title": "Distributed Monitoring for Data Distribution Shifts in Edge-ML Fraud\n  Detection",
    "authors": "Nader Karayanni, Robert J. Shahla, Chieh-Lien Hsiao",
    "abstract": "  The digital era has seen a marked increase in financial fraud. edge ML\nemerged as a promising solution for smartphone payment services fraud\ndetection, enabling the deployment of ML models directly on edge devices. This\napproach enables a more personalized real-time fraud detection. However, a\nsignificant gap in current research is the lack of a robust system for\nmonitoring data distribution shifts in these distributed edge ML applications.\nOur work bridges this gap by introducing a novel open-source framework designed\nfor continuous monitoring of data distribution shifts on a network of edge\ndevices. Our system includes an innovative calculation of the\nKolmogorov-Smirnov (KS) test over a distributed network of edge devices,\nenabling efficient and accurate monitoring of users behavior shifts. We\ncomprehensively evaluate the proposed framework employing both real-world and\nsynthetic financial transaction datasets and demonstrate the framework's\neffectiveness.\n",
    "link": "http://arxiv.org/abs/2401.05219v1"
  },
  {
    "title": "Pre-trained Large Language Models for Financial Sentiment Analysis",
    "authors": "Wei Luo, Dihong Gong",
    "abstract": "  Financial sentiment analysis refers to classifying financial text contents\ninto sentiment categories (e.g. positive, negative, and neutral). In this\npaper, we focus on the classification of financial news title, which is a\nchallenging task due to a lack of large amount of training samples. To overcome\nthis difficulty, we propose to adapt the pretrained large language models\n(LLMs) [1, 2, 3] to solve this problem. The LLMs, which are trained from huge\namount of text corpora,have an advantage in text understanding and can be\neffectively adapted to domain-specific task while requiring very few amount of\ntraining samples. In particular, we adapt the open-source Llama2-7B model\n(2023) with the supervised fine-tuning (SFT) technique [4]. Experimental\nevaluation shows that even with the 7B model (which is relatively small for\nLLMs), our approach significantly outperforms the previous state-of-the-art\nalgorithms.\n",
    "link": "http://arxiv.org/abs/2401.05215v1"
  },
  {
    "title": "A Novel Prompt-tuning Method: Incorporating Scenario-specific Concepts\n  into a Verbalizer",
    "authors": "Yong Ma, Senlin Luo, Yu-Ming Shang, Zhengjun Li, Yong Liu",
    "abstract": "  The verbalizer, which serves to map label words to class labels, is an\nessential component of prompt-tuning. In this paper, we present a novel\napproach to constructing verbalizers. While existing methods for verbalizer\nconstruction mainly rely on augmenting and refining sets of synonyms or related\nwords based on class names, this paradigm suffers from a narrow perspective and\nlack of abstraction, resulting in limited coverage and high bias in the\nlabel-word space. To address this issue, we propose a label-word construction\nprocess that incorporates scenario-specific concepts. Specifically, we extract\nrich concepts from task-specific scenarios as label-word candidates and then\ndevelop a novel cascade calibration module to refine the candidates into a set\nof label words for each class. We evaluate the effectiveness of our proposed\napproach through extensive experiments on {five} widely used datasets for\nzero-shot text classification. The results demonstrate that our method\noutperforms existing methods and achieves state-of-the-art results.\n",
    "link": "http://arxiv.org/abs/2401.05204v1"
  },
  {
    "title": "Knowledge Sharing in Manufacturing using Large Language Models: User\n  Evaluation and Model Benchmarking",
    "authors": "Samuel Kernan Freire, Chaofan Wang, Mina Foosherian, Stefan Wellsandt, Santiago Ruiz-Arenas, Evangelos Niforatos",
    "abstract": "  Managing knowledge efficiently is crucial for organizational success. In\nmanufacturing, operating factories has become increasing knowledge-intensive\nputting strain on the factory's capacity to train and support new operators. In\nthis paper, we introduce a Large Language Model (LLM)-based system designed to\nuse the extensive knowledge contained in factory documentation. The system aims\nto efficiently answer queries from operators and facilitate the sharing of new\nknowledge. To assess its effectiveness, we conducted an evaluation in a factory\nsetting. The results of this evaluation demonstrated the system's benefits;\nnamely, in enabling quicker information retrieval and more efficient resolution\nof issues. However, the study also highlighted a preference for learning from a\nhuman expert when such an option is available. Furthermore, we benchmarked\nseveral closed and open-sourced LLMs for this system. GPT-4 consistently\noutperformed its counterparts, with open-source models like StableBeluga2\ntrailing closely, presenting an attractive option given its data privacy and\ncustomization benefits. Overall, this work offers preliminary insights for\nfactories considering using LLM-tools for knowledge management.\n",
    "link": "http://arxiv.org/abs/2401.05200v1"
  },
  {
    "title": "Monte Carlo Tree Search for Recipe Generation using GPT-2",
    "authors": "Karan Taneja, Richard Segal, Richard Goodwin",
    "abstract": "  Automatic food recipe generation methods provide a creative tool for chefs to\nexplore and to create new, and interesting culinary delights. Given the recent\nsuccess of large language models (LLMs), they have the potential to create new\nrecipes that can meet individual preferences, dietary constraints, and adapt to\nwhat is in your refrigerator. Existing research on using LLMs to generate\nrecipes has shown that LLMs can be finetuned to generate realistic-sounding\nrecipes. However, on close examination, these generated recipes often fail to\nmeet basic requirements like including chicken as an ingredient in chicken\ndishes. In this paper, we propose RecipeMC, a text generation method using\nGPT-2 that relies on Monte Carlo Tree Search (MCTS). RecipeMC allows us to\ndefine reward functions to put soft constraints on text generation and thus\nimprove the credibility of the generated recipes. Our results show that human\nevaluators prefer recipes generated with RecipeMC more often than recipes\ngenerated with other baseline methods when compared with real recipes.\n",
    "link": "http://arxiv.org/abs/2401.05199v1"
  },
  {
    "title": "Modelling, Positioning, and Deep Reinforcement Learning Path Tracking\n  Control of Scaled Robotic Vehicles: Design and Experimental Validation",
    "authors": "Carmine Caponio, Pietro Stano, Raffaele Carli, Ignazio Olivieri, Daniele Ragone, Aldo Sorniotti, Umberto Montanaro",
    "abstract": "  Mobile robotic systems are becoming increasingly popular. These systems are\nused in various indoor applications, raging from warehousing and manufacturing\nto test benches for assessment of advanced control strategies, such as\nartificial intelligence (AI)-based control solutions, just to name a few.\nScaled robotic cars are commonly equipped with a hierarchical control\nacthiecture that includes tasks dedicated to vehicle state estimation and\ncontrol. This paper covers both aspects by proposing (i) a federeted extended\nKalman filter (FEKF), and (ii) a novel deep reinforcement learning (DRL) path\ntracking controller trained via an expert demonstrator to expedite the learning\nphase and increase robustess to the simulation-to-reality gap. The paper also\npresents the formulation of a vehicle model along with an effective yet simple\nprocedure for identifying tis paramters. The experimentally validated model is\nused for (i) supporting the design of the FEKF and (ii) serving as a digital\ntwin for training the proposed DRL-based path tracking algorithm. Experimental\nresults confirm the ability of the FEKF to improve the estimate of the mobile\nrobot's position. Furthermore, the effectiveness of the DRL path tracking\nstrateguy is experimentally tested along manoeuvres not considered during\ntraining, showing also the ability of the AI-based solution to outpeform\nmodel-based control strategies and the demonstrator. The comparison with\nbenchmraking controllers is quantitavely evalueted through a set of key\nperformance indicators.\n",
    "link": "http://arxiv.org/abs/2401.05194v1"
  },
  {
    "title": "Experiment Planning with Function Approximation",
    "authors": "Aldo Pacchiano, Jonathan N. Lee, Emma Brunskill",
    "abstract": "  We study the problem of experiment planning with function approximation in\ncontextual bandit problems. In settings where there is a significant overhead\nto deploying adaptive algorithms -- for example, when the execution of the data\ncollection policies is required to be distributed, or a human in the loop is\nneeded to implement these policies -- producing in advance a set of policies\nfor data collection is paramount. We study the setting where a large dataset of\ncontexts but not rewards is available and may be used by the learner to design\nan effective data collection strategy. Although when rewards are linear this\nproblem has been well studied, results are still missing for more complex\nreward models. In this work we propose two experiment planning strategies\ncompatible with function approximation. The first is an eluder planning and\nsampling procedure that can recover optimality guarantees depending on the\neluder dimension of the reward function class. For the second, we show that a\nuniform sampler achieves competitive optimality rates in the setting where the\nnumber of actions is small. We finalize our results introducing a statistical\ngap fleshing out the fundamental differences between planning and adaptive\nlearning and provide results for planning with model selection.\n",
    "link": "http://arxiv.org/abs/2401.05193v1"
  },
  {
    "title": "Can ChatGPT Rival Neural Machine Translation? A Comparative Study",
    "authors": "Zhaokun Jiang, Ziyin Zhang",
    "abstract": "  Inspired by the increasing interest in leveraging large language models for\ntranslation, this paper evaluates the capabilities of large language models\n(LLMs) represented by ChatGPT in comparison to the mainstream neural machine\ntranslation (NMT) engines in translating Chinese diplomatic texts into English.\nSpecifically, we examine the translation quality of ChatGPT and NMT engines as\nmeasured by four automated metrics and human evaluation based on an\nerror-typology and six analytic rubrics. Our findings show that automated\nmetrics yield similar results for ChatGPT under different prompts and NMT\nsystems, while human annotators tend to assign noticeably higher scores to\nChatGPT when it is provided an example or contextual information about the\ntranslation task. Pairwise correlation between automated metrics and dimensions\nof human evaluation produces weak and non-significant results, suggesting the\ndivergence between the two methods of translation quality assessment. These\nfindings provide valuable insights into the potential of ChatGPT as a capable\nmachine translator, and the influence of prompt engineering on its performance.\n",
    "link": "http://arxiv.org/abs/2401.05176v1"
  },
  {
    "title": "MISS: A Generative Pretraining and Finetuning Approach for Med-VQA",
    "authors": "Jiawei Chen, Dingkang Yang, Yue Jiang, Yuxuan Lei, Lihua Zhang",
    "abstract": "  Medical visual question answering (VQA) is a challenging multimodal task,\nwhere Vision-Language Pre-training (VLP) models can effectively improve the\ngeneralization performance. However, most methods in the medical field treat\nVQA as an answer classification task which is difficult to transfer to\npractical application scenarios. Additionally, due to the privacy of medical\nimages and the expensive annotation process, large-scale medical image-text\npairs datasets for pretraining are severely lacking. In this paper, we propose\na large-scale MultI-task Self-Supervised learning based framework (MISS) for\nmedical VQA tasks. Unlike existing methods, we treat medical VQA as a\ngenerative task. We unify the text encoder and multimodal encoder and align\nimage-text features through multi-task learning. Furthermore, we propose a\nTransfer-and-Caption method that extends the feature space of single-modal\nimage datasets using large language models (LLMs), enabling those traditional\nmedical vision field task data to be applied to VLP. Experiments show that our\nmethod achieves excellent results with fewer multimodal datasets and\ndemonstrates the advantages of generative VQA models. The code and model\nweights will be released upon the paper's acceptance.\n",
    "link": "http://arxiv.org/abs/2401.05163v1"
  },
  {
    "title": "Derm-T2IM: Harnessing Synthetic Skin Lesion Data via Stable Diffusion\n  Models for Enhanced Skin Disease Classification using ViT and CNN",
    "authors": "Muhammad Ali Farooq, Wang Yao, Michael Schukat, Mark A Little, Peter Corcoran",
    "abstract": "  This study explores the utilization of Dermatoscopic synthetic data generated\nthrough stable diffusion models as a strategy for enhancing the robustness of\nmachine learning model training. Synthetic data generation plays a pivotal role\nin mitigating challenges associated with limited labeled datasets, thereby\nfacilitating more effective model training. In this context, we aim to\nincorporate enhanced data transformation techniques by extending the recent\nsuccess of few-shot learning and a small amount of data representation in\ntext-to-image latent diffusion models. The optimally tuned model is further\nused for rendering high-quality skin lesion synthetic data with diverse and\nrealistic characteristics, providing a valuable supplement and diversity to the\nexisting training data. We investigate the impact of incorporating newly\ngenerated synthetic data into the training pipeline of state-of-art machine\nlearning models, assessing its effectiveness in enhancing model performance and\ngeneralization to unseen real-world data. Our experimental results demonstrate\nthe efficacy of the synthetic data generated through stable diffusion models\nhelps in improving the robustness and adaptability of end-to-end CNN and vision\ntransformer models on two different real-world skin lesion datasets.\n",
    "link": "http://arxiv.org/abs/2401.05159v1"
  },
  {
    "title": "Yes, this is what I was looking for! Towards Multi-modal Medical\n  Consultation Concern Summary Generation",
    "authors": "Abhisek Tiwari, Shreyangshu Bera, Sriparna Saha, Pushpak Bhattacharyya, Samrat Ghosh",
    "abstract": "  Over the past few years, the use of the Internet for healthcare-related tasks\nhas grown by leaps and bounds, posing a challenge in effectively managing and\nprocessing information to ensure its efficient utilization. During moments of\nemotional turmoil and psychological challenges, we frequently turn to the\ninternet as our initial source of support, choosing this over discussing our\nfeelings with others due to the associated social stigma. In this paper, we\npropose a new task of multi-modal medical concern summary (MMCS) generation,\nwhich provides a short and precise summary of patients' major concerns brought\nup during the consultation. Nonverbal cues, such as patients' gestures and\nfacial expressions, aid in accurately identifying patients' concerns. Doctors\nalso consider patients' personal information, such as age and gender, in order\nto describe the medical condition appropriately. Motivated by the potential\nefficacy of patients' personal context and visual gestures, we propose a\ntransformer-based multi-task, multi-modal intent-recognition, and medical\nconcern summary generation (IR-MMCSG) system. Furthermore, we propose a\nmultitasking framework for intent recognition and medical concern summary\ngeneration for doctor-patient consultations. We construct the first multi-modal\nmedical concern summary generation (MM-MediConSummation) corpus, which includes\npatient-doctor consultations annotated with medical concern summaries, intents,\npatient personal information, doctor's recommendations, and keywords. Our\nexperiments and analysis demonstrate (a) the significant role of patients'\nexpressions/gestures and their personal information in intent identification\nand medical concern summary generation, and (b) the strong correlation between\nintent recognition and patients' medical concern summary generation\n  The dataset and source code are available at https://github.com/NLP-RL/MMCSG.\n",
    "link": "http://arxiv.org/abs/2401.05134v1"
  },
  {
    "title": "Neural Population Learning beyond Symmetric Zero-sum Games",
    "authors": "Siqi Liu, Luke Marris, Marc Lanctot, Georgios Piliouras, Joel Z. Leibo, Nicolas Heess",
    "abstract": "  We study computationally efficient methods for finding equilibria in n-player\ngeneral-sum games, specifically ones that afford complex visuomotor skills. We\nshow how existing methods would struggle in this setting, either\ncomputationally or in theory. We then introduce NeuPL-JPSRO, a neural\npopulation learning algorithm that benefits from transfer learning of skills\nand converges to a Coarse Correlated Equilibrium (CCE) of the game. We show\nempirical convergence in a suite of OpenSpiel games, validated rigorously by\nexact game solvers. We then deploy NeuPL-JPSRO to complex domains, where our\napproach enables adaptive coordination in a MuJoCo control domain and skill\ntransfer in capture-the-flag. Our work shows that equilibrium convergent\npopulation learning can be implemented at scale and in generality, paving the\nway towards solving real-world games between heterogeneous players with mixed\nmotives.\n",
    "link": "http://arxiv.org/abs/2401.05133v1"
  },
  {
    "title": "Unpacking Human-AI interactions: From interaction primitives to a design\n  space",
    "authors": "Kostas Tsiakas, Dave Murray-Rust",
    "abstract": "  This paper aims to develop a semi-formal design space for Human-AI\ninteractions, by building a set of interaction primitives which specify the\ncommunication between users and AI systems during their interaction. We show\nhow these primitives can be combined into a set of interaction patterns which\ncan provide an abstract specification for exchanging messages between humans\nand AI/ML models to carry out purposeful interactions. The motivation behind\nthis is twofold: firstly, to provide a compact generalisation of existing\npractices, that highlights the similarities and differences between systems in\nterms of their interaction behaviours; and secondly, to support the creation of\nnew systems, in particular by opening the space of possibilities for\ninteractions with models. We present a short literature review on frameworks,\nguidelines and taxonomies related to the design and implementation of HAI\ninteractions, including human-in-the-loop, explainable AI, as well as hybrid\nintelligence and collaborative learning approaches. From the literature review,\nwe define a vocabulary for describing information exchanges in terms of\nproviding and requesting particular model-specific data types. Based on this\nvocabulary, a message passing model for interactions between humans and models\nis presented, which we demonstrate can account for existing systems and\napproaches. Finally, we build this into design patterns as mid-level constructs\nthat capture common interactional structures. We discuss how this approach can\nbe used towards a design space for Human-AI interactions that creates new\npossibilities for designs as well as keeping track of implementation issues and\nconcerns.\n",
    "link": "http://arxiv.org/abs/2401.05115v1"
  },
  {
    "title": "Any-Way Meta Learning",
    "authors": "Junhoo Lee, Yearim Kim, Hyunho Lee, Nojun Kwak",
    "abstract": "  Although meta-learning seems promising performance in the realm of rapid\nadaptability, it is constrained by fixed cardinality. When faced with tasks of\nvarying cardinalities that were unseen during training, the model lacks its\nability. In this paper, we address and resolve this challenge by harnessing\n`label equivalence' emerged from stochastic numeric label assignments during\nepisodic task sampling. Questioning what defines ``true\" meta-learning, we\nintroduce the ``any-way\" learning paradigm, an innovative model training\napproach that liberates model from fixed cardinality constraints. Surprisingly,\nthis model not only matches but often outperforms traditional fixed-way models\nin terms of performance, convergence speed, and stability. This disrupts\nestablished notions about domain generalization. Furthermore, we argue that the\ninherent label equivalence naturally lacks semantic information. To bridge this\nsemantic information gap arising from label equivalence, we further propose a\nmechanism for infusing semantic class information into the model. This would\nenhance the model's comprehension and functionality. Experiments conducted on\nrenowned architectures like MAML and ProtoNet affirm the effectiveness of our\nmethod.\n",
    "link": "http://arxiv.org/abs/2401.05097v1"
  },
  {
    "title": "Generating Diverse and High-Quality Texts by Minimum Bayes Risk Decoding",
    "authors": "Yuu Jinnai, Ukyo Honda, Tetsuro Morimura, Peinan Zhang",
    "abstract": "  One of the most important challenges in text generation systems is to produce\noutputs that are not only correct but also diverse. Recently, Minimum\nBayes-Risk (MBR) decoding has gained prominence for generating sentences of the\nhighest quality among the decoding algorithms. However, existing algorithms\nproposed for generating diverse outputs are predominantly based on beam search\nor random sampling, thus their output quality is capped by these underlying\nmethods. In this paper, we investigate an alternative approach -- we develop\ndiversity-promoting decoding algorithms by enforcing diversity objectives to\nMBR decoding. We propose two variants of MBR, Diverse MBR (DMBR) and\n$k$-medoids MBR (KMBR), methods to generate a set of sentences with high\nquality and diversity. We evaluate DMBR and KMBR on a variety of directed text\ngeneration tasks using encoder-decoder models and a large language model with\nprompting. The experimental results show that the proposed method achieves a\nbetter trade-off than the diverse beam search and sampling algorithms.\n",
    "link": "http://arxiv.org/abs/2401.05054v1"
  },
  {
    "title": "CreINNs: Credal-Set Interval Neural Networks for Uncertainty Estimation\n  in Classification Tasks",
    "authors": "Kaizheng Wang, Keivan Shariatmadar, Shireen Kudukkil Manchingal, Fabio Cuzzolin, David Moens, Hans Hallez",
    "abstract": "  Uncertainty estimation is increasingly attractive for improving the\nreliability of neural networks. In this work, we present novel credal-set\ninterval neural networks (CreINNs) designed for classification tasks. CreINNs\npreserve the traditional interval neural network structure, capturing weight\nuncertainty through deterministic intervals, while forecasting credal sets\nusing the mathematical framework of probability intervals. Experimental\nvalidations on an out-of-distribution detection benchmark (CIFAR10 vs SVHN)\nshowcase that CreINNs outperform epistemic uncertainty estimation when compared\nto variational Bayesian neural networks (BNNs) and deep ensembles (DEs).\nFurthermore, CreINNs exhibit a notable reduction in computational complexity\ncompared to variational BNNs and demonstrate smaller model sizes than DEs.\n",
    "link": "http://arxiv.org/abs/2401.05043v1"
  },
  {
    "title": "Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk",
    "authors": "Dennis Ulmer, Elman Mansimov, Kaixiang Lin, Justin Sun, Xibin Gao, Yi Zhang",
    "abstract": "  Large language models (LLMs) are powerful dialogue agents, but specializing\nthem towards fulfilling a specific function can be challenging. Instructing\ntuning, i.e. tuning models on instruction and sample responses generated by\nhumans (Ouyang et al., 2022), has proven as an effective method to do so, yet\nrequires a number of data samples that a) might not be available or b) costly\nto generate. Furthermore, this cost increases when the goal is to make the LLM\nfollow a specific workflow within a dialogue instead of single instructions.\nInspired by the self-play technique in reinforcement learning and the use of\nLLMs to simulate human agents, we propose a more effective method for data\ncollection through LLMs engaging in a conversation in various roles. This\napproach generates a training data via \"self-talk\" of LLMs that can be refined\nand utilized for supervised fine-tuning. We introduce an automated way to\nmeasure the (partial) success of a dialogue. This metric is used to filter the\ngenerated conversational data that is fed back in LLM for training. Based on\nour automated and human evaluations of conversation quality, we demonstrate\nthat such self-talk data improves results. In addition, we examine the various\ncharacteristics that showcase the quality of generated dialogues and how they\ncan be connected to their potential utility as training data.\n",
    "link": "http://arxiv.org/abs/2401.05033v1"
  },
  {
    "title": "Source-Free Cross-Modal Knowledge Transfer by Unleashing the Potential\n  of Task-Irrelevant Data",
    "authors": "Jinjing Zhu, Yucheng Chen, Lin Wang",
    "abstract": "  Source-free cross-modal knowledge transfer is a crucial yet challenging task,\nwhich aims to transfer knowledge from one source modality (e.g., RGB) to the\ntarget modality (e.g., depth or infrared) with no access to the task-relevant\n(TR) source data due to memory and privacy concerns. A recent attempt leverages\nthe paired task-irrelevant (TI) data and directly matches the features from\nthem to eliminate the modality gap. However, it ignores a pivotal clue that the\npaired TI data could be utilized to effectively estimate the source data\ndistribution and better facilitate knowledge transfer to the target modality.\nTo this end, we propose a novel yet concise framework to unlock the potential\nof paired TI data for enhancing source-free cross-modal knowledge transfer. Our\nwork is buttressed by two key technical components. Firstly, to better estimate\nthe source data distribution, we introduce a Task-irrelevant data-Guided\nModality Bridging (TGMB) module. It translates the target modality data (e.g.,\ninfrared) into the source-like RGB images based on paired TI data and the\nguidance of the available source model to alleviate two key gaps: 1)\ninter-modality gap between the paired TI data; 2) intra-modality gap between TI\nand TR target data. We then propose a Task-irrelevant data-Guided Knowledge\nTransfer (TGKT) module that transfers knowledge from the source model to the\ntarget model by leveraging the paired TI data. Notably, due to the\nunavailability of labels for the TR target data and its less reliable\nprediction from the source model, our TGKT model incorporates a self-supervised\npseudo-labeling approach to enable the target model to learn from its\npredictions. Extensive experiments show that our method achieves\nstate-of-the-art performance on three datasets (RGB-to-depth and\nRGB-to-infrared).\n",
    "link": "http://arxiv.org/abs/2401.05014v1"
  },
  {
    "title": "Less is More : A Closer Look at Multi-Modal Few-Shot Learning",
    "authors": "Chunpeng Zhou, Haishuai Wang, Xilu Yuan, Zhi Yu, Jiajun Bu",
    "abstract": "  Few-shot Learning aims to learn and distinguish new categories with a very\nlimited number of available images, presenting a significant challenge in the\nrealm of deep learning. Recent researchers have sought to leverage the\nadditional textual or linguistic information of these rare categories with a\npre-trained language model to facilitate learning, thus partially alleviating\nthe problem of insufficient supervision signals. However, the full potential of\nthe textual information and pre-trained language model have been underestimated\nin the few-shot learning till now, resulting in limited performance\nenhancements. To address this, we propose a simple but effective framework for\nfew-shot learning tasks, specifically designed to exploit the textual\ninformation and language model. In more detail, we explicitly exploit the\nzero-shot capability of the pre-trained language model with the learnable\nprompt. And we just add the visual feature with the textual feature for\ninference directly without the intricate designed fusion modules in previous\nworks. Additionally, we apply the self-ensemble and distillation to further\nenhance these components. Our extensive experiments conducted across four\nwidely used few-shot datasets demonstrate that our simple framework achieves\nimpressive results. Particularly noteworthy is its outstanding performance in\nthe 1-shot learning task, surpassing state-of-the-art methods by an average of\n3.0\\% in classification accuracy. \\footnote{We will make the source codes of\nthe proposed framework publicly available upon acceptance. }.\n",
    "link": "http://arxiv.org/abs/2401.05010v1"
  },
  {
    "title": "AdaFed: Fair Federated Learning via Adaptive Common Descent Direction",
    "authors": "Shayan Mohajer Hamidi, En-Hui Yang",
    "abstract": "  Federated learning (FL) is a promising technology via which some edge\ndevices/clients collaboratively train a machine learning model orchestrated by\na server. Learning an unfair model is known as a critical problem in federated\nlearning, where the trained model may unfairly advantage or disadvantage some\nof the devices. To tackle this problem, in this work, we propose AdaFed. The\ngoal of AdaFed is to find an updating direction for the server along which (i)\nall the clients' loss functions are decreasing; and (ii) more importantly, the\nloss functions for the clients with larger values decrease with a higher rate.\nAdaFed adaptively tunes this common direction based on the values of local\ngradients and loss functions. We validate the effectiveness of AdaFed on a\nsuite of federated datasets, and demonstrate that AdaFed outperforms\nstate-of-the-art fair FL methods.\n",
    "link": "http://arxiv.org/abs/2401.04993v1"
  },
  {
    "title": "Autonomous Navigation of Tractor-Trailer Vehicles through Roundabout\n  Intersections",
    "authors": "Daniel Attard, Josef Bajada",
    "abstract": "  In recent years, significant advancements have been made in the field of\nautonomous driving with the aim of increasing safety and efficiency. However,\nresearch that focuses on tractor-trailer vehicles is relatively sparse. Due to\nthe physical characteristics and articulated joints, such vehicles require\ntailored models. While turning, the back wheels of the trailer turn at a\ntighter radius and the truck often has to deviate from the centre of the lane\nto accommodate this. Due to the lack of publicly available models, this work\ndevelops truck and trailer models using the high-fidelity simulation software\nCARLA, together with several roundabout scenarios, to establish a baseline\ndataset for benchmarks. Using a twin-q soft actor-critic algorithm, we train a\nquasi-end-to-end autonomous driving model which is able to achieve a 73%\nsuccess rate on different roundabouts.\n",
    "link": "http://arxiv.org/abs/2401.04980v1"
  },
  {
    "title": "Invertible Solution of Neural Differential Equations for Analysis of\n  Irregularly-Sampled Time Series",
    "authors": "YongKyung Oh, Dongyoung Lim, Sungil Kim",
    "abstract": "  To handle the complexities of irregular and incomplete time series data, we\npropose an invertible solution of Neural Differential Equations (NDE)-based\nmethod. While NDE-based methods are a powerful method for analyzing\nirregularly-sampled time series, they typically do not guarantee reversible\ntransformations in their standard form. Our method suggests the variation of\nNeural Controlled Differential Equations (Neural CDEs) with Neural Flow, which\nensures invertibility while maintaining a lower computational burden.\nAdditionally, it enables the training of a dual latent space, enhancing the\nmodeling of dynamic temporal dynamics. Our research presents an advanced\nframework that excels in both classification and interpolation tasks. At the\ncore of our approach is an enhanced dual latent states architecture, carefully\ndesigned for high precision across various time series tasks. Empirical\nanalysis demonstrates that our method significantly outperforms existing\nmodels. This work significantly advances irregular time series analysis,\nintroducing innovative techniques and offering a versatile tool for diverse\npractical applications.\n",
    "link": "http://arxiv.org/abs/2401.04979v1"
  },
  {
    "title": "Closed-Form Interpretation of Neural Network Classifiers with Symbolic\n  Regression Gradients",
    "authors": "Sebastian Johann Wetzel",
    "abstract": "  I introduce a unified framework for interpreting neural network classifiers\ntailored toward automated scientific discovery. In contrast to neural\nnetwork-based regression, for classification, it is in general impossible to\nfind a one-to-one mapping from the neural network to a symbolic equation even\nif the neural network itself bases its classification on a quantity that can be\nwritten as a closed-form equation. In this paper, I embed a trained neural\nnetwork into an equivalence class of classifying functions that base their\ndecisions on the same quantity. I interpret neural networks by finding an\nintersection between this equivalence class and human-readable equations\ndefined by the search space of symbolic regression. The approach is not limited\nto classifiers or full neural networks and can be applied to arbitrary neurons\nin hidden layers or latent spaces or to simplify the process of interpreting\nneural network regressors.\n",
    "link": "http://arxiv.org/abs/2401.04978v1"
  },
  {
    "title": "Information Flow Rate for Cross-Correlated Stochastic Processes",
    "authors": "Dionissios T. Hristopulos",
    "abstract": "  Causal inference seeks to identify cause-and-effect interactions in coupled\nsystems. A recently proposed method by Liang detects causal relations by\nquantifying the direction and magnitude of information flow between time\nseries. The theoretical formulation of information flow for stochastic\ndynamical systems provides a general expression and a data-driven statistic for\nthe rate of entropy transfer between different system units. To advance\nunderstanding of information flow rate in terms of intuitive concepts and\nphysically meaningful parameters, we investigate statistical properties of the\ndata-driven information flow rate between coupled stochastic processes. We\nderive relations between the expectation of the information flow rate statistic\nand properties of the auto- and cross-correlation functions. Thus, we elucidate\nthe dependence of the information flow rate on the analytical properties and\ncharacteristic times of the correlation functions. Our analysis provides\ninsight into the influence of the sampling step, the strength of\ncross-correlations, and the temporal delay of correlations on information flow\nrate. We support the theoretical results with numerical simulations of\ncorrelated Gaussian processes.\n",
    "link": "http://arxiv.org/abs/2401.04950v1"
  },
  {
    "title": "Fully Decentralized Cooperative Multi-Agent Reinforcement Learning: A\n  Survey",
    "authors": "Jiechuan Jiang, Kefan Su, Zongqing Lu",
    "abstract": "  Cooperative multi-agent reinforcement learning is a powerful tool to solve\nmany real-world cooperative tasks, but restrictions of real-world applications\nmay require training the agents in a fully decentralized manner. Due to the\nlack of information about other agents, it is challenging to derive algorithms\nthat can converge to the optimal joint policy in a fully decentralized setting.\nThus, this research area has not been thoroughly studied. In this paper, we\nseek to systematically review the fully decentralized methods in two settings:\nmaximizing a shared reward of all agents and maximizing the sum of individual\nrewards of all agents, and discuss open questions and future research\ndirections.\n",
    "link": "http://arxiv.org/abs/2401.04934v1"
  },
  {
    "title": "Learning-Based Difficulty Calibration for Enhanced Membership Inference\n  Attacks",
    "authors": "Haonan Shi, Tu Ouyang, An Wang",
    "abstract": "  Machine learning models, in particular deep neural networks, are currently an\nintegral part of various applications, from healthcare to finance. However,\nusing sensitive data to train these models raises concerns about privacy and\nsecurity. One method that has emerged to verify if the trained models are\nprivacy-preserving is Membership Inference Attacks (MIA), which allows\nadversaries to determine whether a specific data point was part of a model's\ntraining dataset. While a series of MIAs have been proposed in the literature,\nonly a few can achieve high True Positive Rates (TPR) in the low False Positive\nRate (FPR) region (0.01%~1%). This is a crucial factor to consider for an MIA\nto be practically useful in real-world settings. In this paper, we present a\nnovel approach to MIA that is aimed at significantly improving TPR at low FPRs.\nOur method, named learning-based difficulty calibration for MIA(LDC-MIA),\ncharacterizes data records by their hardness levels using a neural network\nclassifier to determine membership. The experiment results show that LDC-MIA\ncan improve TPR at low FPR by up to 4x compared to the other difficulty\ncalibration based MIAs. It also has the highest Area Under ROC curve (AUC)\nacross all datasets. Our method's cost is comparable with most of the existing\nMIAs, but is orders of magnitude more efficient than one of the\nstate-of-the-art methods, LiRA, while achieving similar performance.\n",
    "link": "http://arxiv.org/abs/2401.04929v1"
  },
  {
    "title": "The Impact of Reasoning Step Length on Large Language Models",
    "authors": "Mingyu Jin, Qinkai Yu, Dong shu, Haiyan Zhao, Wenyue Hua, Yanda Meng, Yongfeng Zhang, Mengnan Du",
    "abstract": "  Chain of Thought (CoT) is significant in improving the reasoning abilities of\nlarge language models (LLMs). However, the correlation between the\neffectiveness of CoT and the length of reasoning steps in prompts remains\nlargely unknown. To shed light on this, we have conducted several empirical\nexperiments to explore the relations. Specifically, we design experiments that\nexpand and compress the rationale reasoning steps within CoT demonstrations,\nwhile keeping all other factors constant. We have the following key findings.\nFirst, the results indicate that lengthening the reasoning steps in prompts,\neven without adding new information into the prompt, considerably enhances\nLLMs' reasoning abilities across multiple datasets. Alternatively, shortening\nthe reasoning steps, even while preserving the key information, significantly\ndiminishes the reasoning abilities of models. This finding highlights the\nimportance of the number of steps in CoT prompts and provides practical\nguidance to make better use of LLMs' potential in complex problem-solving\nscenarios. Second, we also investigated the relationship between the\nperformance of CoT and the rationales used in demonstrations. Surprisingly, the\nresult shows that even incorrect rationales can yield favorable outcomes if\nthey maintain the requisite length of inference. Third, we observed that the\nadvantages of increasing reasoning steps are task-dependent: simpler tasks\nrequire fewer steps, whereas complex tasks gain significantly from longer\ninference sequences.\n",
    "link": "http://arxiv.org/abs/2401.04925v1"
  },
  {
    "title": "ANGO: A Next-Level Evaluation Benchmark For Generation-Oriented Language\n  Models In Chinese Domain",
    "authors": "Bingchao Wang",
    "abstract": "  Recently, various Large Language Models (LLMs) evaluation datasets have\nemerged, but most of them have issues with distorted rankings and difficulty in\nmodel capabilities analysis. Addressing these concerns, this paper introduces\nANGO, a Chinese multi-choice question evaluation benchmark. ANGO proposes\n\\textit{Keypoint} categorization standard for the first time, each question in\nANGO can correspond to multiple keypoints, effectively enhancing\ninterpretability of evaluation results. Base on performance of real humans, we\nbuild a quantifiable question difficulty standard and divide ANGO questions\ninto 9 difficulty levels, which provide more precise guidance for model\ntraining. To minimize data leakage impact and fully leverage ANGO's innovative\nfeatures, we have engineered exclusive sampling strategies and a new evaluation\nframework that support swift testset iteration. Our experiments demonstrate\nthat ANGO poses a stronger challenge to models and reveals more details in\nevaluation result compared to existing benchmarks.\n",
    "link": "http://arxiv.org/abs/2401.04898v1"
  },
  {
    "title": "An Analysis of User Behaviours for Objectively Evaluating Spoken\n  Dialogue Systems",
    "authors": "Koji Inoue, Divesh Lala, Keiko Ochi, Tatsuya Kawahara, Gabriel Skantze",
    "abstract": "  Establishing evaluation schemes for spoken dialogue systems is important, but\nit can also be challenging. While subjective evaluations are commonly used in\nuser experiments, objective evaluations are necessary for research comparison\nand reproducibility. To address this issue, we propose a framework for\nindirectly but objectively evaluating systems based on users' behaviours. In\nthis paper, to this end, we investigate the relationship between user\nbehaviours and subjective evaluation scores in social dialogue tasks: attentive\nlistening, job interview, and first-meeting conversation. The results reveal\nthat in dialogue tasks where user utterances are primary, such as attentive\nlistening and job interview, indicators like the number of utterances and words\nplay a significant role in evaluation. Observing disfluency also can indicate\nthe effectiveness of formal tasks, such as job interview. On the other hand, in\ndialogue tasks with high interactivity, such as first-meeting conversation,\nbehaviours related to turn-taking, like average switch pause length, become\nmore important. These findings suggest that selecting appropriate user\nbehaviours can provide valuable insights for objective evaluation in each\nsocial dialogue task.\n",
    "link": "http://arxiv.org/abs/2401.04867v1"
  },
  {
    "title": "User Embedding Model for Personalized Language Prompting",
    "authors": "Sumanth Doddapaneni, Krishna Sayana, Ambarish Jash, Sukhdeep Sodhi, Dima Kuzmin",
    "abstract": "  Modeling long histories plays a pivotal role in enhancing recommendation\nsystems, allowing to capture user's evolving preferences, resulting in more\nprecise and personalized recommendations. In this study we tackle the\nchallenges of modeling long user histories for preference understanding in\nnatural language. Specifically, we introduce a new User Embedding Module (UEM)\nthat efficiently processes user history in free-form text by compressing and\nrepresenting them as embeddings, to use them as soft prompts to a LM. Our\nexperiments demonstrate the superior capability of this approach in handling\nsignificantly longer histories compared to conventional text based prompting\nmethods, yielding substantial improvements in predictive performance. The main\ncontribution of this research is to demonstrate the ability to bias language\nmodels with user signals represented as embeddings.\n",
    "link": "http://arxiv.org/abs/2401.04858v1"
  }
]