[
  {
    "title": "Synthetic Data Generation Framework, Dataset, and Efficient Deep Model\n  for Pedestrian Intention Prediction",
    "authors": "Muhammad Naveed Riaz, Maciej Wielgosz, Abel Garcia Romera, Antonio M. Lopez",
    "abstract": "  Pedestrian intention prediction is crucial for autonomous driving. In\nparticular, knowing if pedestrians are going to cross in front of the\nego-vehicle is core to performing safe and comfortable maneuvers. Creating\naccurate and fast models that predict such intentions from sequential images is\nchallenging. A factor contributing to this is the lack of datasets with diverse\ncrossing and non-crossing (C/NC) scenarios. We address this scarceness by\nintroducing a framework, named ARCANE, which allows programmatically generating\nsynthetic datasets consisting of C/NC video clip samples. As an example, we use\nARCANE to generate a large and diverse dataset named PedSynth. We will show how\nPedSynth complements widely used real-world datasets such as JAAD and PIE, so\nenabling more accurate models for C/NC prediction. Considering the onboard\ndeployment of C/NC prediction models, we also propose a deep model named\nPedGNN, which is fast and has a very low memory footprint. PedGNN is based on a\nGNN-GRU architecture that takes a sequence of pedestrian skeletons as input to\npredict crossing intentions.\n",
    "link": "http://arxiv.org/abs/2401.06757v1"
  },
  {
    "title": "The Unreasonable Effectiveness of Easy Training Data for Hard Tasks",
    "authors": "Peter Hase, Mohit Bansal, Peter Clark, Sarah Wiegreffe",
    "abstract": "  How can we train models to perform well on hard test data when hard training\ndata is by definition difficult to label correctly? This question has been\ntermed the scalable oversight problem and has drawn increasing attention as\nlanguage models have continually improved. In this paper, we present the\nsurprising conclusion that current language models often generalize relatively\nwell from easy to hard data, even performing as well as \"oracle\" models trained\non hard data. We demonstrate this kind of easy-to-hard generalization using\nsimple training methods like in-context learning, linear classifier heads, and\nQLoRA for seven different measures of datapoint hardness, including six\nempirically diverse human hardness measures (like grade level) and one\nmodel-based measure (loss-based). Furthermore, we show that even if one cares\nmost about model performance on hard data, it can be better to collect and\ntrain on easy data rather than hard data, since hard data is generally noisier\nand costlier to collect. Our experiments use open models up to 70b in size and\nfour publicly available question-answering datasets with questions ranging in\ndifficulty from 3rd grade science questions to college level STEM questions and\ngeneral-knowledge trivia. We conclude that easy-to-hard generalization in LMs\nis surprisingly strong for the tasks studied, suggesting the scalable oversight\nproblem may be easier than previously thought. Our code is available at\nhttps://github.com/allenai/easy-to-hard-generalization\n",
    "link": "http://arxiv.org/abs/2401.06751v1"
  },
  {
    "title": "Using Natural Language Inference to Improve Persona Extraction from\n  Dialogue in a New Domain",
    "authors": "Alexandra DeLucia, Mengjie Zhao, Yoshinori Maeda, Makoto Yoda, Keiichi Yamada, Hiromi Wakaki",
    "abstract": "  While valuable datasets such as PersonaChat provide a foundation for training\npersona-grounded dialogue agents, they lack diversity in conversational and\nnarrative settings, primarily existing in the \"real\" world. To develop dialogue\nagents with unique personas, models are trained to converse given a specific\npersona, but hand-crafting these persona can be time-consuming, thus methods\nexist to automatically extract persona information from existing\ncharacter-specific dialogue. However, these persona-extraction models are also\ntrained on datasets derived from PersonaChat and struggle to provide\nhigh-quality persona information from conversational settings that do not take\nplace in the real world, such as the fantasy-focused dataset, LIGHT. Creating\nnew data to train models on a specific setting is human-intensive, thus\nprohibitively expensive. To address both these issues, we introduce a natural\nlanguage inference method for post-hoc adapting a trained persona extraction\nmodel to a new setting. We draw inspiration from the literature of dialog\nnatural language inference (NLI), and devise NLI-reranking methods to extract\nstructured persona information from dialogue. Compared to existing persona\nextraction models, our method returns higher-quality extracted persona and\nrequires less human annotation.\n",
    "link": "http://arxiv.org/abs/2401.06742v1"
  },
  {
    "title": "Relying on the Unreliable: The Impact of Language Models' Reluctance to\n  Express Uncertainty",
    "authors": "Kaitlyn Zhou, Jena D. Hwang, Xiang Ren, Maarten Sap",
    "abstract": "  As natural language becomes the default interface for human-AI interaction,\nthere is a critical need for LMs to appropriately communicate uncertainties in\ndownstream applications. In this work, we investigate how LMs incorporate\nconfidence about their responses via natural language and how downstream users\nbehave in response to LM-articulated uncertainties. We examine publicly\ndeployed models and find that LMs are unable to express uncertainties when\nanswering questions even when they produce incorrect responses. LMs can be\nexplicitly prompted to express confidences, but tend to be overconfident,\nresulting in high error rates (on average 47%) among confident responses. We\ntest the risks of LM overconfidence by running human experiments and show that\nusers rely heavily on LM generations, whether or not they are marked by\ncertainty. Lastly, we investigate the preference-annotated datasets used in\nRLHF alignment and find that humans have a bias against texts with uncertainty.\nOur work highlights a new set of safety harms facing human-LM interactions and\nproposes design recommendations and mitigating strategies moving forward.\n",
    "link": "http://arxiv.org/abs/2401.06730v1"
  },
  {
    "title": "Reframing Tax Law Entailment as Analogical Reasoning",
    "authors": "Xinrui Zou, Ming Zhang, Nathaniel Weir, Benjamin Van Durme, Nils Holzenberger",
    "abstract": "  Statutory reasoning refers to the application of legislative provisions to a\nseries of case facts described in natural language. We re-frame statutory\nreasoning as an analogy task, where each instance of the analogy task involves\na combination of two instances of statutory reasoning. This increases the\ndataset size by two orders of magnitude, and introduces an element of\ninterpretability. We show that this task is roughly as difficult to Natural\nLanguage Processing models as the original task. Finally, we come back to\nstatutory reasoning, solving it with a combination of a retrieval mechanism and\nanalogy models, and showing some progress on prior comparable work.\n",
    "link": "http://arxiv.org/abs/2401.06715v1"
  },
  {
    "title": "Reliability Analysis of Psychological Concept Extraction and\n  Classification in User-penned Text",
    "authors": "Muskan Garg, MSVPJ Sathvik, Amrit Chadha, Shaina Raza, Sunghwan Sohn",
    "abstract": "  The social NLP research community witness a recent surge in the computational\nadvancements of mental health analysis to build responsible AI models for a\ncomplex interplay between language use and self-perception. Such responsible AI\nmodels aid in quantifying the psychological concepts from user-penned texts on\nsocial media. On thinking beyond the low-level (classification) task, we\nadvance the existing binary classification dataset, towards a higher-level task\nof reliability analysis through the lens of explanations, posing it as one of\nthe safety measures. We annotate the LoST dataset to capture nuanced textual\ncues that suggest the presence of low self-esteem in the posts of Reddit users.\nWe further state that the NLP models developed for determining the presence of\nlow self-esteem, focus more on three types of textual cues: (i) Trigger: words\nthat triggers mental disturbance, (ii) LoST indicators: text indicators\nemphasizing low self-esteem, and (iii) Consequences: words describing the\nconsequences of mental disturbance. We implement existing classifiers to\nexamine the attention mechanism in pre-trained language models (PLMs) for a\ndomain-specific psychology-grounded task. Our findings suggest the need of\nshifting the focus of PLMs from Trigger and Consequences to a more\ncomprehensive explanation, emphasizing LoST indicators while determining low\nself-esteem in Reddit posts.\n",
    "link": "http://arxiv.org/abs/2401.06709v1"
  },
  {
    "title": "A Closed-form Solution for Weight Optimization in Fully-connected\n  Feed-forward Neural Networks",
    "authors": "Slavisa Tomic, Jo\u00e3o Pedro Matos-Carvalho, Marko Beko",
    "abstract": "  This work addresses weight optimization problem for fully-connected\nfeed-forward neural networks. Unlike existing approaches that are based on\nback-propagation (BP) and chain rule gradient-based optimization (which implies\niterative execution, potentially burdensome and time-consuming in some cases),\nthe proposed approach offers the solution for weight optimization in\nclosed-form by means of least squares (LS) methodology. In the case where the\ninput-to-output mapping is injective, the new approach optimizes the weights in\na back-propagating fashion in a single iteration by jointly optimizing a set of\nweights in each layer for each neuron. In the case where the input-to-output\nmapping is not injective (e.g., in classification problems), the proposed\nsolution is easily adapted to obtain its final solution in a few iterations. An\nimportant advantage over the existing solutions is that these computations (for\nall neurons in a layer) are independent from each other; thus, they can be\ncarried out in parallel to optimize all weights in a given layer\nsimultaneously. Furthermore, its running time is deterministic in the sense\nthat one can obtain the exact number of computations necessary to optimize the\nweights in all network layers (per iteration, in the case of non-injective\nmapping). Our simulation and empirical results show that the proposed scheme,\nBPLS, works well and is competitive with existing ones in terms of accuracy,\nbut significantly surpasses them in terms of running time. To summarize, the\nnew method is straightforward to implement, is competitive and computationally\nmore efficient than the existing ones, and is well-tailored for parallel\nimplementation.\n",
    "link": "http://arxiv.org/abs/2401.06699v1"
  },
  {
    "title": "An Experimental Design Framework for Label-Efficient Supervised\n  Finetuning of Large Language Models",
    "authors": "Gantavya Bhatt, Yifang Chen, Arnav M. Das, Jifan Zhang, Sang T. Truong, Stephen Mussmann, Yinglun Zhu, Jeffrey Bilmes, Simon S. Du, Kevin Jamieson, Jordan T. Ash, Robert D. Nowak",
    "abstract": "  Supervised finetuning (SFT) on instruction datasets has played a crucial role\nin achieving the remarkable zero-shot generalization capabilities observed in\nmodern large language models (LLMs). However, the annotation efforts required\nto produce high quality responses for instructions are becoming prohibitively\nexpensive, especially as the number of tasks spanned by instruction datasets\ncontinues to increase. Active learning is effective in identifying useful\nsubsets of samples to annotate from an unlabeled pool, but its high\ncomputational cost remains a barrier to its widespread applicability in the\ncontext of LLMs. To mitigate the annotation cost of SFT and circumvent the\ncomputational bottlenecks of active learning, we propose using experimental\ndesign. Experimental design techniques select the most informative samples to\nlabel, and typically maximize some notion of uncertainty and/or diversity. In\nour work, we implement a framework that evaluates several existing and novel\nexperimental design techniques and find that these methods consistently yield\nsignificant gains in label efficiency with little computational overhead. On\ngenerative tasks, our methods achieve the same generalization performance with\nonly $50\\%$ of annotation cost required by random sampling.\n",
    "link": "http://arxiv.org/abs/2401.06692v1"
  },
  {
    "title": "DQNC2S: DQN-based Cross-stream Crisis event Summarizer",
    "authors": "Daniele Rege Cambrin, Luca Cagliero, Paolo Garza",
    "abstract": "  Summarizing multiple disaster-relevant data streams simultaneously is\nparticularly challenging as existing Retrieve&amp;Re-ranking strategies suffer from\nthe inherent redundancy of multi-stream data and limited scalability in a\nmulti-query setting. This work proposes an online approach to crisis timeline\ngeneration based on weak annotation with Deep Q-Networks. It selects on-the-fly\nthe relevant pieces of text without requiring neither human annotations nor\ncontent re-ranking. This makes the inference time independent of the number of\ninput queries. The proposed approach also incorporates a redundancy filter into\nthe reward function to effectively handle cross-stream content overlaps. The\nachieved ROUGE and BERTScore results are superior to those of best-performing\nmodels on the CrisisFACTS 2022 benchmark.\n",
    "link": "http://arxiv.org/abs/2401.06683v1"
  },
  {
    "title": "LLMRS: Unlocking Potentials of LLM-Based Recommender Systems for\n  Software Purchase",
    "authors": "Angela John, Theophilus Aidoo, Hamayoon Behmanush, Irem B. Gunduz, Hewan Shrestha, Maxx Richard Rahman, Wolfgang Maa\u00df",
    "abstract": "  Recommendation systems are ubiquitous, from Spotify playlist suggestions to\nAmazon product suggestions. Nevertheless, depending on the methodology or the\ndataset, these systems typically fail to capture user preferences and generate\ngeneral recommendations. Recent advancements in Large Language Models (LLM)\noffer promising results for analyzing user queries. However, employing these\nmodels to capture user preferences and efficiency remains an open question. In\nthis paper, we propose LLMRS, an LLM-based zero-shot recommender system where\nwe employ pre-trained LLM to encode user reviews into a review score and\ngenerate user-tailored recommendations. We experimented with LLMRS on a\nreal-world dataset, the Amazon product reviews, for software purchase use\ncases. The results show that LLMRS outperforms the ranking-based baseline model\nwhile successfully capturing meaningful information from product reviews,\nthereby providing more reliable recommendations.\n",
    "link": "http://arxiv.org/abs/2401.06676v1"
  },
  {
    "title": "How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to\n  Challenge AI Safety by Humanizing LLMs",
    "authors": "Yi Zeng, Hongpeng Lin, Jingwen Zhang, Diyi Yang, Ruoxi Jia, Weiyan Shi",
    "abstract": "  Most traditional AI safety research has approached AI models as machines and\ncentered on algorithm-focused attacks developed by security experts. As large\nlanguage models (LLMs) become increasingly common and competent, non-expert\nusers can also impose risks during daily interactions. This paper introduces a\nnew perspective to jailbreak LLMs as human-like communicators, to explore this\noverlooked intersection between everyday language interaction and AI safety.\nSpecifically, we study how to persuade LLMs to jailbreak them. First, we\npropose a persuasion taxonomy derived from decades of social science research.\nThen, we apply the taxonomy to automatically generate interpretable persuasive\nadversarial prompts (PAP) to jailbreak LLMs. Results show that persuasion\nsignificantly increases the jailbreak performance across all risk categories:\nPAP consistently achieves an attack success rate of over $92\\%$ on Llama 2-7b\nChat, GPT-3.5, and GPT-4 in $10$ trials, surpassing recent algorithm-focused\nattacks. On the defense side, we explore various mechanisms against PAP and,\nfound a significant gap in existing defenses, and advocate for more fundamental\nmitigation for highly interactive LLMs\n",
    "link": "http://arxiv.org/abs/2401.06373v1"
  },
  {
    "title": "Decoupling Pixel Flipping and Occlusion Strategy for Consistent XAI\n  Benchmarks",
    "authors": "Stefan Bl\u00fccher, Johanna Vielhaben, Nils Strodthoff",
    "abstract": "  Feature removal is a central building block for eXplainable AI (XAI), both\nfor occlusion-based explanations (Shapley values) as well as their evaluation\n(pixel flipping, PF). However, occlusion strategies can vary significantly from\nsimple mean replacement up to inpainting with state-of-the-art diffusion\nmodels. This ambiguity limits the usefulness of occlusion-based approaches. For\nexample, PF benchmarks lead to contradicting rankings. This is amplified by\ncompeting PF measures: Features are either removed starting with most\ninfluential first (MIF) or least influential first (LIF). This study proposes\ntwo complementary perspectives to resolve this disagreement problem. Firstly,\nwe address the common criticism of occlusion-based XAI, that artificial samples\nlead to unreliable model evaluations. We propose to measure the reliability by\nthe R(eference)-Out-of-Model-Scope (OMS) score. The R-OMS score enables a\nsystematic comparison of occlusion strategies and resolves the disagreement\nproblem by grouping consistent PF rankings. Secondly, we show that the\ninsightfulness of MIF and LIF is conversely dependent on the R-OMS score. To\nleverage this, we combine the MIF and LIF measures into the symmetric relevance\ngain (SRG) measure. This breaks the inherent connection to the underlying\nocclusion strategy and leads to consistent rankings. This resolves the\ndisagreement problem, which we verify for a set of 40 different occlusion\nstrategies.\n",
    "link": "http://arxiv.org/abs/2401.06654v1"
  },
  {
    "title": "Experimental Contexts Can Facilitate Robust Semantic Property Inference\n  in Language Models, but Inconsistently",
    "authors": "Kanishka Misra, Allyson Ettinger, Kyle Mahowald",
    "abstract": "  Recent zero-shot evaluations have highlighted important limitations in the\nabilities of language models (LMs) to perform meaning extraction. However, it\nis now well known that LMs can demonstrate radical improvements in the presence\nof experimental contexts such as in-context examples and instructions. How well\ndoes this translate to previously studied meaning-sensitive tasks? We present a\ncase-study on the extent to which experimental contexts can improve LMs'\nrobustness in performing property inheritance -- predicting semantic properties\nof novel concepts, a task that they have been previously shown to fail on. Upon\ncarefully controlling the nature of the in-context examples and the\ninstructions, our work reveals that they can indeed lead to non-trivial\nproperty inheritance behavior in LMs. However, this ability is inconsistent:\nwith a minimal reformulation of the task, some LMs were found to pick up on\nshallow, non-semantic heuristics from their inputs, suggesting that the\ncomputational principles of semantic property inference are yet to be mastered\nby LMs.\n",
    "link": "http://arxiv.org/abs/2401.06640v1"
  },
  {
    "title": "CCFC: Bridging Federated Clustering and Contrastive Learning",
    "authors": "Jie Yan, Jing Liu, Zhong-Yuan Zhang",
    "abstract": "  Federated clustering, an essential extension of centralized clustering for\nfederated scenarios, enables multiple data-holding clients to collaboratively\ngroup data while keeping their data locally. In centralized scenarios,\nclustering driven by representation learning has made significant advancements\nin handling high-dimensional complex data. However, the combination of\nfederated clustering and representation learning remains underexplored. To\nbridge this, we first tailor a cluster-contrastive model for learning\nclustering-friendly representations. Then, we harness this model as the\nfoundation for proposing a new federated clustering method, named\ncluster-contrastive federated clustering (CCFC). Benefiting from representation\nlearning, the clustering performance of CCFC even double those of the best\nbaseline methods in some cases. Compared to the most related baseline, the\nbenefit results in substantial NMI score improvements of up to 0.4155 on the\nmost conspicuous case. Moreover, CCFC also shows superior performance in\nhandling device failures from a practical viewpoint.\n",
    "link": "http://arxiv.org/abs/2401.06634v1"
  },
  {
    "title": "Ada-Retrieval: An Adaptive Multi-Round Retrieval Paradigm for Sequential\n  Recommendations",
    "authors": "Lei Li, Jianxun Lian, Xiao Zhou, Xing Xie",
    "abstract": "  Retrieval models aim at selecting a small set of item candidates which match\nthe preference of a given user. They play a vital role in large-scale\nrecommender systems since subsequent models such as rankers highly depend on\nthe quality of item candidates. However, most existing retrieval models employ\na single-round inference paradigm, which may not adequately capture the dynamic\nnature of user preferences and stuck in one area in the item space. In this\npaper, we propose Ada-Retrieval, an adaptive multi-round retrieval paradigm for\nrecommender systems that iteratively refines user representations to better\ncapture potential candidates in the full item space. Ada-Retrieval comprises\ntwo key modules: the item representation adapter and the user representation\nadapter, designed to inject context information into items' and users'\nrepresentations. The framework maintains a model-agnostic design, allowing\nseamless integration with various backbone models such as RNNs or Transformers.\nWe perform experiments on three widely used public datasets, incorporating five\npowerful sequential recommenders as backbone models. Our results demonstrate\nthat Ada-Retrieval significantly enhances the performance of various base\nmodels, with consistent improvements observed across different datasets. Our\ncode and data are publicly available at:\nhttps://github.com/ll0ruc/Ada-Retrieval.\n",
    "link": "http://arxiv.org/abs/2401.06633v1"
  },
  {
    "title": "Every Node is Different: Dynamically Fusing Self-Supervised Tasks for\n  Attributed Graph Clustering",
    "authors": "Pengfei Zhu, Qian Wang, Yu Wang, Jialu Li, Qinghua Hu",
    "abstract": "  Attributed graph clustering is an unsupervised task that partitions nodes\ninto different groups. Self-supervised learning (SSL) shows great potential in\nhandling this task, and some recent studies simultaneously learn multiple SSL\ntasks to further boost performance. Currently, different SSL tasks are assigned\nthe same set of weights for all graph nodes. However, we observe that some\ngraph nodes whose neighbors are in different groups require significantly\ndifferent emphases on SSL tasks. In this paper, we propose to dynamically learn\nthe weights of SSL tasks for different nodes and fuse the embeddings learned\nfrom different SSL tasks to boost performance. We design an innovative graph\nclustering approach, namely Dynamically Fusing Self-Supervised Learning\n(DyFSS). Specifically, DyFSS fuses features extracted from diverse SSL tasks\nusing distinct weights derived from a gating network. To effectively learn the\ngating network, we design a dual-level self-supervised strategy that\nincorporates pseudo labels and the graph structure. Extensive experiments on\nfive datasets show that DyFSS outperforms the state-of-the-art multi-task SSL\nmethods by up to 8.66% on the accuracy metric. The code of DyFSS is available\nat: https://github.com/q086/DyFSS.\n",
    "link": "http://arxiv.org/abs/2401.06595v1"
  },
  {
    "title": "Dynamic Behaviour of Connectionist Speech Recognition with Strong\n  Latency Constraints",
    "authors": "Giampiero Salvi",
    "abstract": "  This paper describes the use of connectionist techniques in phonetic speech\nrecognition with strong latency constraints. The constraints are imposed by the\ntask of deriving the lip movements of a synthetic face in real time from the\nspeech signal, by feeding the phonetic string into an articulatory synthesiser.\nParticular attention has been paid to analysing the interaction between the\ntime evolution model learnt by the multi-layer perceptrons and the transition\nmodel imposed by the Viterbi decoder, in different latency conditions. Two\nexperiments were conducted in which the time dependencies in the language model\n(LM) were controlled by a parameter. The results show a strong interaction\nbetween the three factors involved, namely the neural network topology, the\nlength of time dependencies in the LM and the decoder latency.\n",
    "link": "http://arxiv.org/abs/2401.06588v1"
  },
  {
    "title": "Mapping Transformer Leveraged Embeddings for Cross-Lingual Document\n  Representation",
    "authors": "Tsegaye Misikir Tashu, Eduard-Raul Kontos, Matthia Sabatelli, Matias Valdenegro-Toro",
    "abstract": "  Recommendation systems, for documents, have become tools to find relevant\ncontent on the Web. However, these systems have limitations when it comes to\nrecommending documents in languages different from the query language, which\nmeans they might overlook resources in non-native languages. This research\nfocuses on representing documents across languages by using Transformer\nLeveraged Document Representations (TLDRs) that are mapped to a cross-lingual\ndomain. Four multilingual pre-trained transformer models (mBERT, mT5 XLM\nRoBERTa, ErnieM) were evaluated using three mapping methods across 20 language\npairs representing combinations of five selected languages of the European\nUnion. Metrics like Mate Retrieval Rate and Reciprocal Rank were used to\nmeasure the effectiveness of mapped TLDRs compared to non-mapped ones. The\nresults highlight the power of cross-lingual representations achieved through\npre-trained transformers and mapping approaches suggesting a promising\ndirection for expanding beyond language connections, between two specific\nlanguages.\n",
    "link": "http://arxiv.org/abs/2401.06583v1"
  },
  {
    "title": "Lost in the Source Language: How Large Language Models Evaluate the\n  Quality of Machine Translation",
    "authors": "Xu Huang, Zhirui Zhang, Xiang Geng, Yichao Du, Jiajun Chen, Shujian Huang",
    "abstract": "  Large Language Models (LLMs) have achieved remarkable results in the machine\ntranslation evaluation task, yet there remains a gap in knowledge regarding how\nthey utilize the provided data to conduct evaluations. This study aims to\nexplore how LLMs leverage source and reference information in evaluating\ntranslations, with the ultimate goal of better understanding the working\nmechanism of LLMs. To this end, we design the controlled experiments across\nvarious input modes and model types, and employ both coarse-grained and\nfine-grained prompts to discern the utility of source versus reference\ninformation. Surprisingly, we find that reference information significantly\nenhances the evaluation accuracy, while source information sometimes is\ncounterproductive, indicating a lack of cross-lingual capability when using\nLLMs to evaluate translations. We further conduct a meta-evaluation for\ntranslation error detection of LLMs, observing a similar phenomenon. These\nfindings also suggest a potential research direction for LLMs that fully\nexploits the cross-lingual capability of LLMs to achieve better performance in\nmachine translation evaluation tasks.\n",
    "link": "http://arxiv.org/abs/2401.06568v1"
  },
  {
    "title": "A General Benchmark Framework is Dynamic Graph Neural Network Need",
    "authors": "Yusen Zhang",
    "abstract": "  Dynamic graph learning is crucial for modeling real-world systems with\nevolving relationships and temporal dynamics. However, the lack of a unified\nbenchmark framework in current research has led to inaccurate evaluations of\ndynamic graph models. This paper highlights the significance of dynamic graph\nlearning and its applications in various domains. It emphasizes the need for a\nstandardized benchmark framework that captures temporal dynamics, evolving\ngraph structures, and downstream task requirements. Establishing a unified\nbenchmark will help researchers understand the strengths and limitations of\nexisting models, foster innovation, and advance dynamic graph learning. In\nconclusion, this paper identifies the lack of a standardized benchmark\nframework as a current limitation in dynamic graph learning research . Such a\nframework will facilitate accurate model evaluation, drive advancements in\ndynamic graph learning techniques, and enable the development of more effective\nmodels for real-world applications.\n",
    "link": "http://arxiv.org/abs/2401.06559v1"
  },
  {
    "title": "Treatment-Aware Hyperbolic Representation Learning for Causal Effect\n  Estimation with Social Networks",
    "authors": "Ziqiang Cui, Xing Tang, Yang Qiao, Bowei He, Liang Chen, Xiuqiang He, Chen Ma",
    "abstract": "  Estimating the individual treatment effect (ITE) from observational data is a\ncrucial research topic that holds significant value across multiple domains.\nHow to identify hidden confounders poses a key challenge in ITE estimation.\nRecent studies have incorporated the structural information of social networks\nto tackle this challenge, achieving notable advancements. However, these\nmethods utilize graph neural networks to learn the representation of hidden\nconfounders in Euclidean space, disregarding two critical issues: (1) the\nsocial networks often exhibit a scalefree structure, while Euclidean embeddings\nsuffer from high distortion when used to embed such graphs, and (2) each\nego-centric network within a social network manifests a treatment-related\ncharacteristic, implying significant patterns of hidden confounders. To address\nthese issues, we propose a novel method called Treatment-Aware Hyperbolic\nRepresentation Learning (TAHyper). Firstly, TAHyper employs the hyperbolic\nspace to encode the social networks, thereby effectively reducing the\ndistortion of confounder representation caused by Euclidean embeddings.\nSecondly, we design a treatment-aware relationship identification module that\nenhances the representation of hidden confounders by identifying whether an\nindividual and her neighbors receive the same treatment. Extensive experiments\non two benchmark datasets are conducted to demonstrate the superiority of our\nmethod.\n",
    "link": "http://arxiv.org/abs/2401.06557v1"
  },
  {
    "title": "Multimodal Learning for detecting urban functional zones using remote\n  sensing image and multi-semantic information",
    "authors": "Chuanji Shi, Yingying Zhang, Jiaotuan Wang, Qiqi Zhu",
    "abstract": "  Urban area-of-interest (AOI) refers to an integrated urban functional zone\nwith defined boundaries. The rapid development of urban commerce has resulted\nin an increased demand for more precise requirements in defining AOIs. However,\nexisting research primarily concentrates on broad AOI mining for urban planning\nor regional economic analysis, failing to cater to the precise requirements of\nmobile Internet online-to-offline businesses. These businesses necessitate\naccuracy down to a specific community, school, or hospital. In this paper, we\npropose an end-to-end multimodal deep learning algorithm for detecting AOI\nfence polygon using remote sensing images and multi-semantics reference\ninformation. We then evaluate its timeliness through a cascaded module that\nincorporates dynamic human mobility and logistics address information.\nSpecifically, we begin by selecting a point-of-interest (POI) of specific\ncategory, and use it to recall corresponding remote sensing images, nearby\nPOIs, road nodes, human mobility, and logistics addresses to build a multimodal\ndetection model based on transformer encoder-decoder architecture, titled\nAOITR. In the model, in addition to the remote sensing images, multi-semantic\ninformation including core POI and road nodes is embedded and reorganized as\nthe query content part for the transformer decoder to generate the AOI polygon.\nMeanwhile, relatively dynamic distribution features of human mobility, nearby\nPOIs, and logistics addresses are used for AOI reliability evaluation through a\ncascaded feedforward network. The experimental results demonstrate that our\nalgorithm significantly outperforms two existing methods.\n",
    "link": "http://arxiv.org/abs/2401.06550v1"
  },
  {
    "title": "Medical Dialogue Generation via Intuitive-then-Analytical Differential\n  Diagnosis",
    "authors": "Kaishuai Xu, Wenjun Hou, Yi Cheng, Jian Wang, Wenjie Li",
    "abstract": "  Medical dialogue systems have attracted growing research attention as they\nhave the potential to provide rapid diagnoses, treatment plans, and health\nconsultations. In medical dialogues, a proper diagnosis is crucial as it\nestablishes the foundation for future consultations. Clinicians typically\nemploy both intuitive and analytic reasoning to formulate a differential\ndiagnosis. This reasoning process hypothesizes and verifies a variety of\npossible diseases and strives to generate a comprehensive and rigorous\ndiagnosis. However, recent studies on medical dialogue generation have\noverlooked the significance of modeling a differential diagnosis, which hinders\nthe practical application of these systems. To address the above issue, we\npropose a medical dialogue generation framework with the\nIntuitive-then-Analytic Differential Diagnosis (IADDx). Our method starts with\na differential diagnosis via retrieval-based intuitive association and\nsubsequently refines it through a graph-enhanced analytic procedure. The\nresulting differential diagnosis is then used to retrieve medical knowledge and\nguide response generation. Experimental results on two datasets validate the\nefficacy of our method. Besides, we demonstrate how our framework assists both\nclinicians and patients in understanding the diagnostic process, for instance,\nby producing intermediate results and graph-based diagnosis paths.\n",
    "link": "http://arxiv.org/abs/2401.06541v1"
  },
  {
    "title": "Intelligent Data-Driven Architectural Features Orchestration for Network\n  Slicing",
    "authors": "Rodrigo Moreira, Flavio de Oliveira Silva, Tereza Cristina Melo de Brito Carvalho, Joberto S. B. Martins",
    "abstract": "  Network slicing is a crucial enabler and a trend for the Next Generation\nMobile Network (NGMN) and various other new systems like the Internet of\nVehicles (IoV) and Industrial IoT (IIoT). Orchestration and machine learning\nare key elements with a crucial role in the network-slicing processes since the\nNS process needs to orchestrate resources and functionalities, and machine\nlearning can potentially optimize the orchestration process. However, existing\nnetwork-slicing architectures lack the ability to define intelligent approaches\nto orchestrate features and resources in the slicing process. This paper\ndiscusses machine learning-based orchestration of features and capabilities in\nnetwork slicing architectures. Initially, the slice resource orchestration and\nallocation in the slicing planning, configuration, commissioning, and operation\nphases are analyzed. In sequence, we highlight the need for optimized\narchitectural feature orchestration and recommend using ML-embed agents,\nfederated learning intrinsic mechanisms for knowledge acquisition, and a\ndata-driven approach embedded in the network slicing architecture. We further\ndevelop an architectural features orchestration case embedded in the SFI2\nnetwork slicing architecture. An attack prevention security mechanism is\ndeveloped for the SFI2 architecture using distributed embedded and cooperating\nML agents. The case presented illustrates the architectural feature's\norchestration process and benefits, highlighting its importance for the network\nslicing process.\n",
    "link": "http://arxiv.org/abs/2401.06538v1"
  },
  {
    "title": "PCB-Vision: A Multiscene RGB-Hyperspectral Benchmark Dataset of Printed\n  Circuit Boards",
    "authors": "Elias Arbash, Margret Fuchs, Behnood Rasti, Sandra Lorenz, Pedram Ghamisi, Richard Gloaguen",
    "abstract": "  Addressing the critical theme of recycling electronic waste (E-waste), this\ncontribution is dedicated to developing advanced automated data processing\npipelines as a basis for decision-making and process control. Aligning with the\nbroader goals of the circular economy and the United Nations (UN) Sustainable\nDevelopment Goals (SDG), our work leverages non-invasive analysis methods\nutilizing RGB and hyperspectral imaging data to provide both quantitative and\nqualitative insights into the E-waste stream composition for optimizing\nrecycling efficiency. In this paper, we introduce 'PCB-Vision'; a pioneering\nRGB-hyperspectral printed circuit board (PCB) benchmark dataset, comprising 53\nRGB images of high spatial resolution paired with their corresponding high\nspectral resolution hyperspectral data cubes in the visible and near-infrared\n(VNIR) range. Grounded in open science principles, our dataset provides a\ncomprehensive resource for researchers through high-quality ground truths,\nfocusing on three primary PCB components: integrated circuits (IC), capacitors,\nand connectors. We provide extensive statistical investigations on the proposed\ndataset together with the performance of several state-of-the-art (SOTA)\nmodels, including U-Net, Attention U-Net, Residual U-Net, LinkNet, and\nDeepLabv3+. By openly sharing this multi-scene benchmark dataset along with the\nbaseline codes, we hope to foster transparent, traceable, and comparable\ndevelopments of advanced data processing across various scientific communities,\nincluding, but not limited to, computer vision and remote sensing. Emphasizing\nour commitment to supporting a collaborative and inclusive scientific\ncommunity, all materials, including code, data, ground truth, and masks, will\nbe accessible at https://github.com/hifexplo/PCBVision.\n",
    "link": "http://arxiv.org/abs/2401.06528v1"
  },
  {
    "title": "ML-On-Rails: Safeguarding Machine Learning Models in Software Systems A\n  Case Study",
    "authors": "Hala Abdelkader, Mohamed Abdelrazek, Scott Barnett, Jean-Guy Schneider, Priya Rani, Rajesh Vasa",
    "abstract": "  Machine learning (ML), especially with the emergence of large language models\n(LLMs), has significantly transformed various industries. However, the\ntransition from ML model prototyping to production use within software systems\npresents several challenges. These challenges primarily revolve around ensuring\nsafety, security, and transparency, subsequently influencing the overall\nrobustness and trustworthiness of ML models. In this paper, we introduce\nML-On-Rails, a protocol designed to safeguard ML models, establish a\nwell-defined endpoint interface for different ML tasks, and clear communication\nbetween ML providers and ML consumers (software engineers). ML-On-Rails\nenhances the robustness of ML models via incorporating detection capabilities\nto identify unique challenges specific to production ML. We evaluated the\nML-On-Rails protocol through a real-world case study of the MoveReminder\napplication. Through this evaluation, we emphasize the importance of\nsafeguarding ML models in production.\n",
    "link": "http://arxiv.org/abs/2401.06513v1"
  },
  {
    "title": "Frequency Masking for Universal Deepfake Detection",
    "authors": "Chandler Timm Doloriel, Ngai-Man Cheung",
    "abstract": "  We study universal deepfake detection. Our goal is to detect synthetic images\nfrom a range of generative AI approaches, particularly from emerging ones which\nare unseen during training of the deepfake detector. Universal deepfake\ndetection requires outstanding generalization capability. Motivated by recently\nproposed masked image modeling which has demonstrated excellent generalization\nin self-supervised pre-training, we make the first attempt to explore masked\nimage modeling for universal deepfake detection. We study spatial and frequency\ndomain masking in training deepfake detectors. Based on empirical analysis, we\npropose a novel deepfake detector via frequency masking. Our focus on frequency\ndomain is different from the majority, which primarily target spatial domain\ndetection. Our comparative analyses reveal substantial performance gains over\nexisting methods. Code and models are publicly available.\n",
    "link": "http://arxiv.org/abs/2401.06506v1"
  },
  {
    "title": "Improving the Detection of Small Oriented Objects in Aerial Images",
    "authors": "Chandler Timm C. Doloriel, Rhandley D. Cajote",
    "abstract": "  Small oriented objects that represent tiny pixel-area in large-scale aerial\nimages are difficult to detect due to their size and orientation. Existing\noriented aerial detectors have shown promising results but are mainly focused\non orientation modeling with less regard to the size of the objects. In this\nwork, we proposed a method to accurately detect small oriented objects in\naerial images by enhancing the classification and regression tasks of the\noriented object detection model. We designed the Attention-Points Network\nconsisting of two losses: Guided-Attention Loss (GALoss) and Box-Points Loss\n(BPLoss). GALoss uses an instance segmentation mask as ground-truth to learn\nthe attention features needed to improve the detection of small objects. These\nattention features are then used to predict box points for BPLoss, which\ndetermines the points' position relative to the target oriented bounding box.\nExperimental results show the effectiveness of our Attention-Points Network on\na standard oriented aerial dataset with small object instances (DOTA-v1.5) and\non a maritime-related dataset (HRSC2016). The code is publicly available.\n",
    "link": "http://arxiv.org/abs/2401.06503v1"
  },
  {
    "title": "Expected Shapley-Like Scores of Boolean Functions: Complexity and\n  Applications to Probabilistic Databases",
    "authors": "Pratik Karmakar, Mika\u00ebl Monet, Pierre Senellart, St\u00e9phane Bressan",
    "abstract": "  Shapley values, originating in game theory and increasingly prominent in\nexplainable AI, have been proposed to assess the contribution of facts in query\nanswering over databases, along with other similar power indices such as\nBanzhaf values. In this work we adapt these Shapley-like scores to\nprobabilistic settings, the objective being to compute their expected value. We\nshow that the computations of expected Shapley values and of the expected\nvalues of Boolean functions are interreducible in polynomial time, thus\nobtaining the same tractability landscape. We investigate the specific\ntractable case where Boolean functions are represented as deterministic\ndecomposable circuits, designing a polynomial-time algorithm for this setting.\nWe present applications to probabilistic databases through database provenance,\nand an effective implementation of this algorithm within the ProvSQL system,\nwhich experimentally validates its feasibility over a standard benchmark.\n",
    "link": "http://arxiv.org/abs/2401.06493v1"
  },
  {
    "title": "Kun: Answer Polishment for Chinese Self-Alignment with Instruction\n  Back-Translation",
    "authors": "Tianyu Zheng, Shuyue Guo, Xingwei Qu, Jiawei Guo, Weixu Zhang, Xinrun Du, Chenghua Lin, Wenhao Huang, Wenhu Chen, Jie Fu, Ge Zhang",
    "abstract": "  In this paper, we introduce Kun, a novel approach for creating high-quality\ninstruction-tuning datasets for large language models (LLMs) without relying on\nmanual annotations. Adapting a self-training algorithm based on instruction\nback-translation and answer polishment, Kun leverages unlabelled data from\ndiverse sources such as Wudao, Wanjuan, and SkyPile to generate a substantial\ndataset of over a million Chinese instructional data points. This approach\nsignificantly deviates from traditional methods by using a self-curation\nprocess to refine and select the most effective instruction-output pairs. Our\nexperiments with the 6B-parameter Yi model across various benchmarks\ndemonstrate Kun's robustness and scalability. Our method's core contributions\nlie in its algorithmic advancement, which enhances data retention and clarity,\nand its innovative data generation approach that substantially reduces the\nreliance on costly and time-consuming manual annotations. This methodology\npresents a scalable and efficient solution for improving the\ninstruction-following capabilities of LLMs, with significant implications for\ntheir application across diverse fields. The code and dataset can be found at\nhttps://github.com/Zheng0428/COIG-Kun\n",
    "link": "http://arxiv.org/abs/2401.06477v1"
  },
  {
    "title": "A Brain-inspired Computational Model for Human-like Concept Learning",
    "authors": "Yuwei Wang, Yi Zeng",
    "abstract": "  Concept learning is a fundamental aspect of human cognition and plays a\ncritical role in mental processes such as categorization, reasoning, memory,\nand decision-making. Researchers across various disciplines have shown\nconsistent interest in the process of concept acquisition in individuals. To\nelucidate the mechanisms involved in human concept learning, this study\nexamines the findings from computational neuroscience and cognitive psychology.\nThese findings indicate that the brain's representation of concepts relies on\ntwo essential components: multisensory representation and text-derived\nrepresentation. These two types of representations are coordinated by a\nsemantic control system, ultimately leading to the acquisition of concepts.\nDrawing inspiration from this mechanism, the study develops a human-like\ncomputational model for concept learning based on spiking neural networks. By\neffectively addressing the challenges posed by diverse sources and imbalanced\ndimensionality of the two forms of concept representations, the study\nsuccessfully attains human-like concept representations. Tests involving\nsimilar concepts demonstrate that our model, which mimics the way humans learn\nconcepts, yields representations that closely align with human cognition.\n",
    "link": "http://arxiv.org/abs/2401.06471v1"
  },
  {
    "title": "PersianMind: A Cross-Lingual Persian-English Large Language Model",
    "authors": "Pedram Rostami, Ali Salemi, Mohammad Javad Dousti",
    "abstract": "  Large language models demonstrate remarkable proficiency in various\nlinguistic tasks and have extensive knowledge across various domains. Although\nthey perform best in English, their ability in other languages is notable too.\nIn contrast, open-source models, such as LLaMa, are primarily trained on\nEnglish datasets, resulting in poor performance in non-English languages. In\nthis paper, we introduce PersianMind, an open-source bilingual large language\nmodel which demonstrates comparable performance to closed-source GPT-3.5-turbo\nin the Persian language. By expanding LLaMa2's vocabulary with 10,000 Persian\ntokens and training it on a dataset comprising nearly 2 billion Persian tokens,\nwe show that our approach preserves the model's English knowledge and employs\ntransfer learning to excel at transferring task knowledge from one language to\nanother.\n",
    "link": "http://arxiv.org/abs/2401.06466v1"
  },
  {
    "title": "Sanity Checks Revisited: An Exploration to Repair the Model Parameter\n  Randomisation Test",
    "authors": "Anna Hedstr\u00f6m, Leander Weber, Sebastian Lapuschkin, Marina MC H\u00f6hne",
    "abstract": "  The Model Parameter Randomisation Test (MPRT) is widely acknowledged in the\neXplainable Artificial Intelligence (XAI) community for its well-motivated\nevaluative principle: that the explanation function should be sensitive to\nchanges in the parameters of the model function. However, recent works have\nidentified several methodological caveats for the empirical interpretation of\nMPRT. To address these caveats, we introduce two adaptations to the original\nMPRT -- Smooth MPRT and Efficient MPRT, where the former minimises the impact\nthat noise has on the evaluation results through sampling and the latter\ncircumvents the need for biased similarity measurements by re-interpreting the\ntest through the explanation's rise in complexity, after full parameter\nrandomisation. Our experimental results demonstrate that these proposed\nvariants lead to improved metric reliability, thus enabling a more trustworthy\napplication of XAI methods.\n",
    "link": "http://arxiv.org/abs/2401.06465v1"
  },
  {
    "title": "Between Lines of Code: Unraveling the Distinct Patterns of Machine and\n  Human Programmers",
    "authors": "Yuling Shi, Hongyu Zhang, Chengcheng Wan, Xiaodong Gu",
    "abstract": "  Large language models have catalyzed an unprecedented wave in code\ngeneration. While achieving significant advances, they blur the distinctions\nbetween machine-and human-authored source code, causing integrity and\nauthenticity issues of software artifacts. Previous methods such as DetectGPT\nhave proven effective in discerning machine-generated texts, but they do not\nidentify and harness the unique patterns of machine-generated code. Thus, its\napplicability falters when applied to code. In this paper, we carefully study\nthe specific patterns that characterize machine and human-authored code.\nThrough a rigorous analysis of code attributes such as length, lexical\ndiversity, and naturalness, we expose unique pat-terns inherent to each source.\nWe particularly notice that the structural segmentation of code is a critical\nfactor in identifying its provenance. Based on our findings, we propose a novel\nmachine-generated code detection method called DetectCodeGPT, which improves\nDetectGPT by capturing the distinct structural patterns of code. Diverging from\nconventional techniques that depend on external LLMs for perturbations,\nDetectCodeGPT perturbs the code corpus by strategically inserting spaces and\nnewlines, ensuring both efficacy and efficiency. Experiment results show that\nour approach significantly outperforms state-of-the-art techniques in detecting\nmachine-generated code.\n",
    "link": "http://arxiv.org/abs/2401.06461v1"
  },
  {
    "title": "3D-PreMise: Can Large Language Models Generate 3D Shapes with Sharp\n  Features and Parametric Control?",
    "authors": "Zeqing Yuan, Haoxuan Lan, Qiang Zou, Junbo Zhao",
    "abstract": "  Recent advancements in implicit 3D representations and generative models have\nmarkedly propelled the field of 3D object generation forward. However, it\nremains a significant challenge to accurately model geometries with defined\nsharp features under parametric controls, which is crucial in fields like\nindustrial design and manufacturing. To bridge this gap, we introduce a\nframework that employs Large Language Models (LLMs) to generate text-driven 3D\nshapes, manipulating 3D software via program synthesis. We present 3D-PreMise,\na dataset specifically tailored for 3D parametric modeling of industrial\nshapes, designed to explore state-of-the-art LLMs within our proposed pipeline.\nOur work reveals effective generation strategies and delves into the\nself-correction capabilities of LLMs using a visual interface. Our work\nhighlights both the potential and limitations of LLMs in 3D parametric modeling\nfor industrial applications.\n",
    "link": "http://arxiv.org/abs/2401.06437v1"
  },
  {
    "title": "Improving Graph Convolutional Networks with Transformer Layer in\n  social-based items recommendation",
    "authors": "Thi Linh Hoang, Tuan Dung Pham, Viet Cuong Ta",
    "abstract": "  In this work, we have proposed an approach for improving the GCN for\npredicting ratings in social networks. Our model is expanded from the standard\nmodel with several layers of transformer architecture. The main focus of the\npaper is on the encoder architecture for node embedding in the network. Using\nthe embedding layer from the graph-based convolution layer, the attention\nmechanism could rearrange the feature space to get a more efficient embedding\nfor the downstream task. The experiments showed that our proposed architecture\nachieves better performance than GCN on the traditional link prediction task.\n",
    "link": "http://arxiv.org/abs/2401.06436v1"
  },
  {
    "title": "From Automation to Augmentation: Large Language Models Elevating Essay\n  Scoring Landscape",
    "authors": "Changrong Xiao, Wenxing Ma, Sean Xin Xu, Kunpeng Zhang, Yufang Wang, Qi Fu",
    "abstract": "  Receiving immediate and personalized feedback is crucial for second-language\nlearners, and Automated Essay Scoring (AES) systems are a vital resource when\nhuman instructors are unavailable. This study investigates the effectiveness of\nLarge Language Models (LLMs), specifically GPT-4 and fine-tuned GPT-3.5, as\ntools for AES. Our comprehensive set of experiments, conducted on both public\nand private datasets, highlights the remarkable advantages of LLM-based AES\nsystems. They include superior accuracy, consistency, generalizability, and\ninterpretability, with fine-tuned GPT-3.5 surpassing traditional grading\nmodels. Additionally, we undertake LLM-assisted human evaluation experiments\ninvolving both novice and expert graders. One pivotal discovery is that LLMs\nnot only automate the grading process but also enhance the performance of human\ngraders. Novice graders when provided with feedback generated by LLMs, achieve\na level of accuracy on par with experts, while experts become more efficient\nand maintain greater consistency in their assessments. These results underscore\nthe potential of LLMs in educational technology, paving the way for effective\ncollaboration between humans and AI, ultimately leading to transformative\nlearning experiences through AI-generated feedback.\n",
    "link": "http://arxiv.org/abs/2401.06431v1"
  },
  {
    "title": "UPDP: A Unified Progressive Depth Pruner for CNN and Vision Transformer",
    "authors": "Ji Liu, Dehua Tang, Yuanxian Huang, Li Zhang, Xiaocheng Zeng, Dong Li, Mingjie Lu, Jinzhang Peng, Yu Wang, Fan Jiang, Lu Tian, Ashish Sirasao",
    "abstract": "  Traditional channel-wise pruning methods by reducing network channels\nstruggle to effectively prune efficient CNN models with depth-wise\nconvolutional layers and certain efficient modules, such as popular inverted\nresidual blocks. Prior depth pruning methods by reducing network depths are not\nsuitable for pruning some efficient models due to the existence of some\nnormalization layers. Moreover, finetuning subnet by directly removing\nactivation layers would corrupt the original model weights, hindering the\npruned model from achieving high performance. To address these issues, we\npropose a novel depth pruning method for efficient models. Our approach\nproposes a novel block pruning strategy and progressive training method for the\nsubnet. Additionally, we extend our pruning method to vision transformer\nmodels. Experimental results demonstrate that our method consistently\noutperforms existing depth pruning methods across various pruning\nconfigurations. We obtained three pruned ConvNeXtV1 models with our method\napplying on ConvNeXtV1, which surpass most SOTA efficient models with\ncomparable inference performance. Our method also achieves state-of-the-art\npruning performance on the vision transformer model.\n",
    "link": "http://arxiv.org/abs/2401.06426v1"
  },
  {
    "title": "Uncertainty quantification for probabilistic machine learning in earth\n  observation using conformal prediction",
    "authors": "Geethen Singh, Glenn Moncrieff, Zander Venter, Kerry Cawse-Nicholson, Jasper Slingsby, Tamara B Robinson",
    "abstract": "  Unreliable predictions can occur when using artificial intelligence (AI)\nsystems with negative consequences for downstream applications, particularly\nwhen employed for decision-making. Conformal prediction provides a\nmodel-agnostic framework for uncertainty quantification that can be applied to\nany dataset, irrespective of its distribution, post hoc. In contrast to other\npixel-level uncertainty quantification methods, conformal prediction operates\nwithout requiring access to the underlying model and training dataset,\nconcurrently offering statistically valid and informative prediction regions,\nall while maintaining computational efficiency. In response to the increased\nneed to report uncertainty alongside point predictions, we bring attention to\nthe promise of conformal prediction within the domain of Earth Observation (EO)\napplications. To accomplish this, we assess the current state of uncertainty\nquantification in the EO domain and found that only 20% of the reviewed Google\nEarth Engine (GEE) datasets incorporated a degree of uncertainty information,\nwith unreliable methods prevalent. Next, we introduce modules that seamlessly\nintegrate into existing GEE predictive modelling workflows and demonstrate the\napplication of these tools for datasets spanning local to global scales,\nincluding the Dynamic World and Global Ecosystem Dynamics Investigation (GEDI)\ndatasets. These case studies encompass regression and classification tasks,\nfeaturing both traditional and deep learning-based workflows. Subsequently, we\ndiscuss the opportunities arising from the use of conformal prediction in EO.\nWe anticipate that the increased availability of easy-to-use implementations of\nconformal predictors, such as those provided here, will drive wider adoption of\nrigorous uncertainty quantification in EO, thereby enhancing the reliability of\nuses such as operational monitoring and decision making.\n",
    "link": "http://arxiv.org/abs/2401.06421v1"
  },
  {
    "title": "Mission: Impossible Language Models",
    "authors": "Julie Kallini, Isabel Papadimitriou, Richard Futrell, Kyle Mahowald, Christopher Potts",
    "abstract": "  Chomsky and others have very directly claimed that large language models\n(LLMs) are equally capable of learning languages that are possible and\nimpossible for humans to learn. However, there is very little published\nexperimental evidence to support such a claim. Here, we develop a set of\nsynthetic impossible languages of differing complexity, each designed by\nsystematically altering English data with unnatural word orders and grammar\nrules. These languages lie on an impossibility continuum: at one end are\nlanguages that are inherently impossible, such as random and irreversible\nshuffles of English words, and on the other, languages that may not be\nintuitively impossible but are often considered so in linguistics, particularly\nthose with rules based on counting word positions. We report on a wide range of\nevaluations to assess the capacity of GPT-2 small models to learn these\nuncontroversially impossible languages, and crucially, we perform these\nassessments at various stages throughout training to compare the learning\nprocess for each language. Our core finding is that GPT-2 struggles to learn\nimpossible languages when compared to English as a control, challenging the\ncore claim. More importantly, we hope our approach opens up a productive line\nof inquiry in which different LLM architectures are tested on a variety of\nimpossible languages in an effort to learn more about how LLMs can be used as\ntools for these cognitive and typological investigations.\n",
    "link": "http://arxiv.org/abs/2401.06416v1"
  },
  {
    "title": "Knowledge-Informed Machine Learning for Cancer Diagnosis and Prognosis:\n  A review",
    "authors": "Lingchao Mao, Hairong Wang, Leland S. Hu, Nhan L Tran, Peter D Canoll, Kristin R Swanson, Jing Li",
    "abstract": "  Cancer remains one of the most challenging diseases to treat in the medical\nfield. Machine learning has enabled in-depth analysis of rich multi-omics\nprofiles and medical imaging for cancer diagnosis and prognosis. Despite these\nadvancements, machine learning models face challenges stemming from limited\nlabeled sample sizes, the intricate interplay of high-dimensionality data\ntypes, the inherent heterogeneity observed among patients and within tumors,\nand concerns about interpretability and consistency with existing biomedical\nknowledge. One approach to surmount these challenges is to integrate biomedical\nknowledge into data-driven models, which has proven potential to improve the\naccuracy, robustness, and interpretability of model results. Here, we review\nthe state-of-the-art machine learning studies that adopted the fusion of\nbiomedical knowledge and data, termed knowledge-informed machine learning, for\ncancer diagnosis and prognosis. Emphasizing the properties inherent in four\nprimary data types including clinical, imaging, molecular, and treatment data,\nwe highlight modeling considerations relevant to these contexts. We provide an\noverview of diverse forms of knowledge representation and current strategies of\nknowledge integration into machine learning pipelines with concrete examples.\nWe conclude the review article by discussing future directions to advance\ncancer research through knowledge-informed machine learning.\n",
    "link": "http://arxiv.org/abs/2401.06406v1"
  },
  {
    "title": "DevEval: Evaluating Code Generation in Practical Software Projects",
    "authors": "Jia Li, Ge Li, Yunfei Zhao, Yongmin Li, Zhi Jin, Hao Zhu, Huanyu Liu, Kaibo Liu, Lecheng Wang, Zheng Fang, Lanshen Wang, Jiazheng Ding, Xuanming Zhang, Yihong Dong, Yuqi Zhu, Bin Gu, Mengfei Yang",
    "abstract": "  How to evaluate Large Language Models (LLMs) in code generation is an open\nquestion. Many benchmarks have been proposed but are inconsistent with\npractical software projects, e.g., unreal program distributions, insufficient\ndependencies, and small-scale project contexts. Thus, the capabilities of LLMs\nin practical projects are still unclear. In this paper, we propose a new\nbenchmark named DevEval, aligned with Developers' experiences in practical\nprojects. DevEval is collected through a rigorous pipeline, containing 2,690\nsamples from 119 practical projects and covering 10 domains. Compared to\nprevious benchmarks, DevEval aligns to practical projects in multiple\ndimensions, e.g., real program distributions, sufficient dependencies, and\nenough-scale project contexts. We assess five popular LLMs on DevEval (e.g.,\ngpt-4, gpt-3.5-turbo, CodeLLaMa, and StarCoder) and reveal their actual\nabilities in code generation. For instance, the highest Pass@1 of gpt-3.5-turbo\nonly is 42 in our experiments. We also discuss the challenges and future\ndirections of code generation in practical projects. We open-source DevEval and\nhope it can facilitate the development of code generation in practical\nprojects.\n",
    "link": "http://arxiv.org/abs/2401.06401v1"
  },
  {
    "title": "Adaptive Data Augmentation for Aspect Sentiment Quad Prediction",
    "authors": "Wenyuan Zhang, Xinghua Zhang, Shiyao Cui, Kun Huang, Xuebin Wang, Tingwen Liu",
    "abstract": "  Aspect sentiment quad prediction (ASQP) aims to predict the quad sentiment\nelements for a given sentence, which is a critical task in the field of\naspect-based sentiment analysis. However, the data imbalance issue has not\nreceived sufficient attention in ASQP task. In this paper, we divide the issue\ninto two-folds, quad-pattern imbalance and aspect-category imbalance, and\npropose an Adaptive Data Augmentation (ADA) framework to tackle the imbalance\nissue. Specifically, a data augmentation process with a condition function\nadaptively enhances the tail quad patterns and aspect categories, alleviating\nthe data imbalance in ASQP. Following previous studies, we also further explore\nthe generative framework for extracting complete quads by introducing the\ncategory prior knowledge and syntax-guided decoding target. Experimental\nresults demonstrate that data augmentation for imbalance in ASQP task can\nimprove the performance, and the proposed ADA method is superior to naive data\noversampling.\n",
    "link": "http://arxiv.org/abs/2401.06394v1"
  },
  {
    "title": "What should I say? -- Interacting with AI and Natural Language\n  Interfaces",
    "authors": "Mark Adkins",
    "abstract": "  As Artificial Intelligence (AI) technology becomes more and more prevalent,\nit becomes increasingly important to explore how we as humans interact with AI.\nThe Human-AI Interaction (HAI) sub-field has emerged from the Human-Computer\nInteraction (HCI) field and aims to examine this very notion. Many interaction\npatterns have been implemented without fully understanding the changes in\nrequired cognition as well as the cognitive science implications of using these\nalternative interfaces that aim to be more human-like in nature. Prior research\nsuggests that theory of mind representations are crucial to successful and\neffortless communication, however very little is understood when it comes to\nhow theory of mind representations are established when interacting with AI.\n",
    "link": "http://arxiv.org/abs/2401.06382v1"
  },
  {
    "title": "Vehicle: Bridging the Embedding Gap in the Verification of\n  Neuro-Symbolic Programs",
    "authors": "Matthew L. Daggitt, Wen Kokke, Robert Atkey, Natalia Slusarz, Luca Arnaboldi, Ekaterina Komendantskaya",
    "abstract": "  Neuro-symbolic programs -- programs containing both machine learning\ncomponents and traditional symbolic code -- are becoming increasingly\nwidespread. However, we believe that there is still a lack of a general\nmethodology for verifying these programs whose correctness depends on the\nbehaviour of the machine learning components. In this paper, we identify the\n``embedding gap'' -- the lack of techniques for linking semantically-meaningful\n``problem-space'' properties to equivalent ``embedding-space'' properties -- as\none of the key issues, and describe Vehicle, a tool designed to facilitate the\nend-to-end verification of neural-symbolic programs in a modular fashion.\nVehicle provides a convenient language for specifying ``problem-space''\nproperties of neural networks and declaring their relationship to the\n``embedding-space\", and a powerful compiler that automates interpretation of\nthese properties in the language of a chosen machine-learning training\nenvironment, neural network verifier, and interactive theorem prover. We\ndemonstrate Vehicle's utility by using it to formally verify the safety of a\nsimple autonomous car equipped with a neural network controller.\n",
    "link": "http://arxiv.org/abs/2401.06379v1"
  },
  {
    "title": "Cognitive BPM as an Equalizer: Improving Access and Efficiency for\n  Employees with (and without) Cognitive Disabilities",
    "authors": "Gordon Banks, Gates Bierhuizen, Katherine McCrum, Ellen Wengert",
    "abstract": "  We examine ProcessGPT, an AI model designed to automate, augment, and improve\nbusiness processes, to study the challenges of managing business processes\nwithin the cognitive limitations of the human workforce, particularly\nindividuals with cognitive disabilities. ProcessGPT provides a blueprint for\ndesigning efficient business processes that take into account human cognitive\nlimitations. By viewing this through the lens of cognitive disabilities, we\nshow that ProcessGPT improves process usability for individuals with and\nwithout cognitive disabilities. We also demonstrate that organizations\nimplementing ProcessGPT-like capabilities will realize increased productivity,\nmorale, and inclusion.\n",
    "link": "http://arxiv.org/abs/2401.06375v1"
  },
  {
    "title": "Graph Relation Distillation for Efficient Biomedical Instance\n  Segmentation",
    "authors": "Xiaoyu Liu, Yueyi Zhang, Zhiwei Xiong, Wei Huang, Bo Hu, Xiaoyan Sun, Feng Wu",
    "abstract": "  Instance-aware embeddings predicted by deep neural networks have\nrevolutionized biomedical instance segmentation, but its resource requirements\nare substantial. Knowledge distillation offers a solution by transferring\ndistilled knowledge from heavy teacher networks to lightweight yet\nhigh-performance student networks. However, existing knowledge distillation\nmethods struggle to extract knowledge for distinguishing instances and overlook\nglobal relation information. To address these challenges, we propose a graph\nrelation distillation approach for efficient biomedical instance segmentation,\nwhich considers three essential types of knowledge: instance-level features,\ninstance relations, and pixel-level boundaries. We introduce two graph\ndistillation schemes deployed at both the intra-image level and the inter-image\nlevel: instance graph distillation (IGD) and affinity graph distillation (AGD).\nIGD constructs a graph representing instance features and relations,\ntransferring these two types of knowledge by enforcing instance graph\nconsistency. AGD constructs an affinity graph representing pixel relations to\ncapture structured knowledge of instance boundaries, transferring\nboundary-related knowledge by ensuring pixel affinity consistency. Experimental\nresults on a number of biomedical datasets validate the effectiveness of our\napproach, enabling student models with less than $ 1\\%$ parameters and less\nthan $10\\%$ inference time while achieving promising performance compared to\nteacher models.\n",
    "link": "http://arxiv.org/abs/2401.06370v1"
  },
  {
    "title": "A Temporal-Spectral Fusion Transformer with Subject-specific Adapter for\n  Enhancing RSVP-BCI Decoding",
    "authors": "Xujin Li, Wei Wei, Shuang Qiu, Huiguang He",
    "abstract": "  The Rapid Serial Visual Presentation (RSVP)-based Brain-Computer Interface\n(BCI) is an efficient technology for target retrieval using\nelectroencephalography (EEG) signals. The performance improvement of\ntraditional decoding methods relies on a substantial amount of training data\nfrom new test subjects, which increases preparation time for BCI systems.\nSeveral studies introduce data from existing subjects to reduce the dependence\nof performance improvement on data from new subjects, but their optimization\nstrategy based on adversarial learning with extensive data increases training\ntime during the preparation procedure. Moreover, most previous methods only\nfocus on the single-view information of EEG signals, but ignore the information\nfrom other views which may further improve performance. To enhance decoding\nperformance while reducing preparation time, we propose a Temporal-Spectral\nfusion transformer with Subject-specific Adapter (TSformer-SA). Specifically, a\ncross-view interaction module is proposed to facilitate information transfer\nand extract common representations across two-view features extracted from EEG\ntemporal signals and spectrogram images. Then, an attention-based fusion module\nfuses the features of two views to obtain comprehensive discriminative features\nfor classification. Furthermore, a multi-view consistency loss is proposed to\nmaximize the feature similarity between two views of the same EEG signal.\nFinally, we propose a subject-specific adapter to rapidly transfer the\nknowledge of the model trained on data from existing subjects to decode data\nfrom new subjects. Experimental results show that TSformer-SA significantly\noutperforms comparison methods and achieves outstanding performance with\nlimited training data from new subjects. This facilitates efficient decoding\nand rapid deployment of BCI systems in practical use.\n",
    "link": "http://arxiv.org/abs/2401.06340v1"
  },
  {
    "title": "Striking a Balance in Fairness for Dynamic Systems Through Reinforcement\n  Learning",
    "authors": "Yaowei Hu, Jacob Lear, Lu Zhang",
    "abstract": "  While significant advancements have been made in the field of fair machine\nlearning, the majority of studies focus on scenarios where the decision model\noperates on a static population. In this paper, we study fairness in dynamic\nsystems where sequential decisions are made. Each decision may shift the\nunderlying distribution of features or user behavior. We model the dynamic\nsystem through a Markov Decision Process (MDP). By acknowledging that\ntraditional fairness notions and long-term fairness are distinct requirements\nthat may not necessarily align with one another, we propose an algorithmic\nframework to integrate various fairness considerations with reinforcement\nlearning using both pre-processing and in-processing approaches. Three case\nstudies show that our method can strike a balance between traditional fairness\nnotions, long-term fairness, and utility.\n",
    "link": "http://arxiv.org/abs/2401.06318v1"
  },
  {
    "title": "A Semantic-Aware Multiple Access Scheme for Distributed, Dynamic\n  6G-Based Applications",
    "authors": "Hamidreza Mazandarani, Masoud Shokrnezhad, Tarik Taleb",
    "abstract": "  The emergence of the semantic-aware paradigm presents opportunities for\ninnovative services, especially in the context of 6G-based applications.\nAlthough significant progress has been made in semantic extraction techniques,\nthe incorporation of semantic information into resource allocation\ndecision-making is still in its early stages, lacking consideration of the\nrequirements and characteristics of future systems. In response, this paper\nintroduces a novel formulation for the problem of multiple access to the\nwireless spectrum. It aims to optimize the utilization-fairness trade-off,\nusing the $\\alpha$-fairness metric, while accounting for user data correlation\nby introducing the concepts of self- and assisted throughputs. Initially, the\nproblem is analyzed to identify its optimal solution. Subsequently, a\nSemantic-Aware Multi-Agent Double and Dueling Deep Q-Learning (SAMA-D3QL)\ntechnique is proposed. This method is grounded in Model-free Multi-Agent Deep\nReinforcement Learning (MADRL), enabling the user equipment to autonomously\nmake decisions regarding wireless spectrum access based solely on their local\nindividual observations. The efficiency of the proposed technique is evaluated\nthrough two scenarios: single-channel and multi-channel. The findings\nillustrate that, across a spectrum of $\\alpha$ values, association matrices,\nand channels, SAMA-D3QL consistently outperforms alternative approaches. This\nestablishes it as a promising candidate for facilitating the realization of\nfuture federated, dynamically evolving applications.\n",
    "link": "http://arxiv.org/abs/2401.06308v1"
  }
]