[
  {
    "title": "Health Text Simplification: An Annotated Corpus for Digestive Cancer\n  Education and Novel Strategies for Reinforcement Learning",
    "authors": "Md Mushfiqur Rahman, Mohammad Sabik Irbaz, Kai North, Michelle S. Williams, Marcos Zampieri, Kevin Lybarger",
    "abstract": "  Objective: The reading level of health educational materials significantly\ninfluences information understandability and accessibility, particularly for\nminoritized populations. Many patient educational resources surpass the reading\nlevel and complexity of widely accepted standards. There is a critical need for\nhigh-performing text simplification models in health information to enhance\ndissemination and literacy. This need is particularly acute in cancer\neducation, where effective prevention and screening education can substantially\nreduce morbidity and mortality.\n  Methods: We introduce Simplified Digestive Cancer (SimpleDC), a parallel\ncorpus of cancer education materials tailored for health text simplification\nresearch. Utilizing SimpleDC alongside the existing Med-EASi corpus, we explore\nLarge Language Model (LLM)-based simplification methods, including fine-tuning,\nreinforcement learning (RL), reinforcement learning with human feedback (RLHF),\ndomain adaptation, and prompt-based approaches. Our experimentation encompasses\nLlama 2 and GPT-4. A novel RLHF reward function is introduced, featuring a\nlightweight model adept at distinguishing between original and simplified\ntexts, thereby enhancing the model's effectiveness with unlabeled data.\n  Results: Fine-tuned Llama 2 models demonstrated high performance across\nvarious metrics. Our innovative RLHF reward function surpassed existing RL text\nsimplification reward functions in effectiveness. The results underscore that\nRL/RLHF can augment fine-tuning, facilitating model training on unlabeled text\nand improving performance. Additionally, these methods effectively adapt\nout-of-domain text simplification models to targeted domains.\n",
    "link": "http://arxiv.org/abs/2401.15043v1"
  },
  {
    "title": "Turn-taking and Backchannel Prediction with Acoustic and Large Language\n  Model Fusion",
    "authors": "Jinhan Wang, Long Chen, Aparna Khare, Anirudh Raju, Pranav Dheram, Di He, Minhua Wu, Andreas Stolcke, Venkatesh Ravichandran",
    "abstract": "  We propose an approach for continuous prediction of turn-taking and\nbackchanneling locations in spoken dialogue by fusing a neural acoustic model\nwith a large language model (LLM). Experiments on the Switchboard human-human\nconversation dataset demonstrate that our approach consistently outperforms the\nbaseline models with single modality. We also develop a novel multi-task\ninstruction fine-tuning strategy to further benefit from LLM-encoded knowledge\nfor understanding the tasks and conversational contexts, leading to additional\nimprovements. Our approach demonstrates the potential of combined LLMs and\nacoustic models for a more natural and conversational interaction between\nhumans and speech-enabled AI agents.\n",
    "link": "http://arxiv.org/abs/2401.14717v1"
  }
]