[
  {
    "title": "KADEL: Knowledge-Aware Denoising Learning for Commit Message Generation",
    "authors": "Wei Tao, Yucheng Zhou, Yanlin Wang, Hongyu Zhang, Haofen Wang, Wenqiang Zhang",
    "abstract": "  Commit messages are natural language descriptions of code changes, which are\nimportant for software evolution such as code understanding and maintenance.\nHowever, previous methods are trained on the entire dataset without considering\nthe fact that a portion of commit messages adhere to good practice (i.e.,\ngood-practice commits), while the rest do not. On the basis of our empirical\nstudy, we discover that training on good-practice commits significantly\ncontributes to the commit message generation. Motivated by this finding, we\npropose a novel knowledge-aware denoising learning method called KADEL.\nConsidering that good-practice commits constitute only a small proportion of\nthe dataset, we align the remaining training samples with these good-practice\ncommits. To achieve this, we propose a model that learns the commit knowledge\nby training on good-practice commits. This knowledge model enables\nsupplementing more information for training samples that do not conform to good\npractice. However, since the supplementary information may contain noise or\nprediction errors, we propose a dynamic denoising training method. This method\ncomposes a distribution-aware confidence function and a dynamic distribution\nlist, which enhances the effectiveness of the training process. Experimental\nresults on the whole MCMD dataset demonstrate that our method overall achieves\nstate-of-the-art performance compared with previous methods. Our source code\nand data are available at https://github.com/DeepSoftwareAnalytics/KADEL\n",
    "link": "http://arxiv.org/abs/2401.08376v1"
  },
  {
    "title": "Hallucination Detection and Hallucination Mitigation: An Investigation",
    "authors": "Junliang Luo, Tianyu Li, Di Wu, Michael Jenkin, Steve Liu, Gregory Dudek",
    "abstract": "  Large language models (LLMs), including ChatGPT, Bard, and Llama, have\nachieved remarkable successes over the last two years in a range of different\napplications. In spite of these successes, there exist concerns that limit the\nwide application of LLMs. A key problem is the problem of hallucination.\nHallucination refers to the fact that in addition to correct responses, LLMs\ncan also generate seemingly correct but factually incorrect responses. This\nreport aims to present a comprehensive review of the current literature on both\nhallucination detection and hallucination mitigation. We hope that this report\ncan serve as a good reference for both engineers and researchers who are\ninterested in LLMs and applying them to real world tasks.\n",
    "link": "http://arxiv.org/abs/2401.08358v1"
  },
  {
    "title": "Boosting Gradient Ascent for Continuous DR-submodular Maximization",
    "authors": "Qixin Zhang, Zongqi Wan, Zengde Deng, Zaiyi Chen, Xiaoming Sun, Jialin Zhang, Yu Yang",
    "abstract": "  Projected Gradient Ascent (PGA) is the most commonly used optimization scheme\nin machine learning and operations research areas. Nevertheless, numerous\nstudies and examples have shown that the PGA methods may fail to achieve the\ntight approximation ratio for continuous DR-submodular maximization problems.\nTo address this challenge, we present a boosting technique in this paper, which\ncan efficiently improve the approximation guarantee of the standard PGA to\n\\emph{optimal} with only small modifications on the objective function. The\nfundamental idea of our boosting technique is to exploit non-oblivious search\nto derive a novel auxiliary function $F$, whose stationary points are excellent\napproximations to the global maximum of the original DR-submodular objective\n$f$. Specifically, when $f$ is monotone and $\\gamma$-weakly DR-submodular, we\npropose an auxiliary function $F$ whose stationary points can provide a better\n$(1-e^{-\\gamma})$-approximation than the\n$(\\gamma^2/(1+\\gamma^2))$-approximation guaranteed by the stationary points of\n$f$ itself. Similarly, for the non-monotone case, we devise another auxiliary\nfunction $F$ whose stationary points can achieve an optimal\n$\\frac{1-\\min_{\\boldsymbol{x}\\in\\mathcal{C}}\\|\\boldsymbol{x}\\|_{\\infty}}{4}$-approximation\nguarantee where $\\mathcal{C}$ is a convex constraint set. In contrast, the\nstationary points of the original non-monotone DR-submodular function can be\narbitrarily bad~\\citep{chen2023continuous}. Furthermore, we demonstrate the\nscalability of our boosting technique on four problems. In all of these four\nproblems, our resulting variants of boosting PGA algorithm beat the previous\nstandard PGA in several aspects such as approximation ratio and efficiency.\nFinally, we corroborate our theoretical findings with numerical experiments,\nwhich demonstrate the effectiveness of our boosting PGA methods.\n",
    "link": "http://arxiv.org/abs/2401.08330v1"
  },
  {
    "title": "RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large\n  Language Models in Tool Learning",
    "authors": "Junjie Ye, Yilong Wu, Songyang Gao, Sixian Li, Guanyu Li, Xiaoran Fan, Qi Zhang, Tao Gui, Xuanjing Huang",
    "abstract": "  Tool learning has generated widespread interest as a vital means of\ninteraction between Large Language Models (LLMs) and the physical world.\nCurrent research predominantly emphasizes LLMs' capacity to utilize tools in\nwell-structured environments while overlooking their stability when confronted\nwith the inevitable noise of the real world. To bridge this gap, we introduce\nRoTBench, a multi-level benchmark for evaluating the robustness of LLMs in tool\nlearning. Specifically, we establish five external environments, each featuring\nvarying levels of noise (i.e., Clean, Slight, Medium, Heavy, and Union),\nproviding an in-depth analysis of the model's resilience across three critical\nphases: tool selection, parameter identification, and content filling.\nExperiments involving six widely-used models underscore the urgent necessity\nfor enhancing the robustness of LLMs in tool learning. For instance, the\nperformance of GPT-4 even drops significantly from 80.00 to 58.10 when there is\nno substantial change in manual accuracy. More surprisingly, the noise\ncorrection capability inherent in the GPT family paradoxically impedes its\nadaptability in the face of mild noise. In light of these findings, we propose\nRoTTuning, a strategy that enriches the diversity of training environments to\nbolster the robustness of LLMs in tool learning. The code and data are\navailable at https://github.com/Junjie-Ye/RoTBench.\n",
    "link": "http://arxiv.org/abs/2401.08326v1"
  },
  {
    "title": "Large Language Models are Null-Shot Learners",
    "authors": "Pittawat Taveekitworachai, Febri Abdullah, Ruck Thawonmas",
    "abstract": "  This paper presents null-shot prompting. Null-shot prompting exploits\nhallucination in large language models (LLMs) by instructing LLMs to utilize\ninformation from the \"Examples\" section that never exists within the provided\ncontext to perform a task. While reducing hallucination is crucial and\nnon-negligible for daily and critical uses of LLMs, we propose that in the\ncurrent landscape in which these LLMs still hallucinate, it is possible, in\nfact, to exploit hallucination to increase performance in performing tasks\ncompared to standard zero-shot prompting. Experiments with six LLMs show\nimprovements in performance across the majority of eight datasets, including\nreading comprehension, arithmetic reasoning, and closed-book question\nanswering. The observed inconsistency in increased relative performance across\nLLMs also potentially indicates a different degree of inherent hallucination in\neach model. These differences show that it is possible to utilize null-shot\nprompting as a way to detect degrees of hallucination in LLMs using existing\nbenchmarking datasets. We also perform ablation studies, including\nexperimenting with a modified version of null-shot prompting that incorporates\nideas from zero-shot chain-of-thought prompting, which shows different trends\nof results.\n",
    "link": "http://arxiv.org/abs/2401.08273v1"
  },
  {
    "title": "An Explainable Proxy Model for Multiabel Audio Segmentation",
    "authors": "Th\u00e9o Mariotte, Antonio Almud\u00e9var, Marie Tahon, Alsonfo Ortega",
    "abstract": "  Audio signal segmentation is a key task for automatic audio indexing. It\nconsists of detecting the boundaries of class-homogeneous segments in the\nsignal. In many applications, explainable AI is a vital process for\ntransparency of decision-making with machine learning. In this paper, we\npropose an explainable multilabel segmentation model that solves speech\nactivity (SAD), music (MD), noise (ND), and overlapped speech detection (OSD)\nsimultaneously. This proxy uses the non-negative matrix factorization (NMF) to\nmap the embedding used for the segmentation to the frequency domain.\nExperiments conducted on two datasets show similar performances as the\npre-trained black box model while showing strong explainability features.\nSpecifically, the frequency bins used for the decision can be easily identified\nat both the segment level (local explanations) and global level (class\nprototypes).\n",
    "link": "http://arxiv.org/abs/2401.08268v1"
  },
  {
    "title": "Probabilistically Robust Watermarking of Neural Networks",
    "authors": "Mikhail Pautov, Nikita Bogdanov, Stanislav Pyatkin, Oleg Rogov, Ivan Oseledets",
    "abstract": "  As deep learning (DL) models are widely and effectively used in Machine\nLearning as a Service (MLaaS) platforms, there is a rapidly growing interest in\nDL watermarking techniques that can be used to confirm the ownership of a\nparticular model. Unfortunately, these methods usually produce watermarks\nsusceptible to model stealing attacks. In our research, we introduce a novel\ntrigger set-based watermarking approach that demonstrates resilience against\nfunctionality stealing attacks, particularly those involving extraction and\ndistillation. Our approach does not require additional model training and can\nbe applied to any model architecture. The key idea of our method is to compute\nthe trigger set, which is transferable between the source model and the set of\nproxy models with a high probability. In our experimental study, we show that\nif the probability of the set being transferable is reasonably high, it can be\neffectively used for ownership verification of the stolen model. We evaluate\nour method on multiple benchmarks and show that our approach outperforms\ncurrent state-of-the-art watermarking techniques in all considered experimental\nsetups.\n",
    "link": "http://arxiv.org/abs/2401.08261v1"
  },
  {
    "title": "A Generative Adversarial Attack for Multilingual Text Classifiers",
    "authors": "Tom Roth, Inigo Jauregi Unanue, Alsharif Abuadbba, Massimo Piccardi",
    "abstract": "  Current adversarial attack algorithms, where an adversary changes a text to\nfool a victim model, have been repeatedly shown to be effective against text\nclassifiers. These attacks, however, generally assume that the victim model is\nmonolingual and cannot be used to target multilingual victim models, a\nsignificant limitation given the increased use of these models. For this\nreason, in this work we propose an approach to fine-tune a multilingual\nparaphrase model with an adversarial objective so that it becomes able to\ngenerate effective adversarial examples against multilingual classifiers. The\ntraining objective incorporates a set of pre-trained models to ensure text\nquality and language consistency of the generated text. In addition, all the\nmodels are suitably connected to the generator by vocabulary-mapping matrices,\nallowing for full end-to-end differentiability of the overall training\npipeline. The experimental validation over two multilingual datasets and five\nlanguages has shown the effectiveness of the proposed approach compared to\nexisting baselines, particularly in terms of query efficiency. We also provide\na detailed analysis of the generated attacks and discuss limitations and\nopportunities for future research.\n",
    "link": "http://arxiv.org/abs/2401.08255v1"
  },
  {
    "title": "Towards Causal Relationship in Indefinite Data: Baseline Model and New\n  Datasets",
    "authors": "Hang Chen, Xinyu Yang, Keqing Du",
    "abstract": "  Integrating deep learning and causal discovery has encouraged us to spot that\nlearning causal structures and representations in dialogue and video is full of\nchallenges. We defined These data forms as \"Indefinite Data\", characterized by\nmulti-structure data and multi-value representations. Unlike existing adaptable\ndata forms, Indefinite Data still faces gaps in datasets and methods. To\naddress the dataset gap, we release two high-quality datasets - Causalogue and\nCausaction, containing text dialogue samples and video action samples with\ncausal annotations respectively. Moreover, the method gap arises from the\ncoexistence of multi-structure data and multi-value representations, breaking\nthe assumptions of all current methods and rendering them infeasible on\nIndefinite Data. To this end, we propose a probabilistic framework as a\nbaseline, incorporating three designed highlights for this gap: 1) establishing\nCausation Condition of representations using the independence of noise terms\nunder non-fixed causal structures, 2) treating causal strength as a latent\nvariable and measuring the reconstruction loss in the correlation space, and 3)\nestimating the effects of latent confounders. These highpoints make the\nprobabilistic model capable of overcoming challenges brought by the coexistence\nof multi-structure data and multi-value representations and pave the way for\nthe extension of latent confounders. Comprehensive experiments have evaluated\nbaseline results of causal structures, causal representations, and confounding\ndisentanglement.\n",
    "link": "http://arxiv.org/abs/2401.08221v1"
  },
  {
    "title": "End-to-End Optimized Image Compression with the Frequency-Oriented\n  Transform",
    "authors": "Yuefeng Zhang, Kai Lin",
    "abstract": "  Image compression constitutes a significant challenge amidst the era of\ninformation explosion. Recent studies employing deep learning methods have\ndemonstrated the superior performance of learning-based image compression\nmethods over traditional codecs. However, an inherent challenge associated with\nthese methods lies in their lack of interpretability. Following an analysis of\nthe varying degrees of compression degradation across different frequency\nbands, we propose the end-to-end optimized image compression model facilitated\nby the frequency-oriented transform. The proposed end-to-end image compression\nmodel consists of four components: spatial sampling, frequency-oriented\ntransform, entropy estimation, and frequency-aware fusion. The\nfrequency-oriented transform separates the original image signal into distinct\nfrequency bands, aligning with the human-interpretable concept. Leveraging the\nnon-overlapping hypothesis, the model enables scalable coding through the\nselective transmission of arbitrary frequency components. Extensive experiments\nare conducted to demonstrate that our model outperforms all traditional codecs\nincluding next-generation standard H.266/VVC on MS-SSIM metric. Moreover,\nvisual analysis tasks (i.e., object detection and semantic segmentation) are\nconducted to verify the proposed compression method could preserve semantic\nfidelity besides signal-level precision.\n",
    "link": "http://arxiv.org/abs/2401.08194v1"
  },
  {
    "title": "PRewrite: Prompt Rewriting with Reinforcement Learning",
    "authors": "Weize Kong, Spurthi Amba Hombaiah, Mingyang Zhang, Qiaozhu Mei, Michael Bendersky",
    "abstract": "  Prompt engineering is critical for the development of LLM-based applications.\nHowever, it is usually done manually in a \"trial and error\" fashion. This\nmanual procedure can be time consuming, ineffective, and the generated prompts\nare, in a lot of cases, sub-optimal. Even for the prompts which seemingly work\nwell, there is always a lingering question: can the prompts be made better with\nfurther modifications?\n  To address these questions, in this paper, we investigate prompt engineering\nautomation. We consider a specific use case scenario in which developers/users\nhave drafted initial prompts, but lack the time/expertise to optimize them. We\npropose PRewrite, an automated tool to rewrite these drafts and to generate\nhighly effective new prompts. PRewrite is based on the Reinforcement Learning\n(RL) framework which allows for end-to-end optimization and our design allows\nthe RL search to happen in a large action space. The automated tool leverages\nmanually crafted prompts as starting points which makes the rewriting procedure\nmore guided and efficient. The generated prompts are human readable, and\nself-explanatory, unlike some of those in previous works. We conducted\nextensive experiments on diverse datasets and found that the prompts generated\nwith this new method not only outperform professionally crafted prompts, but\nalso prompts generated with other previously proposed methods.\n",
    "link": "http://arxiv.org/abs/2401.08189v1"
  },
  {
    "title": "DPAFNet:Dual Path Attention Fusion Network for Single Image Deraining",
    "authors": "Bingcai Wei",
    "abstract": "  Rainy weather will have a significant impact on the regular operation of the\nimaging system. Based on this premise, image rain removal has always been a\npopular branch of low-level visual tasks, especially methods using deep neural\nnetworks. However, most neural networks are but-branched, such as only using\nconvolutional neural networks or Transformers, which is unfavourable for the\nmultidimensional fusion of image features. In order to solve this problem, this\npaper proposes a dual-branch attention fusion network. Firstly, a two-branch\nnetwork structure is proposed. Secondly, an attention fusion module is proposed\nto selectively fuse the features extracted by the two branches rather than\nsimply adding them. Finally, complete ablation experiments and sufficient\ncomparison experiments prove the rationality and effectiveness of the proposed\nmethod.\n",
    "link": "http://arxiv.org/abs/2401.08185v1"
  },
  {
    "title": "LLMs for Test Input Generation for Semantic Caches",
    "authors": "Zafaryab Rasool, Scott Barnett, David Willie, Stefanus Kurniawan, Sherwin Balugo, Srikanth Thudumu, Mohamed Abdelrazek",
    "abstract": "  Large language models (LLMs) enable state-of-the-art semantic capabilities to\nbe added to software systems such as semantic search of unstructured documents\nand text generation. However, these models are computationally expensive. At\nscale, the cost of serving thousands of users increases massively affecting\nalso user experience. To address this problem, semantic caches are used to\ncheck for answers to similar queries (that may have been phrased differently)\nwithout hitting the LLM service. Due to the nature of these semantic cache\ntechniques that rely on query embeddings, there is a high chance of errors\nimpacting user confidence in the system. Adopting semantic cache techniques\nusually requires testing the effectiveness of a semantic cache (accurate cache\nhits and misses) which requires a labelled test set of similar queries and\nresponses which is often unavailable. In this paper, we present VaryGen, an\napproach for using LLMs for test input generation that produces similar\nquestions from unstructured text documents. Our novel approach uses the\nreasoning capabilities of LLMs to 1) adapt queries to the domain, 2) synthesise\nsubtle variations to queries, and 3) evaluate the synthesised test dataset. We\nevaluated our approach in the domain of a student question and answer system by\nqualitatively analysing 100 generated queries and result pairs, and conducting\nan empirical case study with an open source semantic cache. Our results show\nthat query pairs satisfy human expectations of similarity and our generated\ndata demonstrates failure cases of a semantic cache. Additionally, we also\nevaluate our approach on Qasper dataset. This work is an important first step\ninto test input generation for semantic applications and presents\nconsiderations for practitioners when calibrating a semantic cache.\n",
    "link": "http://arxiv.org/abs/2401.08138v1"
  },
  {
    "title": "CycLight: learning traffic signal cooperation with a cycle-level\n  strategy",
    "authors": "Gengyue Han, Xiaohan Liu, Xianyue Peng, Hao Wang, Yu Han",
    "abstract": "  This study introduces CycLight, a novel cycle-level deep reinforcement\nlearning (RL) approach for network-level adaptive traffic signal control\n(NATSC) systems. Unlike most traditional RL-based traffic controllers that\nfocus on step-by-step decision making, CycLight adopts a cycle-level strategy,\noptimizing cycle length and splits simultaneously using Parameterized Deep\nQ-Networks (PDQN) algorithm. This cycle-level approach effectively reduces the\ncomputational burden associated with frequent data communication, meanwhile\nenhancing the practicality and safety of real-world applications. A\ndecentralized framework is formulated for multi-agent cooperation, while\nattention mechanism is integrated to accurately assess the impact of the\nsurroundings on the current intersection. CycLight is tested in a large\nsynthetic traffic grid using the microscopic traffic simulation tool, SUMO.\nExperimental results not only demonstrate the superiority of CycLight over\nother state-of-the-art approaches but also showcase its robustness against\ninformation transmission delays.\n",
    "link": "http://arxiv.org/abs/2401.08121v1"
  },
  {
    "title": "E2HQV: High-Quality Video Generation from Event Camera via\n  Theory-Inspired Model-Aided Deep Learning",
    "authors": "Qiang Qu, Yiran Shen, Xiaoming Chen, Yuk Ying Chung, Tongliang Liu",
    "abstract": "  The bio-inspired event cameras or dynamic vision sensors are capable of\nasynchronously capturing per-pixel brightness changes (called event-streams) in\nhigh temporal resolution and high dynamic range. However, the non-structural\nspatial-temporal event-streams make it challenging for providing intuitive\nvisualization with rich semantic information for human vision. It calls for\nevents-to-video (E2V) solutions which take event-streams as input and generate\nhigh quality video frames for intuitive visualization. However, current\nsolutions are predominantly data-driven without considering the prior knowledge\nof the underlying statistics relating event-streams and video frames. It highly\nrelies on the non-linearity and generalization capability of the deep neural\nnetworks, thus, is struggling on reconstructing detailed textures when the\nscenes are complex. In this work, we propose \\textbf{E2HQV}, a novel E2V\nparadigm designed to produce high-quality video frames from events. This\napproach leverages a model-aided deep learning framework, underpinned by a\ntheory-inspired E2V model, which is meticulously derived from the fundamental\nimaging principles of event cameras. To deal with the issue of state-reset in\nthe recurrent components of E2HQV, we also design a temporal shift embedding\nmodule to further improve the quality of the video frames. Comprehensive\nevaluations on the real world event camera datasets validate our approach, with\nE2HQV, notably outperforming state-of-the-art approaches, e.g., surpassing the\nsecond best by over 40\\% for some evaluation metrics.\n",
    "link": "http://arxiv.org/abs/2401.08117v1"
  },
  {
    "title": "No-Clean-Reference Image Super-Resolution: Application to Electron\n  Microscopy",
    "authors": "Mohammad Khateri, Morteza Ghahremani, Alejandra Sierra, Jussi Tohka",
    "abstract": "  The inability to acquire clean high-resolution (HR) electron microscopy (EM)\nimages over a large brain tissue volume hampers many neuroscience studies. To\naddress this challenge, we propose a deep-learning-based image super-resolution\n(SR) approach to computationally reconstruct clean HR 3D-EM with a large field\nof view (FoV) from noisy low-resolution (LR) acquisition. Our contributions are\nI) Investigating training with no-clean references for $\\ell_2$ and $\\ell_1$\nloss functions; II) Introducing a novel network architecture, named EMSR, for\nenhancing the resolution of LR EM images while reducing inherent noise; and,\nIII) Comparing different training strategies including using acquired LR and HR\nimage pairs, i.e., real pairs with no-clean references contaminated with real\ncorruptions, the pairs of synthetic LR and acquired HR, as well as acquired LR\nand denoised HR pairs. Experiments with nine brain datasets showed that\ntraining with real pairs can produce high-quality super-resolved results,\ndemonstrating the feasibility of training with non-clean references for both\nloss functions. Additionally, comparable results were observed, both visually\nand numerically, when employing denoised and noisy references for training.\nMoreover, utilizing the network trained with synthetically generated LR images\nfrom HR counterparts proved effective in yielding satisfactory SR results, even\nin certain cases, outperforming training with real pairs. The proposed SR\nnetwork was compared quantitatively and qualitatively with several established\nSR techniques, showcasing either the superiority or competitiveness of the\nproposed method in mitigating noise while recovering fine details.\n",
    "link": "http://arxiv.org/abs/2401.08115v1"
  },
  {
    "title": "Hardware Acceleration for Real-Time Wildfire Detection Onboard Drone\n  Networks",
    "authors": "Austin Briley, Fatemeh Afghah",
    "abstract": "  Early wildfire detection in remote and forest areas is crucial for minimizing\ndevastation and preserving ecosystems. Autonomous drones offer agile access to\nremote, challenging terrains, equipped with advanced imaging technology that\ndelivers both high-temporal and detailed spatial resolution, making them\nvaluable assets in the early detection and monitoring of wildfires. However,\nthe limited computation and battery resources of Unmanned Aerial Vehicles\n(UAVs) pose significant challenges in implementing robust and efficient image\nclassification models. Current works in this domain often operate offline,\nemphasizing the need for solutions that can perform inference in real time,\ngiven the constraints of UAVs. To address these challenges, this paper aims to\ndevelop a real-time image classification and fire segmentation model. It\npresents a comprehensive investigation into hardware acceleration using the\nJetson Nano P3450 and the implications of TensorRT, NVIDIA's high-performance\ndeep-learning inference library, on fire classification accuracy and speed. The\nstudy includes implementations of Quantization Aware Training (QAT), Automatic\nMixed Precision (AMP), and post-training mechanisms, comparing them against the\nlatest baselines for fire segmentation and classification. All experiments\nutilize the FLAME dataset - an image dataset collected by low-altitude drones\nduring a prescribed forest fire. This work contributes to the ongoing efforts\nto enable real-time, on-board wildfire detection capabilities for UAVs,\naddressing speed and the computational and energy constraints of these crucial\nmonitoring systems. The results show a 13% increase in classification speed\ncompared to similar models without hardware optimization. Comparatively, loss\nand accuracy are within 1.225% of the original values.\n",
    "link": "http://arxiv.org/abs/2401.08105v1"
  },
  {
    "title": "Resolving Ethics Trade-offs in Implementing Responsible AI",
    "authors": "Conrad Sanderson, Emma Schleiger, David Douglas, Petra Kuhnert, Qinghua Lu",
    "abstract": "  While the operationalisation of high-level AI ethics principles into\npractical AI/ML systems has made progress, there is still a theory-practice gap\nin managing tensions between the underlying AI ethics aspects. We cover five\napproaches for addressing the tensions via trade-offs, ranging from rudimentary\nto complex. The approaches differ in the types of considered context, scope,\nmethods for measuring contexts, and degree of justification. None of the\napproaches is likely to be appropriate for all organisations, systems, or\napplications. To address this, we propose a framework which consists of: (i)\nproactive identification of tensions, (ii) prioritisation and weighting of\nethics aspects, (iii) justification and documentation of trade-off decisions.\nThe proposed framework aims to facilitate the implementation of well-rounded\nAI/ML systems that are appropriate for potential regulatory requirements.\n",
    "link": "http://arxiv.org/abs/2401.08103v1"
  },
  {
    "title": "KTVIC: A Vietnamese Image Captioning Dataset on the Life Domain",
    "authors": "Anh-Cuong Pham, Van-Quang Nguyen, Thi-Hong Vuong, Quang-Thuy Ha",
    "abstract": "  Image captioning is a crucial task with applications in a wide range of\ndomains, including healthcare and education. Despite extensive research on\nEnglish image captioning datasets, the availability of such datasets for\nVietnamese remains limited, with only two existing datasets. In this study, we\nintroduce KTVIC, a comprehensive Vietnamese Image Captioning dataset focused on\nthe life domain, covering a wide range of daily activities. This dataset\ncomprises 4,327 images and 21,635 Vietnamese captions, serving as a valuable\nresource for advancing image captioning in the Vietnamese language. We conduct\nexperiments using various deep neural networks as the baselines on our dataset,\nevaluating them using the standard image captioning metrics, including BLEU,\nMETEOR, CIDEr, and ROUGE. Our findings underscore the effectiveness of the\nproposed dataset and its potential contributions to the field of image\ncaptioning in the Vietnamese context.\n",
    "link": "http://arxiv.org/abs/2401.08100v1"
  },
  {
    "title": "Inpainting Normal Maps for Lightstage data",
    "authors": "Hancheng Zuo, Bernard Tiddeman",
    "abstract": "  This study introduces a novel method for inpainting normal maps using a\ngenerative adversarial network (GAN). Normal maps, often derived from a\nlightstage, are crucial in performance capture but can have obscured areas due\nto movement (e.g., by arms, hair, or props). Inpainting fills these missing\nareas with plausible data. Our approach extends previous general image\ninpainting techniques, employing a bow tie-like generator network and a\ndiscriminator network, with alternating training phases. The generator aims to\nsynthesize images aligning with the ground truth and deceive the discriminator,\nwhich differentiates between real and processed images. Periodically, the\ndiscriminator undergoes retraining to enhance its ability to identify processed\nimages. Importantly, our method adapts to the unique characteristics of normal\nmap data, necessitating modifications to the loss function. We utilize a cosine\nloss instead of mean squared error loss for generator training. Limited\ntraining data availability, even with synthetic datasets, demands significant\naugmentation, considering the specific nature of the input data. This includes\nappropriate image flipping and in-plane rotations to accurately alter normal\nvectors. Throughout training, we monitored key metrics such as average loss,\nStructural Similarity Index Measure (SSIM), and Peak Signal-to-Noise Ratio\n(PSNR) for the generator, along with average loss and accuracy for the\ndiscriminator. Our findings suggest that the proposed model effectively\ngenerates high-quality, realistic inpainted normal maps, suitable for\nperformance capture applications. These results establish a foundation for\nfuture research, potentially involving more advanced networks and comparisons\nwith inpainting of source images used to create the normal maps.\n",
    "link": "http://arxiv.org/abs/2401.08099v1"
  },
  {
    "title": "A Study of Fairness Concerns in AI-based Mobile App Reviews",
    "authors": "Ali Rezaei Nasab, Maedeh Dashti, Mojtaba Shahin, Mansooreh Zahedi, Hourieh Khalajzadeh, Chetan Arora, Peng Liang",
    "abstract": "  With the growing application of AI-based systems in our lives and society,\nthere is a rising need to ensure that AI-based systems are developed and used\nin a responsible way. Fairness is one of the socio-technical concerns that must\nbe addressed in AI-based systems for this purpose. Unfair AI-based systems,\nparticularly, unfair AI-based mobile apps, can pose difficulties for a\nsignificant proportion of the global populace. This paper aims to deeply\nanalyze fairness concerns in AI-based app reviews. We first manually\nconstructed a ground-truth dataset including a statistical sample of fairness\nand non-fairness reviews. Leveraging the ground-truth dataset, we then\ndeveloped and evaluated a set of machine learning and deep learning classifiers\nthat distinguish fairness reviews from non-fairness reviews. Our experiments\nshow that our best-performing classifier can detect fairness reviews with a\nprecision of 94%. We then applied the best-performing classifier on\napproximately 9.5M reviews collected from 108 AI-based apps and identified\naround 92K fairness reviews. While the fairness reviews appear in 23 app\ncategories, we found that the 'communication' and 'social' app categories have\nthe highest percentage of fairness reviews. Next, applying the K-means\nclustering technique to the 92K fairness reviews, followed by manual analysis,\nled to the identification of six distinct types of fairness concerns (e.g.,\n'receiving different quality of features and services in different platforms\nand devices' and 'lack of transparency and fairness in dealing with\nuser-generated content'). Finally, the manual analysis of 2,248 app owners'\nresponses to the fairness reviews identified six root causes (e.g., 'copyright\nissues', 'external factors', 'development cost') that app owners report to\njustify fairness concerns.\n",
    "link": "http://arxiv.org/abs/2401.08097v1"
  },
  {
    "title": "DurFlex-EVC: Duration-Flexible Emotional Voice Conversion with Parallel\n  Generation",
    "authors": "Hyoung-Seok Oh, Sang-Hoon Lee, Deok-Hyun Cho, Seong-Whan Lee",
    "abstract": "  Emotional voice conversion (EVC) seeks to modify the emotional tone of a\nspeaker's voice while preserving the original linguistic content and the\nspeaker's unique vocal characteristics. Recent advancements in EVC have\ninvolved the simultaneous modeling of pitch and duration, utilizing the\npotential of sequence-to-sequence (seq2seq) models. To enhance reliability and\nefficiency in conversion, this study shifts focus towards parallel speech\ngeneration. We introduce Duration-Flexible EVC (DurFlex-EVC), which integrates\na style autoencoder and unit aligner. Traditional models, while incorporating\nself-supervised learning (SSL) representations that contain both linguistic and\nparalinguistic information, have neglected this dual nature, leading to reduced\ncontrollability. Addressing this issue, we implement cross-attention to\nsynchronize these representations with various emotions. Additionally, a style\nautoencoder is developed for the disentanglement and manipulation of style\nelements. The efficacy of our approach is validated through both subjective and\nobjective evaluations, establishing its superiority over existing models in the\nfield.\n",
    "link": "http://arxiv.org/abs/2401.08095v1"
  },
  {
    "title": "A Survey of Resource-efficient LLM and Multimodal Foundation Models",
    "authors": "Mengwei Xu, Wangsong Yin, Dongqi Cai, Rongjie Yi, Daliang Xu, Qipeng Wang, Bingyang Wu, Yihao Zhao, Chen Yang, Shihe Wang, Qiyang Zhang, Zhenyan Lu, Li Zhang, Shangguang Wang, Yuanchun Li, Yunxin Liu, Xin Jin, Xuanzhe Liu",
    "abstract": "  Large foundation models, including large language models (LLMs), vision\ntransformers (ViTs), diffusion, and LLM-based multimodal models, are\nrevolutionizing the entire machine learning lifecycle, from training to\ndeployment. However, the substantial advancements in versatility and\nperformance these models offer come at a significant cost in terms of hardware\nresources. To support the growth of these large models in a scalable and\nenvironmentally sustainable way, there has been a considerable focus on\ndeveloping resource-efficient strategies. This survey delves into the critical\nimportance of such research, examining both algorithmic and systemic aspects.\nIt offers a comprehensive analysis and valuable insights gleaned from existing\nliterature, encompassing a broad array of topics from cutting-edge model\narchitectures and training/serving algorithms to practical system designs and\nimplementations. The goal of this survey is to provide an overarching\nunderstanding of how current approaches are tackling the resource challenges\nposed by large foundation models and to potentially inspire future\nbreakthroughs in this field.\n",
    "link": "http://arxiv.org/abs/2401.08092v1"
  },
  {
    "title": "A Study on Training and Developing Large Language Models for Behavior\n  Tree Generation",
    "authors": "Fu Li, Xueying Wang, Bin Li, Yunlong Wu, Yanzhen Wang, Xiaodong Yi",
    "abstract": "  This paper presents an innovative exploration of the application potential of\nlarge language models (LLM) in addressing the challenging task of automatically\ngenerating behavior trees (BTs) for complex tasks. The conventional manual BT\ngeneration method is inefficient and heavily reliant on domain expertise. On\nthe other hand, existing automatic BT generation technologies encounter\nbottlenecks related to task complexity, model adaptability, and reliability. In\norder to overcome these challenges, we propose a novel methodology that\nleverages the robust representation and reasoning abilities of LLMs. The core\ncontribution of this paper lies in the design of a BT generation framework\nbased on LLM, which encompasses the entire process, from data synthesis and\nmodel training to application developing and data verification. Synthetic data\nis introduced to train the BT generation model (BTGen model), enhancing its\nunderstanding and adaptability to various complex tasks, thereby significantly\nimproving its overall performance. In order to ensure the effectiveness and\nexecutability of the generated BTs, we emphasize the importance of data\nverification and introduce a multilevel verification strategy. Additionally, we\nexplore a range of agent design and development schemes with LLM as the central\nelement. We hope that the work in this paper may provide a reference for the\nresearchers who are interested in BT generation based on LLMs.\n",
    "link": "http://arxiv.org/abs/2401.08089v1"
  },
  {
    "title": "Transformer-based approach for Ethereum Price Prediction Using\n  Crosscurrency correlation and Sentiment Analysis",
    "authors": "Shubham Singh, Mayur Bhat",
    "abstract": "  The research delves into the capabilities of a transformer-based neural\nnetwork for Ethereum cryptocurrency price forecasting. The experiment runs\naround the hypothesis that cryptocurrency prices are strongly correlated with\nother cryptocurrencies and the sentiments around the cryptocurrency. The model\nemploys a transformer architecture for several setups from single-feature\nscenarios to complex configurations incorporating volume, sentiment, and\ncorrelated cryptocurrency prices. Despite a smaller dataset and less complex\narchitecture, the transformer model surpasses ANN and MLP counterparts on some\nparameters. The conclusion presents a hypothesis on the illusion of causality\nin cryptocurrency price movements driven by sentiments.\n",
    "link": "http://arxiv.org/abs/2401.08077v1"
  },
  {
    "title": "Achieve Fairness without Demographics for Dermatological Disease\n  Diagnosis",
    "authors": "Ching-Hao Chiu, Yu-Jen Chen, Yawen Wu, Yiyu Shi, Tsung-Yi Ho",
    "abstract": "  In medical image diagnosis, fairness has become increasingly crucial. Without\nbias mitigation, deploying unfair AI would harm the interests of the\nunderprivileged population and potentially tear society apart. Recent research\naddresses prediction biases in deep learning models concerning demographic\ngroups (e.g., gender, age, and race) by utilizing demographic (sensitive\nattribute) information during training. However, many sensitive attributes\nnaturally exist in dermatological disease images. If the trained model only\ntargets fairness for a specific attribute, it remains unfair for other\nattributes. Moreover, training a model that can accommodate multiple sensitive\nattributes is impractical due to privacy concerns. To overcome this, we propose\na method enabling fair predictions for sensitive attributes during the testing\nphase without using such information during training. Inspired by prior work\nhighlighting the impact of feature entanglement on fairness, we enhance the\nmodel features by capturing the features related to the sensitive and target\nattributes and regularizing the feature entanglement between corresponding\nclasses. This ensures that the model can only classify based on the features\nrelated to the target attribute without relying on features associated with\nsensitive attributes, thereby improving fairness and accuracy. Additionally, we\nuse disease masks from the Segment Anything Model (SAM) to enhance the quality\nof the learned feature. Experimental results demonstrate that the proposed\nmethod can improve fairness in classification compared to state-of-the-art\nmethods in two dermatological disease datasets.\n",
    "link": "http://arxiv.org/abs/2401.08066v1"
  },
  {
    "title": "Enhancing Robustness of LLM-Synthetic Text Detectors for Academic\n  Writing: A Comprehensive Analysis",
    "authors": "Zhicheng Dou, Yuchen Guo, Ching-Chun Chang, Huy H. Nguyen, Isao Echizen",
    "abstract": "  The emergence of large language models (LLMs), such as Generative Pre-trained\nTransformer 4 (GPT-4) used by ChatGPT, has profoundly impacted the academic and\nbroader community. While these models offer numerous advantages in terms of\nrevolutionizing work and study methods, they have also garnered significant\nattention due to their potential negative consequences. One example is\ngenerating academic reports or papers with little to no human contribution.\nConsequently, researchers have focused on developing detectors to address the\nmisuse of LLMs. However, most existing methods prioritize achieving higher\naccuracy on restricted datasets, neglecting the crucial aspect of\ngeneralizability. This limitation hinders their practical application in\nreal-life scenarios where reliability is paramount. In this paper, we present a\ncomprehensive analysis of the impact of prompts on the text generated by LLMs\nand highlight the potential lack of robustness in one of the current\nstate-of-the-art GPT detectors. To mitigate these issues concerning the misuse\nof LLMs in academic writing, we propose a reference-based Siamese detector\nnamed Synthetic-Siamese which takes a pair of texts, one as the inquiry and the\nother as the reference. Our method effectively addresses the lack of robustness\nof previous detectors (OpenAI detector and DetectGPT) and significantly\nimproves the baseline performances in realistic academic writing scenarios by\napproximately 67% to 95%.\n",
    "link": "http://arxiv.org/abs/2401.08046v1"
  },
  {
    "title": "Self-Imagine: Effective Unimodal Reasoning with Multimodal Models using\n  Self-Imagination",
    "authors": "Syeda Nahida Akter, Aman Madaan, Sangwu Lee, Yiming Yang, Eric Nyberg",
    "abstract": "  The potential of Vision-Language Models (\\textsc{vlm}s) often remains\nunderutilized in handling complex text-based problems, particularly when these\nproblems could benefit from visual representation. Resonating with humans'\nability to solve complex text-based problems by (1) creating a visual diagram\nfrom the problem and (2) deducing what steps they need to take to solve it, we\npropose \\textsc{Self-Imagine}. We leverage a single Vision-Language Model\n(\\textsc{vlm}) to generate a structured representation of the question using\nHTML, then render the HTML as an image, and finally use the same \\vlm to answer\nthe question using both the question and the image. Our approach does not\nrequire any additional training data or training. We evaluate our approach in\nthree mathematics tasks and nine general-purpose reasoning tasks using\nstate-of-the-art \\textsc{vlm}. Our approach boosts the performance of\n\\textsc{vlm} on all math tasks (\\gsm: +4.62\\%; \\asdiv: +4.49\\%; \\svamp:\n+9.30\\%) and the majority of the general-purpose reasoning tasks by 0.4\\% to\n13.20\\% while achieving comparable performance in other tasks.\n  Code and data at https://github.com/snat1505027/self-imagine .\n",
    "link": "http://arxiv.org/abs/2401.08025v1"
  }
]