[
  {
    "title": "Weaver: Foundation Models for Creative Writing",
    "authors": "Tiannan Wang, Jiamin Chen, Qingrui Jia, Shuai Wang, Ruoyu Fang, Huilin Wang, Zhaowei Gao, Chunzhao Xie, Chuou Xu, Jihong Dai, Yibin Liu, Jialong Wu, Shengwei Ding, Long Li, Zhiwei Huang, Xinle Deng, Teng Yu, Gangan Ma, Han Xiao, Zixin Chen, Danjun Xiang, Yunxia Wang, Yuanyuan Zhu, Yi Xiao, Jing Wang, Yiru Wang, Siran Ding, Jiayang Huang, Jiayi Xu, Yilihamu Tayier, Zhenyu Hu, Yuan Gao, Chengfeng Zheng, Yueshu Ye, Yihang Li, Lei Wan, Xinyue Jiang, Yujie Wang, Siyu Cheng, Zhule Song, Xiangru Tang, Xiaohua Xu, Ningyu Zhang, Huajun Chen, Yuchen Eleanor Jiang, Wangchunshu Zhou",
    "abstract": "  This work introduces Weaver, our first family of large language models (LLMs)\ndedicated to content creation. Weaver is pre-trained on a carefully selected\ncorpus that focuses on improving the writing capabilities of large language\nmodels. We then fine-tune Weaver for creative and professional writing purposes\nand align it to the preference of professional writers using a suit of novel\nmethods for instruction data synthesis and LLM alignment, making it able to\nproduce more human-like texts and follow more diverse instructions for content\ncreation. The Weaver family consists of models of Weaver Mini (1.8B), Weaver\nBase (6B), Weaver Pro (14B), and Weaver Ultra (34B) sizes, suitable for\ndifferent applications and can be dynamically dispatched by a routing agent\naccording to query complexity to balance response quality and computation cost.\nEvaluation on a carefully curated benchmark for assessing the writing\ncapabilities of LLMs shows Weaver models of all sizes outperform generalist\nLLMs several times larger than them. Notably, our most-capable Weaver Ultra\nmodel surpasses GPT-4, a state-of-the-art generalist LLM, on various writing\nscenarios, demonstrating the advantage of training specialized LLMs for writing\npurposes. Moreover, Weaver natively supports retrieval-augmented generation\n(RAG) and function calling (tool usage). We present various use cases of these\nabilities for improving AI-assisted writing systems, including integration of\nexternal knowledge bases, tools, or APIs, and providing personalized writing\nassistance. Furthermore, we discuss and summarize a guideline and best\npractices for pre-training and fine-tuning domain-specific LLMs.\n",
    "link": "http://arxiv.org/abs/2401.17268v1"
  },
  {
    "title": "Proactive Detection of Voice Cloning with Localized Watermarking",
    "authors": "Robin San Roman, Pierre Fernandez, Alexandre D\u00e9fossez, Teddy Furon, Tuan Tran, Hady Elsahar",
    "abstract": "  In the rapidly evolving field of speech generative models, there is a\npressing need to ensure audio authenticity against the risks of voice cloning.\nWe present AudioSeal, the first audio watermarking technique designed\nspecifically for localized detection of AI-generated speech. AudioSeal employs\na generator/detector architecture trained jointly with a localization loss to\nenable localized watermark detection up to the sample level, and a novel\nperceptual loss inspired by auditory masking, that enables AudioSeal to achieve\nbetter imperceptibility. AudioSeal achieves state-of-the-art performance in\nterms of robustness to real life audio manipulations and imperceptibility based\non automatic and human evaluation metrics. Additionally, AudioSeal is designed\nwith a fast, single-pass detector, that significantly surpasses existing models\nin speed - achieving detection up to two orders of magnitude faster, making it\nideal for large-scale and real-time applications.\n",
    "link": "http://arxiv.org/abs/2401.17264v1"
  },
  {
    "title": "Robust Prompt Optimization for Defending Language Models Against\n  Jailbreaking Attacks",
    "authors": "Andy Zhou, Bo Li, Haohan Wang",
    "abstract": "  Despite advances in AI alignment, language models (LM) remain vulnerable to\nadversarial attacks or jailbreaking, in which adversaries modify input prompts\nto induce harmful behavior. While some defenses have been proposed, they focus\non narrow threat models and fall short of a strong defense, which we posit\nshould be effective, universal, and practical. To achieve this, we propose the\nfirst adversarial objective for defending LMs against jailbreaking attacks and\nan algorithm, robust prompt optimization (RPO), that uses gradient-based token\noptimization to enforce harmless outputs. This results in an easily accessible\nsuffix that significantly improves robustness to both jailbreaks seen during\noptimization and unknown, held-out jailbreaks, reducing the attack success rate\non Starling-7B from 84% to 8.66% across 20 jailbreaks. In addition, we find\nthat RPO has a minor effect on normal LM use, is successful under adaptive\nattacks, and can transfer to black-box models, reducing the success rate of the\nstrongest attack on GPT-4 from 92% to 6%.\n",
    "link": "http://arxiv.org/abs/2401.17263v1"
  },
  {
    "title": "LLaMP: Large Language Model Made Powerful for High-fidelity Materials\n  Knowledge Retrieval and Distillation",
    "authors": "Yuan Chiang, Chia-Hong Chou, Janosh Riebesell",
    "abstract": "  Reducing hallucination of Large Language Models (LLMs) is imperative for use\nin the sciences where reproducibility is crucial. However, LLMs inherently lack\nlong-term memory, making it a nontrivial, ad hoc, and inevitably biased task to\nfine-tune them on domain-specific literature and data. Here we introduce LLaMP,\na multimodal retrieval-augmented generation (RAG) framework of multiple\ndata-aware reasoning-and-acting (ReAct) agents that dynamically interact with\ncomputational and experimental data on Materials Project (MP). Without\nfine-tuning, LLaMP demonstrates an ability to comprehend and integrate various\nmodalities of materials science concepts, fetch relevant data stores on the\nfly, process higher-order data (such as crystal structures and elastic\ntensors), and summarize multi-step procedures for solid-state synthesis. We\nshow that LLaMP effectively corrects errors in GPT-3.5's intrinsic knowledge,\nreducing a 5.21% MAPE on frequently-documented bandgaps and a significant\n1103.54% MAPE on formation energies -- errors that GPT-3.5 seems to derive from\nmixed data sources. Additionally, LLaMP substantially reduces the hallucinated\nvolumetric strain in a diamond cubic silicon structure from 66.3% to 0. The\nproposed framework offers an intuitive and nearly hallucination-free approach\nto exploring materials informatics and establishes a pathway for knowledge\ndistillation and fine-tuning other language models. We envision the framework\nas a valuable component for scientific hypotheses and a foundation for future\nautonomous laboratories where multiple LLM agents communicate and cooperate\nwith robotics to drive material synthesis and chemical reactions without\nhard-coded human logic and intervention.\n",
    "link": "http://arxiv.org/abs/2401.17244v1"
  },
  {
    "title": "ESPnet-SPK: full pipeline speaker embedding toolkit with reproducible\n  recipes, self-supervised front-ends, and off-the-shelf models",
    "authors": "Jee-weon Jung, Wangyou Zhang, Jiatong Shi, Zakaria Aldeneh, Takuya Higuchi, Barry-John Theobald, Ahmed Hussen Abdelaziz, Shinji Watanabe",
    "abstract": "  This paper introduces ESPnet-SPK, a toolkit designed with several objectives\nfor training speaker embedding extractors. First, we provide an open-source\nplatform for researchers in the speaker recognition community to effortlessly\nbuild models. We provide several models, ranging from x-vector to recent\nSKA-TDNN. Through the modularized architecture design, variants can be\ndeveloped easily. We also aspire to bridge developed models with other domains,\nfacilitating the broad research community to effortlessly incorporate\nstate-of-the-art embedding extractors. Pre-trained embedding extractors can be\naccessed in an off-the-shelf manner and we demonstrate the toolkit's\nversatility by showcasing its integration with two tasks. Another goal is to\nintegrate with diverse self-supervised learning features. We release a\nreproducible recipe that achieves an equal error rate of 0.39% on the Vox1-O\nevaluation protocol using WavLM-Large with ECAPA-TDNN.\n",
    "link": "http://arxiv.org/abs/2401.17230v1"
  },
  {
    "title": "MouSi: Poly-Visual-Expert Vision-Language Models",
    "authors": "Xiaoran Fan, Tao Ji, Changhao Jiang, Shuo Li, Senjie Jin, Sirui Song, Junke Wang, Boyang Hong, Lu Chen, Guodong Zheng, Ming Zhang, Caishuang Huang, Rui Zheng, Zhiheng Xi, Yuhao Zhou, Shihan Dou, Junjie Ye, Hang Yan, Tao Gui, Qi Zhang, Xipeng Qiu, Xuanjing Huang, Zuxuan Wu, Yu-Gang Jiang",
    "abstract": "  Current large vision-language models (VLMs) often encounter challenges such\nas insufficient capabilities of a single visual component and excessively long\nvisual tokens. These issues can limit the model's effectiveness in accurately\ninterpreting complex visual information and over-lengthy contextual\ninformation. Addressing these challenges is crucial for enhancing the\nperformance and applicability of VLMs. This paper proposes the use of ensemble\nexperts technique to synergizes the capabilities of individual visual encoders,\nincluding those skilled in image-text matching, OCR, image segmentation, etc.\nThis technique introduces a fusion network to unify the processing of outputs\nfrom different visual experts, while bridging the gap between image encoders\nand pre-trained LLMs. In addition, we explore different positional encoding\nschemes to alleviate the waste of positional encoding caused by lengthy image\nfeature sequences, effectively addressing the issue of position overflow and\nlength limitations. For instance, in our implementation, this technique\nsignificantly reduces the positional occupancy in models like SAM, from a\nsubstantial 4096 to a more efficient and manageable 64 or even down to 1.\nExperimental results demonstrate that VLMs with multiple experts exhibit\nconsistently superior performance over isolated visual encoders and mark a\nsignificant performance boost as more experts are integrated. We have\nopen-sourced the training code used in this report. All of these resources can\nbe found on our project website.\n",
    "link": "http://arxiv.org/abs/2401.17221v1"
  },
  {
    "title": "NormEnsembleXAI: Unveiling the Strengths and Weaknesses of XAI Ensemble\n  Techniques",
    "authors": "Weronika Hryniewska-Guzik, Bartosz Sawicki, Przemys\u0142aw Biecek",
    "abstract": "  This paper presents a comprehensive comparative analysis of explainable\nartificial intelligence (XAI) ensembling methods. Our research brings three\nsignificant contributions. Firstly, we introduce a novel ensembling method,\nNormEnsembleXAI, that leverages minimum, maximum, and average functions in\nconjunction with normalization techniques to enhance interpretability.\nSecondly, we offer insights into the strengths and weaknesses of XAI ensemble\nmethods. Lastly, we provide a library, facilitating the practical\nimplementation of XAI ensembling, thus promoting the adoption of transparent\nand interpretable deep learning models.\n",
    "link": "http://arxiv.org/abs/2401.17200v1"
  },
  {
    "title": "Nested Construction of Polar Codes via Transformers",
    "authors": "Sravan Kumar Ankireddy, S Ashwin Hebbar, Heping Wan, Joonyoung Cho, Charlie Zhang",
    "abstract": "  Tailoring polar code construction for decoding algorithms beyond successive\ncancellation has remained a topic of significant interest in the field.\nHowever, despite the inherent nested structure of polar codes, the use of\nsequence models in polar code construction is understudied. In this work, we\npropose using a sequence modeling framework to iteratively construct a polar\ncode for any given length and rate under various channel conditions.\nSimulations show that polar codes designed via sequential modeling using\ntransformers outperform both 5G-NR sequence and Density Evolution based\napproaches for both AWGN and Rayleigh fading channels.\n",
    "link": "http://arxiv.org/abs/2401.17188v1"
  },
  {
    "title": "Embracing Language Inclusivity and Diversity in CLIP through Continual\n  Language Learning",
    "authors": "Bang Yang, Yong Dai, Xuxin Cheng, Yaowei Li, Asif Raza, Yuexian Zou",
    "abstract": "  While vision-language pre-trained models (VL-PTMs) have advanced multimodal\nresearch in recent years, their mastery in a few languages like English\nrestricts their applicability in broader communities. To this end, there is an\nincreasing interest in developing multilingual VL models via a joint-learning\nsetup, which, however, could be unrealistic due to expensive costs and data\navailability. In this work, we propose to extend VL-PTMs' language capacity by\ncontinual language learning (CLL), where a model needs to update its linguistic\nknowledge incrementally without suffering from catastrophic forgetting (CF). We\nbegin our study by introducing a model dubbed CLL-CLIP, which builds upon CLIP,\na prevailing VL-PTM that has acquired image-English text alignment.\nSpecifically, CLL-CLIP contains an expandable token embedding layer to handle\nlinguistic differences. It solely trains token embeddings to improve memory\nstability and is optimized under cross-modal and cross-lingual objectives to\nlearn the alignment between images and multilingual texts. To alleviate CF\nraised by covariate shift and lexical overlap, we further propose a novel\napproach that ensures the identical distribution of all token embeddings during\ninitialization and regularizes token embedding learning during training. We\nconstruct a CLL benchmark covering 36 languages based on MSCOCO and XM3600\ndatasets and then evaluate multilingual image-text retrieval performance.\nExtensive experiments verify the effectiveness of CLL-CLIP and show that our\napproach can boost CLL-CLIP, e.g., by 6.7% in text-to-image average Recall@1 on\nXM3600, and improve various state-of-the-art methods consistently. Our code and\ndata are available at \\url{https://github.com/yangbang18/CLFM}.\n",
    "link": "http://arxiv.org/abs/2401.17186v1"
  },
  {
    "title": "GraphViz2Vec: A Structure-aware Feature Generation Model to Improve\n  Classification in GNNs",
    "authors": "Shraban Kumar Chatterjee, Suman Kundu",
    "abstract": "  GNNs are widely used to solve various tasks including node classification and\nlink prediction. Most of the GNN architectures assume the initial embedding to\nbe random or generated from popular distributions. These initial embeddings\nrequire multiple layers of transformation to converge into a meaningful latent\nrepresentation. While number of layers allow accumulation of larger\nneighbourhood of a node it also introduce the problem of over-smoothing. In\naddition, GNNs are inept at representing structural information. For example,\nthe output embedding of a node does not capture its triangles participation. In\nthis paper, we presented a novel feature extraction methodology GraphViz2Vec\nthat can capture the structural information of a node's local neighbourhood to\ncreate meaningful initial embeddings for a GNN model. These initial embeddings\nhelps existing models achieve state-of-the-art results in various\nclassification tasks. Further, these initial embeddings help the model to\nproduce desired results with only two layers which in turn reduce the problem\nof over-smoothing. The initial encoding of a node is obtained from an image\nclassification model trained on multiple energy diagrams of its local\nneighbourhood. These energy diagrams are generated with the induced sub-graph\nof the nodes traversed by multiple random walks. The generated encodings\nincrease the performance of existing models on classification tasks (with a\nmean increase of $4.65\\%$ and $2.58\\%$ for the node and link classification\ntasks, respectively), with some models achieving state-of-the-art results.\n",
    "link": "http://arxiv.org/abs/2401.17178v1"
  },
  {
    "title": "Zero-Shot Reinforcement Learning via Function Encoders",
    "authors": "Tyler Ingebrand, Amy Zhang, Ufuk Topcu",
    "abstract": "  Although reinforcement learning (RL) can solve many challenging sequential\ndecision making problems, achieving zero-shot transfer across related tasks\nremains a challenge. The difficulty lies in finding a good representation for\nthe current task so that the agent understands how it relates to previously\nseen tasks. To achieve zero-shot transfer, we introduce the function encoder, a\nrepresentation learning algorithm which represents a function as a weighted\ncombination of learned, non-linear basis functions. By using a function encoder\nto represent the reward function or the transition function, the agent has\ninformation on how the current task relates to previously seen tasks via a\ncoherent vector representation. Thus, the agent is able to achieve transfer\nbetween related tasks at run time with no additional training. We demonstrate\nstate-of-the-art data efficiency, asymptotic performance, and training\nstability in three RL fields by augmenting basic RL algorithms with a function\nencoder task representation.\n",
    "link": "http://arxiv.org/abs/2401.17173v1"
  },
  {
    "title": "Conditional and Modal Reasoning in Large Language Models",
    "authors": "Wesley H. Holliday, Matthew Mandelkern",
    "abstract": "  The reasoning abilities of large language models (LLMs) are the topic of a\ngrowing body of research in artificial intelligence and cognitive science. In\nthis paper, we probe the extent to which a dozen LLMs are able to distinguish\nlogically correct inferences from logically fallacious ones. We focus on\ninference patterns involving conditionals (e.g., 'If Ann has a queen, then Bob\nhas a jack') and epistemic modals (e.g., 'Ann might have an ace', 'Bob must\nhave a king'). These inference patterns have been of special interest to\nlogicians, philosophers, and linguists, since they plausibly play a central\nrole in human reasoning. Assessing LLMs on these inference patterns is thus\nhighly relevant to the question of how much the reasoning abilities of LLMs\nmatch those of humans. Among the LLMs we tested, all but GPT-4 often make basic\nmistakes with conditionals. Moreover, even GPT-4 displays logically\ninconsistent judgments across inference patterns involving epistemic modals.\n",
    "link": "http://arxiv.org/abs/2401.17169v1"
  },
  {
    "title": "Layered and Staged Monte Carlo Tree Search for SMT Strategy Synthesis",
    "authors": "Zhengyang Lu, Stefan Siemer, Piyush Jha, Joel Day, Florin Manea, Vijay Ganesh",
    "abstract": "  Modern SMT solvers, such as Z3, offer user-controllable strategies, enabling\nusers to tailor them for their unique set of instances, thus dramatically\nenhancing solver performance for their use case. However, this approach of\nstrategy customization presents a significant challenge: handcrafting an\noptimized strategy for a class of SMT instances remains a complex and demanding\ntask for both solver developers and users alike.\n  In this paper, we address this problem of automatic SMT strategy synthesis\nvia a novel Monte Carlo Tree Search (MCTS) based method. Our method treats\nstrategy synthesis as a sequential decision-making process, whose search tree\ncorresponds to the strategy space, and employs MCTS to navigate this vast\nsearch space. The key innovations that enable our method to identify effective\nstrategies, while keeping costs low, are the ideas of layered and staged MCTS\nsearch. These novel approaches allow for a deeper and more efficient\nexploration of the strategy space, enabling us to synthesize more effective\nstrategies than the default ones in state-of-the-art (SOTA) SMT solvers. We\nimplement our method, dubbed Z3alpha, as part of the Z3 SMT solver. Through\nextensive evaluations across 6 important SMT logics, Z3alpha demonstrates\nsuperior performance compared to the SOTA synthesis tool FastSMT, the default\nZ3 solver, and the CVC5 solver on most benchmarks. Remarkably, on a challenging\nQF_BV benchmark set, Z3alpha solves 42.7% more instances than the default\nstrategy in the Z3 SMT solver.\n",
    "link": "http://arxiv.org/abs/2401.17159v1"
  },
  {
    "title": "Large Language Model Evaluation via Matrix Entropy",
    "authors": "Lai Wei, Zhiquan Tan, Chenghai Li, Jindong Wang, Weiran Huang",
    "abstract": "  Large language models (LLMs) have revolutionized the field of natural\nlanguage processing, extending their strong capabilities into multi-modal\ndomains. Thus, it is vital to define proper and diversified metrics for the\nevaluation of LLMs.\n  In this paper, we introduce matrix entropy, a novel metric rooted in\ninformation theory and geometry principles to quantify the data compression\nproficiency in LLMs. It reflects the model's ability to extract relevant\ninformation and eliminate unnecessary elements, thereby providing insight into\nthe language model's intrinsic capability. Specifically, we demonstrate its\napplicability in both single-modal (language) and multi-modal settings. For\nlanguage models, our findings reveal that the matrix entropy of representations\nfollows a scaling law type reduction when the model scales up, serving as a\ncomplement to the traditional loss scaling law. For the multi-modal setting, we\nalso propose an evaluation method based on matrix entropy for assessing\nalignment quality and we find that modern large multi-modal models exhibit\ngreat alignment performance.\n",
    "link": "http://arxiv.org/abs/2401.17139v1"
  },
  {
    "title": "A Proactive and Dual Prevention Mechanism against Illegal Song Covers\n  empowered by Singing Voice Conversion",
    "authors": "Guangke Chen, Yedi Zhang, Fu Song, Ting Wang, Xiaoning Du, Yang Liu",
    "abstract": "  Singing voice conversion (SVC) automates song covers by converting one\nsinger's singing voice into another target singer's singing voice with the\noriginal lyrics and melody. However, it raises serious concerns about copyright\nand civil right infringements to multiple entities. This work proposes\nSongBsAb, the first proactive approach to mitigate unauthorized SVC-based\nillegal song covers. SongBsAb introduces human-imperceptible perturbations to\nsinging voices before releasing them, so that when they are used, the\ngeneration process of SVC will be interfered, resulting in unexpected singing\nvoices. SongBsAb features a dual prevention effect by causing both (singer)\nidentity disruption and lyric disruption, namely, the SVC-covered singing voice\nneither imitates the target singer nor preserves the original lyrics. To\nimprove the imperceptibility of perturbations, we refine a psychoacoustic\nmodel-based loss with the backing track as an additional masker, a unique\naccompanying element for singing voices compared to ordinary speech voices. To\nenhance the transferability, we propose to utilize a frame-level interaction\nreduction-based loss. We demonstrate the prevention effectiveness, utility, and\nrobustness of SongBsAb on three SVC models and two datasets using both\nobjective and human study-based subjective metrics. Our work fosters an\nemerging research direction for mitigating illegal automated song covers.\n",
    "link": "http://arxiv.org/abs/2401.17133v1"
  },
  {
    "title": "Traffic estimation in unobserved network locations using data-driven\n  macroscopic models",
    "authors": "Pablo Guarda, Sean Qian",
    "abstract": "  This paper leverages macroscopic models and multi-source spatiotemporal data\ncollected from automatic traffic counters and probe vehicles to accurately\nestimate traffic flow and travel time in links where these measurements are\nunavailable. This problem is critical in transportation planning applications\nwhere the sensor coverage is low and the planned interventions have\nnetwork-wide impacts. The proposed model, named the Macroscopic Traffic\nEstimator (MaTE), can perform network-wide estimations of traffic flow and\ntravel time only using the set of observed measurements of these quantities.\nBecause MaTE is grounded in macroscopic flow theory, all parameters and\nvariables are interpretable. The estimated traffic flow satisfies fundamental\nflow conservation constraints and exhibits an increasing monotonic relationship\nwith the estimated travel time. Using logit-based stochastic traffic assignment\nas the principle for routing flow behavior makes the model fully differentiable\nwith respect to the model parameters. This property facilitates the application\nof computational graphs to learn parameters from vast amounts of spatiotemporal\ndata. We also integrate neural networks and polynomial kernel functions to\ncapture link flow interactions and enrich the mapping of traffic flows into\ntravel times. MaTE also adds a destination choice model and a trip generation\nmodel that uses historical data on the number of trips generated by location.\nExperiments on synthetic data show that the model can accurately estimate\ntravel time and traffic flow in out-of-sample links. Results obtained using\nreal-world multi-source data from a large-scale transportation network suggest\nthat MaTE outperforms data-driven benchmarks, especially in travel time\nestimation. The estimated parameters of MaTE are also informative about the\nhourly change in travel demand and supply characteristics of the transportation\nnetwork.\n",
    "link": "http://arxiv.org/abs/2401.17095v1"
  },
  {
    "title": "BlockFusion: Expandable 3D Scene Generation using Latent Tri-plane\n  Extrapolation",
    "authors": "Zhennan Wu, Yang Li, Han Yan, Taizhang Shang, Weixuan Sun, Senbo Wang, Ruikai Cui, Weizhe Liu, Hiroyuki Sato, Hongdong Li, Pan Ji",
    "abstract": "  We present BlockFusion, a diffusion-based model that generates 3D scenes as\nunit blocks and seamlessly incorporates new blocks to extend the scene.\nBlockFusion is trained using datasets of 3D blocks that are randomly cropped\nfrom complete 3D scene meshes. Through per-block fitting, all training blocks\nare converted into the hybrid neural fields: with a tri-plane containing the\ngeometry features, followed by a Multi-layer Perceptron (MLP) for decoding the\nsigned distance values. A variational auto-encoder is employed to compress the\ntri-planes into the latent tri-plane space, on which the denoising diffusion\nprocess is performed. Diffusion applied to the latent representations allows\nfor high-quality and diverse 3D scene generation. To expand a scene during\ngeneration, one needs only to append empty blocks to overlap with the current\nscene and extrapolate existing latent tri-planes to populate new blocks. The\nextrapolation is done by conditioning the generation process with the feature\nsamples from the overlapping tri-planes during the denoising iterations. Latent\ntri-plane extrapolation produces semantically and geometrically meaningful\ntransitions that harmoniously blend with the existing scene. A 2D layout\nconditioning mechanism is used to control the placement and arrangement of\nscene elements. Experimental results indicate that BlockFusion is capable of\ngenerating diverse, geometrically consistent and unbounded large 3D scenes with\nunprecedented high-quality shapes in both indoor and outdoor scenarios.\n",
    "link": "http://arxiv.org/abs/2401.17053v1"
  },
  {
    "title": "ViTree: Single-path Neural Tree for Step-wise Interpretable Fine-grained\n  Visual Categorization",
    "authors": "Danning Lao, Qi Liu, Jiazi Bu, Junchi Yan, Wei Shen",
    "abstract": "  As computer vision continues to advance and finds widespread applications\nacross various domains, the need for interpretability in deep learning models\nbecomes paramount. Existing methods often resort to post-hoc techniques or\nprototypes to explain the decision-making process, which can be indirect and\nlack intrinsic illustration. In this research, we introduce ViTree, a novel\napproach for fine-grained visual categorization that combines the popular\nvision transformer as a feature extraction backbone with neural decision trees.\nBy traversing the tree paths, ViTree effectively selects patches from\ntransformer-processed features to highlight informative local regions, thereby\nrefining representations in a step-wise manner. Unlike previous tree-based\nmodels that rely on soft distributions or ensembles of paths, ViTree selects a\nsingle tree path, offering a clearer and simpler decision-making process. This\npatch and path selectivity enhances model interpretability of ViTree, enabling\nbetter insights into the model's inner workings. Remarkably, extensive\nexperimentation validates that this streamlined approach surpasses various\nstrong competitors and achieves state-of-the-art performance while maintaining\nexceptional interpretability which is proved by multi-perspective methods. Code\ncan be found at https://github.com/SJTU-DeepVisionLab/ViTree.\n",
    "link": "http://arxiv.org/abs/2401.17050v1"
  },
  {
    "title": "Explaining Explanations in Probabilistic Logic Programming",
    "authors": "Germ\u00e1n Vidal",
    "abstract": "  The emergence of tools based on artificial intelligence has also led to the\nneed of producing explanations which are understandable by a human being. In\nsome approaches, the system is not transparent (often referred to as a \"black\nbox\"), making it difficult to generate appropriate explanations. In this work,\nthough, we consider probabilistic logic programming, a combination of logic\nprogramming (for knowledge representation) and probability (to model\nuncertainty). In this setting, one can say that models are interpretable, which\neases its understanding. However, given a particular query, the usual notion of\n\"explanation\" is associated with a set of choices, one for each random variable\nof the model. Unfortunately, this set does not have a causal structure and, in\nfact, some of the choices are actually irrelevant to the considered query. In\norder to overcome these shortcomings, we present an approach to explaining\nexplanations which is based on the definition of a query-driven inference\nmechanism for probabilistic logic programs.\n",
    "link": "http://arxiv.org/abs/2401.17045v1"
  },
  {
    "title": "Scalable Mechanism Design for Multi-Agent Path Finding",
    "authors": "Paul Friedrich, Yulun Zhang, Michael Curry, Ludwig Dierks, Stephen McAleer, Jiaoyang Li, Tuomas Sandholm, Sven Seuken",
    "abstract": "  Multi-Agent Path Finding (MAPF) involves determining paths for multiple\nagents to travel simultaneously through a shared area toward particular goal\nlocations. This problem is computationally complex, especially when dealing\nwith large numbers of agents, as is common in realistic applications like\nautonomous vehicle coordination. Finding an optimal solution is often\ncomputationally infeasible, making the use of approximate algorithms essential.\nAdding to the complexity, agents might act in a self-interested and strategic\nway, possibly misrepresenting their goals to the MAPF algorithm if it benefits\nthem. Although the field of mechanism design offers tools to align incentives,\nusing these tools without careful consideration can fail when only having\naccess to approximately optimal outcomes. Since approximations are crucial for\nscalable MAPF algorithms, this poses a significant challenge. In this work, we\nintroduce the problem of scalable mechanism design for MAPF and propose three\nstrategyproof mechanisms, two of which even use approximate MAPF algorithms. We\ntest our mechanisms on realistic MAPF domains with problem sizes ranging from\ndozens to hundreds of agents. Our findings indicate that they improve welfare\nbeyond a simple baseline.\n",
    "link": "http://arxiv.org/abs/2401.17044v1"
  },
  {
    "title": "Finetuning Large Language Models for Vulnerability Detection",
    "authors": "Alexey Shestov, Anton Cheshkov, Rodion Levichev, Ravil Mussabayev, Pavel Zadorozhny, Evgeny Maslov, Chibirev Vadim, Egor Bulychev",
    "abstract": "  This paper presents the results of finetuning large language models (LLMs)\nfor the task of detecting vulnerabilities in source code. We leverage\nWizardCoder, a recent improvement of the state-of-the-art LLM StarCoder, and\nadapt it for vulnerability detection through further finetuning. To accelerate\ntraining, we modify WizardCoder's training procedure, also we investigate\noptimal training regimes. For the imbalanced dataset with many more negative\nexamples than positive, we also explore different techniques to improve\nclassification performance. The finetuned WizardCoder model achieves\nimprovement in ROC AUC and F1 measures on balanced and imbalanced vulnerability\ndatasets over CodeBERT-like model, demonstrating the effectiveness of adapting\npretrained LLMs for vulnerability detection in source code. The key\ncontributions are finetuning the state-of-the-art code LLM, WizardCoder,\nincreasing its training speed without the performance harm, optimizing the\ntraining procedure and regimes, handling class imbalance, and improving\nperformance on difficult vulnerability detection datasets. This demonstrates\nthe potential for transfer learning by finetuning large pretrained language\nmodels for specialized source code analysis tasks.\n",
    "link": "http://arxiv.org/abs/2401.17010v1"
  },
  {
    "title": "ActDroid: An active learning framework for Android malware detection",
    "authors": "Ali Muzaffar, Hani Ragab Hassen, Hind Zantout, Michael A Lones",
    "abstract": "  The growing popularity of Android requires malware detection systems that can\nkeep up with the pace of new software being released. According to a recent\nstudy, a new piece of malware appears online every 12 seconds. To address this,\nwe treat Android malware detection as a streaming data problem and explore the\nuse of active online learning as a means of mitigating the problem of labelling\napplications in a timely and cost-effective manner. Our resulting framework\nachieves accuracies of up to 96\\%, requires as little of 24\\% of the training\ndata to be labelled, and compensates for concept drift that occurs between the\nrelease and labelling of an application. We also consider the broader\npracticalities of online learning within Android malware detection, and\nsystematically explore the trade-offs between using different static, dynamic\nand hybrid feature sets to classify malware.\n",
    "link": "http://arxiv.org/abs/2401.16982v1"
  },
  {
    "title": "CORE: Towards Scalable and Efficient Causal Discovery with Reinforcement\n  Learning",
    "authors": "Andreas W. M. Sauter, Nicol\u00f2 Botteghi, Erman Acar, Aske Plaat",
    "abstract": "  Causal discovery is the challenging task of inferring causal structure from\ndata. Motivated by Pearl's Causal Hierarchy (PCH), which tells us that passive\nobservations alone are not enough to distinguish correlation from causation,\nthere has been a recent push to incorporate interventions into machine learning\nresearch. Reinforcement learning provides a convenient framework for such an\nactive approach to learning. This paper presents CORE, a deep reinforcement\nlearning-based approach for causal discovery and intervention planning. CORE\nlearns to sequentially reconstruct causal graphs from data while learning to\nperform informative interventions. Our results demonstrate that CORE\ngeneralizes to unseen graphs and efficiently uncovers causal structures.\nFurthermore, CORE scales to larger graphs with up to 10 variables and\noutperforms existing approaches in structure estimation accuracy and sample\nefficiency. All relevant code and supplementary material can be found at\nhttps://github.com/sa-and/CORE\n",
    "link": "http://arxiv.org/abs/2401.16974v1"
  },
  {
    "title": "Two Heads Are Better Than One: Integrating Knowledge from Knowledge\n  Graphs and Large Language Models for Entity Alignment",
    "authors": "Linyao Yang, Hongyang Chen, Xiao Wang, Jing Yang, Fei-Yue Wang, Han Liu",
    "abstract": "  Entity alignment, which is a prerequisite for creating a more comprehensive\nKnowledge Graph (KG), involves pinpointing equivalent entities across disparate\nKGs. Contemporary methods for entity alignment have predominantly utilized\nknowledge embedding models to procure entity embeddings that encapsulate\nvarious similarities-structural, relational, and attributive. These embeddings\nare then integrated through attention-based information fusion mechanisms.\nDespite this progress, effectively harnessing multifaceted information remains\nchallenging due to inherent heterogeneity. Moreover, while Large Language\nModels (LLMs) have exhibited exceptional performance across diverse downstream\ntasks by implicitly capturing entity semantics, this implicit knowledge has yet\nto be exploited for entity alignment. In this study, we propose a Large\nLanguage Model-enhanced Entity Alignment framework (LLMEA), integrating\nstructural knowledge from KGs with semantic knowledge from LLMs to enhance\nentity alignment. Specifically, LLMEA identifies candidate alignments for a\ngiven entity by considering both embedding similarities between entities across\nKGs and edit distances to a virtual equivalent entity. It then engages an LLM\niteratively, posing multiple multi-choice questions to draw upon the LLM's\ninference capability. The final prediction of the equivalent entity is derived\nfrom the LLM's output. Experiments conducted on three public datasets reveal\nthat LLMEA surpasses leading baseline models. Additional ablation studies\nunderscore the efficacy of our proposed framework.\n",
    "link": "http://arxiv.org/abs/2401.16960v1"
  },
  {
    "title": "Reinforcement Learning for Versatile, Dynamic, and Robust Bipedal\n  Locomotion Control",
    "authors": "Zhongyu Li, Xue Bin Peng, Pieter Abbeel, Sergey Levine, Glen Berseth, Koushil Sreenath",
    "abstract": "  This paper presents a comprehensive study on using deep reinforcement\nlearning (RL) to create dynamic locomotion controllers for bipedal robots.\nGoing beyond focusing on a single locomotion skill, we develop a general\ncontrol solution that can be used for a range of dynamic bipedal skills, from\nperiodic walking and running to aperiodic jumping and standing. Our RL-based\ncontroller incorporates a novel dual-history architecture, utilizing both a\nlong-term and short-term input/output (I/O) history of the robot. This control\narchitecture, when trained through the proposed end-to-end RL approach,\nconsistently outperforms other methods across a diverse range of skills in both\nsimulation and the real world.The study also delves into the adaptivity and\nrobustness introduced by the proposed RL system in developing locomotion\ncontrollers. We demonstrate that the proposed architecture can adapt to both\ntime-invariant dynamics shifts and time-variant changes, such as contact\nevents, by effectively using the robot's I/O history. Additionally, we identify\ntask randomization as another key source of robustness, fostering better task\ngeneralization and compliance to disturbances. The resulting control policies\ncan be successfully deployed on Cassie, a torque-controlled human-sized bipedal\nrobot. This work pushes the limits of agility for bipedal robots through\nextensive real-world experiments. We demonstrate a diverse range of locomotion\nskills, including: robust standing, versatile walking, fast running with a\ndemonstration of a 400-meter dash, and a diverse set of jumping skills, such as\nstanding long jumps and high jumps.\n",
    "link": "http://arxiv.org/abs/2401.16889v1"
  },
  {
    "title": "A Tournament of Transformation Models: B-Spline-based vs. Mesh-based\n  Multi-Objective Deformable Image Registration",
    "authors": "Georgios Andreadis, Joas I. Mulder, Anton Bouter, Peter A. N. Bosman, Tanja Alderliesten",
    "abstract": "  The transformation model is an essential component of any deformable image\nregistration approach. It provides a representation of physical deformations\nbetween images, thereby defining the range and realism of registrations that\ncan be found. Two types of transformation models have emerged as popular\nchoices: B-spline models and mesh models. Although both models have been\ninvestigated in detail, a direct comparison has not yet been made, since the\nmodels are optimized using very different optimization methods in practice.\nB-spline models are predominantly optimized using gradient-descent methods,\nwhile mesh models are typically optimized using finite-element method solvers\nor evolutionary algorithms. Multi-objective optimization methods, which aim to\nfind a diverse set of high-quality trade-off registrations, are increasingly\nacknowledged to be important in deformable image registration. Since these\nmethods search for a diverse set of registrations, they can provide a more\ncomplete picture of the capabilities of different transformation models, making\nthem suitable for a comparison of models. In this work, we conduct the first\ndirect comparison between B-spline and mesh transformation models, by\noptimizing both models with the same state-of-the-art multi-objective\noptimization method, the Multi-Objective Real-Valued Gene-pool Optimal Mixing\nEvolutionary Algorithm (MO-RV-GOMEA). The combination with B-spline\ntransformation models, moreover, is novel. We experimentally compare both\nmodels on two different registration problems that are both based on pelvic CT\nscans of cervical cancer patients, featuring large deformations. Our results,\non three cervical cancer patients, indicate that the choice of transformation\nmodel can have a profound impact on the diversity and quality of achieved\nregistration outcomes.\n",
    "link": "http://arxiv.org/abs/2401.16867v1"
  },
  {
    "title": "Encoding Temporal Statistical-space Priors via Augmented Representation",
    "authors": "Insu Choi, Woosung Koh, Gimin Kang, Yuntae Jang, Woo Chang Kim",
    "abstract": "  Modeling time series data remains a pervasive issue as the temporal dimension\nis inherent to numerous domains. Despite significant strides in time series\nforecasting, high noise-to-signal ratio, non-normality, non-stationarity, and\nlack of data continue challenging practitioners. In response, we leverage a\nsimple representation augmentation technique to overcome these challenges. Our\naugmented representation acts as a statistical-space prior encoded at each time\nstep. In response, we name our method Statistical-space Augmented\nRepresentation (SSAR). The underlying high-dimensional data-generating process\ninspires our representation augmentation. We rigorously examine the empirical\ngeneralization performance on two data sets with two downstream temporal\nlearning algorithms. Our approach significantly beats all five up-to-date\nbaselines. Moreover, the highly modular nature of our approach can easily be\napplied to various settings. Lastly, fully-fledged theoretical perspectives are\navailable throughout the writing for a clear and rigorous understanding.\n",
    "link": "http://arxiv.org/abs/2401.16808v1"
  },
  {
    "title": "Detecting LLM-Assisted Writing in Scientific Communication: Are We There\n  Yet?",
    "authors": "Teddy Lazebnik, Ariel Rosenfeld",
    "abstract": "  Large Language Models (LLMs), exemplified by ChatGPT, have significantly\nreshaped text generation, particularly in the realm of writing assistance.\nWhile ethical considerations underscore the importance of transparently\nacknowledging LLM use, especially in scientific communication, genuine\nacknowledgment remains infrequent. A potential avenue to encourage accurate\nacknowledging of LLM-assisted writing involves employing automated detectors.\nOur evaluation of four cutting-edge LLM-generated text detectors reveals their\nsuboptimal performance compared to a simple ad-hoc detector designed to\nidentify abrupt writing style changes around the time of LLM proliferation. We\ncontend that the development of specialized detectors exclusively dedicated to\nLLM-assisted writing detection is necessary. Such detectors could play a\ncrucial role in fostering more authentic recognition of LLM involvement in\nscientific communication, addressing the current challenges in acknowledgment\npractices.\n",
    "link": "http://arxiv.org/abs/2401.16807v1"
  },
  {
    "title": "Performance Insights-based AI-driven Football Transfer Fee Prediction",
    "authors": "Daniil Sulimov",
    "abstract": "  We developed an artificial intelligence approach to predict the transfer fee\nof a football player. This model can help clubs make better decisions about\nwhich players to buy and sell, which can lead to improved performance and\nincreased club budgets. Having collected data on player performance, transfer\nfees, and other factors that might affect a player's value, we then used this\ndata to train a machine learning model that can accurately predict a player's\nimpact on the game. We further passed the obtained results as one of the\nfeatures to the predictor of transfer fees. The model can help clubs identify\nplayers who are undervalued and who could be sold for a profit. It can also\nhelp clubs avoid overpaying for players. We believe that our model can be a\nvaluable tool for football clubs. It can help them make better decisions about\nplayer recruitment and transfers.\n",
    "link": "http://arxiv.org/abs/2401.16795v1"
  },
  {
    "title": "Can Large Language Models be Trusted for Evaluation? Scalable\n  Meta-Evaluation of LLMs as Evaluators via Agent Debate",
    "authors": "Steffi Chern, Ethan Chern, Graham Neubig, Pengfei Liu",
    "abstract": "  Despite the utility of Large Language Models (LLMs) across a wide range of\ntasks and scenarios, developing a method for reliably evaluating LLMs across\nvaried contexts continues to be challenging. Modern evaluation approaches often\nuse LLMs to assess responses generated by LLMs. However, the meta-evaluation\nconducted to assess the effectiveness of these LLMs as evaluators is typically\nconstrained by the coverage of existing benchmarks or requires extensive human\nannotation. This underscores the urgency of methods for scalable\nmeta-evaluation that can effectively, reliably, and efficiently evaluate the\nperformance of LLMs as evaluators across diverse tasks and scenarios,\nparticularly in potentially new, user-defined scenarios. To fill this gap, we\npropose ScaleEval, an agent-debate-assisted meta-evaluation framework that\nleverages the capabilities of multiple communicative LLM agents. This framework\nsupports multi-round discussions to assist human annotators in discerning the\nmost capable LLMs as evaluators, which significantly eases their workload in\ncases that used to require large-scale annotations during meta-evaluation. We\nrelease the code for our framework, which is publicly available at:\n\\url{https://github.com/GAIR-NLP/scaleeval}.\n",
    "link": "http://arxiv.org/abs/2401.16788v1"
  },
  {
    "title": "Graph Fairness Learning under Distribution Shifts",
    "authors": "Yibo Li, Xiao Wang, Yujie Xing, Shaohua Fan, Ruijia Wang, Yaoqi Liu, Chuan Shi",
    "abstract": "  Graph neural networks (GNNs) have achieved remarkable performance on\ngraph-structured data. However, GNNs may inherit prejudice from the training\ndata and make discriminatory predictions based on sensitive attributes, such as\ngender and race. Recently, there has been an increasing interest in ensuring\nfairness on GNNs, but all of them are under the assumption that the training\nand testing data are under the same distribution, i.e., training data and\ntesting data are from the same graph. Will graph fairness performance decrease\nunder distribution shifts? How does distribution shifts affect graph fairness\nlearning? All these open questions are largely unexplored from a theoretical\nperspective. To answer these questions, we first theoretically identify the\nfactors that determine bias on a graph. Subsequently, we explore the factors\ninfluencing fairness on testing graphs, with a noteworthy factor being the\nrepresentation distances of certain groups between the training and testing\ngraph. Motivated by our theoretical analysis, we propose our framework\nFatraGNN. Specifically, to guarantee fairness performance on unknown testing\ngraphs, we propose a graph generator to produce numerous graphs with\nsignificant bias and under different distributions. Then we minimize the\nrepresentation distances for each certain group between the training graph and\ngenerated graphs. This empowers our model to achieve high classification and\nfairness performance even on generated graphs with significant bias, thereby\neffectively handling unknown testing graphs. Experiments on real-world and\nsemi-synthetic datasets demonstrate the effectiveness of our model in terms of\nboth accuracy and fairness.\n",
    "link": "http://arxiv.org/abs/2401.16784v1"
  },
  {
    "title": "Extrinsicaly Rewarded Soft Q Imitation Learning with Discriminator",
    "authors": "Ryoma Furuyama, Daiki Kuyoshi, Satoshi Yamane",
    "abstract": "  Imitation learning is often used in addition to reinforcement learning in\nenvironments where reward design is difficult or where the reward is sparse,\nbut it is difficult to be able to imitate well in unknown states from a small\namount of expert data and sampling data. Supervised learning methods such as\nBehavioral Cloning do not require sampling data, but usually suffer from\ndistribution shift. The methods based on reinforcement learning, such as\ninverse reinforcement learning and Generative Adversarial imitation learning\n(GAIL), can learn from only a few expert data. However, they often need to\ninteract with the environment. Soft Q imitation learning (SQIL) addressed the\nproblems, and it was shown that it could learn efficiently by combining\nBehavioral Cloning and soft Q-learning with constant rewards. In order to make\nthis algorithm more robust to distribution shift, we propose more efficient and\nrobust algorithm by adding to this method a reward function based on\nadversarial inverse reinforcement learning that rewards the agent for\nperforming actions in status similar to the demo. We call this algorithm\nDiscriminator Soft Q Imitation Learning (DSQIL). We evaluated it on MuJoCo\nenvironments.\n",
    "link": "http://arxiv.org/abs/2401.16772v1"
  },
  {
    "title": "Detection and Recovery Against Deep Neural Network Fault Injection\n  Attacks Based on Contrastive Learning",
    "authors": "Chenan Wang, Pu Zhao, Siyue Wang, Xue Lin",
    "abstract": "  Deep Neural Network (DNN) models when implemented on executing devices as the\ninference engines are susceptible to Fault Injection Attacks (FIAs) that\nmanipulate model parameters to disrupt inference execution with disastrous\nperformance. This work introduces Contrastive Learning (CL) of visual\nrepresentations i.e., a self-supervised learning approach into the deep\nlearning training and inference pipeline to implement DNN inference engines\nwith self-resilience under FIAs. Our proposed CL based FIA Detection and\nRecovery (CFDR) framework features (i) real-time detection with only a single\nbatch of testing data and (ii) fast recovery effective even with only a small\namount of unlabeled testing data. Evaluated with the CIFAR-10 dataset on\nmultiple types of FIAs, our CFDR shows promising detection and recovery\neffectiveness.\n",
    "link": "http://arxiv.org/abs/2401.16766v1"
  },
  {
    "title": "A Cross-Language Investigation into Jailbreak Attacks in Large Language\n  Models",
    "authors": "Jie Li, Yi Liu, Chongyang Liu, Ling Shi, Xiaoning Ren, Yaowen Zheng, Yang Liu, Yinxing Xue",
    "abstract": "  Large Language Models (LLMs) have become increasingly popular for their\nadvanced text generation capabilities across various domains. However, like any\nsoftware, they face security challenges, including the risk of 'jailbreak'\nattacks that manipulate LLMs to produce prohibited content. A particularly\nunderexplored area is the Multilingual Jailbreak attack, where malicious\nquestions are translated into various languages to evade safety filters.\nCurrently, there is a lack of comprehensive empirical studies addressing this\nspecific threat.\n  To address this research gap, we conducted an extensive empirical study on\nMultilingual Jailbreak attacks. We developed a novel semantic-preserving\nalgorithm to create a multilingual jailbreak dataset and conducted an\nexhaustive evaluation on both widely-used open-source and commercial LLMs,\nincluding GPT-4 and LLaMa. Additionally, we performed interpretability analysis\nto uncover patterns in Multilingual Jailbreak attacks and implemented a\nfine-tuning mitigation method. Our findings reveal that our mitigation strategy\nsignificantly enhances model defense, reducing the attack success rate by\n96.2%. This study provides valuable insights into understanding and mitigating\nMultilingual Jailbreak attacks.\n",
    "link": "http://arxiv.org/abs/2401.16765v1"
  },
  {
    "title": "SwapNet: Efficient Swapping for DNN Inference on Edge AI Devices Beyond\n  the Memory Budget",
    "authors": "Kun Wang, Jiani Cao, Zimu Zhou, Zhenjiang Li",
    "abstract": "  Executing deep neural networks (DNNs) on edge artificial intelligence (AI)\ndevices enables various autonomous mobile computing applications. However, the\nmemory budget of edge AI devices restricts the number and complexity of DNNs\nallowed in such applications. Existing solutions, such as model compression or\ncloud offloading, reduce the memory footprint of DNN inference at the cost of\ndecreased model accuracy or autonomy. To avoid these drawbacks, we divide DNN\ninto blocks and swap them in and out in order, such that large DNNs can execute\nwithin a small memory budget. Nevertheless, naive swapping on edge AI devices\ninduces significant delays due to the redundant memory operations in the DNN\ndevelopment ecosystem for edge AI devices. To this end, we develop SwapNet, an\nefficient DNN block swapping middleware for edge AI devices. We systematically\neliminate the unnecessary memory operations during block swapping while\nretaining compatible with the deep learning frameworks, GPU backends, and\nhardware architectures of edge AI devices. We further showcase the utility of\nSwapNet via a multi-DNN scheduling scheme. Evaluations on eleven DNN inference\ntasks in three applications demonstrate that SwapNet achieves almost the same\nlatency as the case with sufficient memory even when DNNs demand 2.32x to 5.81x\nmemory beyond the available budget. The design of SwapNet also provides novel\nand feasible insights for deploying large language models (LLMs) on edge AI\ndevices in the future.\n",
    "link": "http://arxiv.org/abs/2401.16757v1"
  },
  {
    "title": "Diffusion model for relational inference",
    "authors": "Shuhan Zheng, Ziqiang Li, Kantaro Fujiwara, Gouhei Tanaka",
    "abstract": "  Dynamical behaviors of complex interacting systems, including brain\nactivities, financial price movements, and physical collective phenomena, are\nassociated with underlying interactions between the system's components. The\nissue of uncovering interaction relations in such systems using observable\ndynamics is called relational inference. In this study, we propose a Diffusion\nmodel for Relational Inference (DiffRI), inspired by a self-supervised method\nfor probabilistic time series imputation. DiffRI learns to infer the\nprobability of the presence of connections between components through\nconditional diffusion modeling. Experiments on both simulated and quasi-real\ndatasets show that DiffRI is highly competent compared with other\nstate-of-the-art models in discovering ground truth interactions in an\nunsupervised manner. Our code will be made public soon.\n",
    "link": "http://arxiv.org/abs/2401.16755v1"
  },
  {
    "title": "ShaRP: Explaining Rankings with Shapley Values",
    "authors": "Venetia Pliatsika, Joao Fonseca, Tilun Wang, Julia Stoyanovich",
    "abstract": "  Algorithmic decisions in critical domains such as hiring, college admissions,\nand lending are often based on rankings. Because of the impact these decisions\nhave on individuals, organizations, and population groups, there is a need to\nunderstand them: to know whether the decisions are abiding by the law, to help\nindividuals improve their rankings, and to design better ranking procedures.\n  In this paper, we present ShaRP (Shapley for Rankings and Preferences), a\nframework that explains the contributions of features to different aspects of a\nranked outcome, and is based on Shapley values. Using ShaRP, we show that even\nwhen the scoring function used by an algorithmic ranker is known and linear,\nthe weight of each feature does not correspond to its Shapley value\ncontribution. The contributions instead depend on the feature distributions,\nand on the subtle local interactions between the scoring features. ShaRP builds\non the Quantitative Input Influence framework, and can compute the\ncontributions of features for multiple Quantities of Interest, including score,\nrank, pair-wise preference, and top-k. Because it relies on black-box access to\nthe ranker, ShaRP can be used to explain both score-based and learned ranking\nmodels. We show results of an extensive experimental validation of ShaRP using\nreal and synthetic datasets, showcasing its usefulness for qualitative\nanalysis.\n",
    "link": "http://arxiv.org/abs/2401.16744v1"
  },
  {
    "title": "Generative AI-based closed-loop fMRI system",
    "authors": "Mikihiro Kasahara, Taiki Oka, Vincent Taschereau-Dumouchel, Mitsuo Kawato, Hiroki Takakura, Aurelio Cortese",
    "abstract": "  While generative AI is now widespread and useful in society, there are\npotential risks of misuse, e.g., unconsciously influencing cognitive processes\nor decision-making. Although this causes a security problem in the cognitive\ndomain, there has been no research about neural and computational mechanisms\ncounteracting the impact of malicious generative AI in humans. We propose\nDecNefGAN, a novel framework that combines a generative adversarial system and\na neural reinforcement model. More specifically, DecNefGAN bridges human and\ngenerative AI in a closed-loop system, with the AI creating stimuli that induce\nspecific mental states, thus exerting external control over neural activity.\nThe objective of the human is the opposite, to compete and reach an orthogonal\nmental state. This framework can contribute to elucidating how the human brain\nresponds to and counteracts the potential influence of generative AI.\n",
    "link": "http://arxiv.org/abs/2401.16742v1"
  },
  {
    "title": "Towards Generating Informative Textual Description for Neurons in\n  Language Models",
    "authors": "Shrayani Mondal, Rishabh Garodia, Arbaaz Qureshi, Taesung Lee, Youngja Park",
    "abstract": "  Recent developments in transformer-based language models have allowed them to\ncapture a wide variety of world knowledge that can be adapted to downstream\ntasks with limited resources. However, what pieces of information are\nunderstood in these models is unclear, and neuron-level contributions in\nidentifying them are largely unknown. Conventional approaches in neuron\nexplainability either depend on a finite set of pre-defined descriptors or\nrequire manual annotations for training a secondary model that can then explain\nthe neurons of the primary model. In this paper, we take BERT as an example and\nwe try to remove these constraints and propose a novel and scalable framework\nthat ties textual descriptions to neurons. We leverage the potential of\ngenerative language models to discover human-interpretable descriptors present\nin a dataset and use an unsupervised approach to explain neurons with these\ndescriptors. Through various qualitative and quantitative analyses, we\ndemonstrate the effectiveness of this framework in generating useful\ndata-specific descriptors with little human involvement in identifying the\nneurons that encode these descriptors. In particular, our experiment shows that\nthe proposed approach achieves 75% precision@2, and 50% recall@2\n",
    "link": "http://arxiv.org/abs/2401.16731v1"
  },
  {
    "title": "Multivariate Beta Mixture Model: Probabilistic Clustering With Flexible\n  Cluster Shapes",
    "authors": "Yung-Peng Hsu, Hung-Hsuan Chen",
    "abstract": "  This paper introduces the multivariate beta mixture model (MBMM), a new\nprobabilistic model for soft clustering. MBMM adapts to diverse cluster shapes\nbecause of the flexible probability density function of the multivariate beta\ndistribution. We introduce the properties of MBMM, describe the parameter\nlearning procedure, and present the experimental results, showing that MBMM\nfits diverse cluster shapes on synthetic and real datasets. The code is\nreleased anonymously at \\url{https://github.com/hhchen1105/mbmm/}.\n",
    "link": "http://arxiv.org/abs/2401.16708v1"
  },
  {
    "title": "AutoIE: An Automated Framework for Information Extraction from\n  Scientific Literature",
    "authors": "Yangyang Liu, Shoubin Li",
    "abstract": "  In the rapidly evolving field of scientific research, efficiently extracting\nkey information from the burgeoning volume of scientific papers remains a\nformidable challenge. This paper introduces an innovative framework designed to\nautomate the extraction of vital data from scientific PDF documents, enabling\nresearchers to discern future research trajectories more readily. AutoIE\nuniquely integrates four novel components: (1) A multi-semantic feature\nfusion-based approach for PDF document layout analysis; (2) Advanced functional\nblock recognition in scientific texts; (3) A synergistic technique for\nextracting and correlating information on molecular sieve synthesis; (4) An\nonline learning paradigm tailored for molecular sieve literature. Our SBERT\nmodel achieves high Marco F1 scores of 87.19 and 89.65 on CoNLL04 and ADE\ndatasets. In addition, a practical application of AutoIE in the petrochemical\nmolecular sieve synthesis domain demonstrates its efficacy, evidenced by an\nimpressive 78\\% accuracy rate. This research paves the way for enhanced data\nmanagement and interpretation in molecular sieve synthesis. It is a valuable\nasset for seasoned experts and newcomers in this specialized field.\n",
    "link": "http://arxiv.org/abs/2401.16672v1"
  },
  {
    "title": "Is Artificial Intelligence Providing the Second Revolution for Weather\n  Forecasting?",
    "authors": "Fenghua Ling, Lin Ouyang, Boufeniza Redouane Larbi, Jing-Jia Luo, Tao Han, Xiaohui Zhong, Lei Bai",
    "abstract": "  The rapid advancement of artificial intelligence technologies, particularly\nin recent years, has led to the emergence of several large parameter artificial\nintelligence weather forecast models. These models represent a significant\nbreakthrough, overcoming the limitations of traditional numerical weather\nprediction models and indicating a potential second revolution for weather\nforecast. This study explores the evolution of these advanced artificial\nintelligence forecast models, and based on the identified commonalities,\nproposes the \"Three Large Rules\" for their development. We discuss the\npotential of artificial intelligence in revolutionizing numerical weather\nprediction, briefly outlining the underlying reasons for this potential.\nAdditionally, we explore key areas for future development prospects for large\nartificial intelligence weather forecast models, integrating the entire\nnumerical prediction process. Through an example that combines a large\nartificial intelligence model with ocean wave forecasting, we illustrate how\nforecasters can adapt and leverage the advanced artificial intelligence model.\nWhile acknowledging the high accuracy, computational efficiency, and ease of\ndeployment of large artificial intelligence forecast models, we emphasize the\nirreplaceable values of traditional numerical forecasts. We believe that the\noptimal future of weather forecasting lies in achieving a seamless integration\nof artificial intelligence and traditional numerical models. Such a synthesis\nis anticipated to offer a more comprehensive and reliable approach for future\nweather forecasting.\n",
    "link": "http://arxiv.org/abs/2401.16669v1"
  },
  {
    "title": "Recovering Mental Representations from Large Language Models with Markov\n  Chain Monte Carlo",
    "authors": "Jian-Qiao Zhu, Haijiang Yan, Thomas L. Griffiths",
    "abstract": "  Simulating sampling algorithms with people has proven a useful method for\nefficiently probing and understanding their mental representations. We propose\nthat the same methods can be used to study the representations of Large\nLanguage Models (LLMs). While one can always directly prompt either humans or\nLLMs to disclose their mental representations introspectively, we show that\nincreased efficiency can be achieved by using LLMs as elements of a sampling\nalgorithm. We explore the extent to which we recover human-like representations\nwhen LLMs are interrogated with Direct Sampling and Markov chain Monte Carlo\n(MCMC). We found a significant increase in efficiency and performance using\nadaptive sampling algorithms based on MCMC. We also highlight the potential of\nour method to yield a more general method of conducting Bayesian inference\n\\textit{with} LLMs.\n",
    "link": "http://arxiv.org/abs/2401.16657v1"
  },
  {
    "title": "Augmenting Replay in World Models for Continual Reinforcement Learning",
    "authors": "Luke Yang, Levin Kuhlmann, Gideon Kowadlo",
    "abstract": "  In continual RL, the environment of a reinforcement learning (RL) agent\nundergoes change. A successful system should appropriately balance the\nconflicting requirements of retaining agent performance on already learned\ntasks, stability, whilst learning new tasks, plasticity. The first-in-first-out\nbuffer is commonly used to enhance learning in such settings but requires\nsignificant memory. We explore the application of an augmentation to this\nbuffer which alleviates the memory constraints, and use it with a world model\nmodel-based reinforcement learning algorithm, to evaluate its effectiveness in\nfacilitating continual learning. We evaluate the effectiveness of our method in\nProcgen and Atari RL benchmarks and show that the distribution matching\naugmentation to the replay-buffer used in the context of latent world models\ncan successfully prevent catastrophic forgetting with significantly reduced\ncomputational overhead. Yet, we also find such a solution to not be entirely\ninfallible, and other failure modes such as the opposite -- lacking plasticity\nand being unable to learn a new task -- to be a potential limitation in\ncontinual learning systems.\n",
    "link": "http://arxiv.org/abs/2401.16650v1"
  },
  {
    "title": "Incoherent Probability Judgments in Large Language Models",
    "authors": "Jian-Qiao Zhu, Thomas L. Griffiths",
    "abstract": "  Autoregressive Large Language Models (LLMs) trained for next-word prediction\nhave demonstrated remarkable proficiency at producing coherent text. But are\nthey equally adept at forming coherent probability judgments? We use\nprobabilistic identities and repeated judgments to assess the coherence of\nprobability judgments made by LLMs. Our results show that the judgments\nproduced by these models are often incoherent, displaying human-like systematic\ndeviations from the rules of probability theory. Moreover, when prompted to\njudge the same event, the mean-variance relationship of probability judgments\nproduced by LLMs shows an inverted-U-shaped like that seen in humans. We\npropose that these deviations from rationality can be explained by linking\nautoregressive LLMs to implicit Bayesian inference and drawing parallels with\nthe Bayesian Sampler model of human probability judgments.\n",
    "link": "http://arxiv.org/abs/2401.16646v1"
  },
  {
    "title": "Breaking Free Transformer Models: Task-specific Context Attribution\n  Promises Improved Generalizability Without Fine-tuning Pre-trained LLMs",
    "authors": "Stepan Tytarenko, Mohammad Ruhul Amin",
    "abstract": "  Fine-tuning large pre-trained language models (LLMs) on particular datasets\nis a commonly employed strategy in Natural Language Processing (NLP)\nclassification tasks. However, this approach usually results in a loss of\nmodels generalizability. In this paper, we present a framework that allows for\nmaintaining generalizability, and enhances the performance on the downstream\ntask by utilizing task-specific context attribution. We show that a linear\ntransformation of the text representation from any transformer model using the\ntask-specific concept operator results in a projection onto the latent concept\nspace, referred to as context attribution in this paper. The specific concept\noperator is optimized during the supervised learning stage via novel loss\nfunctions. The proposed framework demonstrates that context attribution of the\ntext representation for each task objective can improve the capacity of the\ndiscriminator function and thus achieve better performance for the\nclassification task. Experimental results on three datasets, namely HateXplain,\nIMDB reviews, and Social Media Attributions, illustrate that the proposed model\nattains superior accuracy and generalizability. Specifically, for the\nnon-fine-tuned BERT on the HateXplain dataset, we observe 8% improvement in\naccuracy and 10% improvement in F1-score. Whereas for the IMDB dataset,\nfine-tuned state-of-the-art XLNet is outperformed by 1% for both accuracy and\nF1-score. Furthermore, in an out-of-domain cross-dataset test, DistilBERT\nfine-tuned on the IMDB dataset in conjunction with the proposed model improves\nthe F1-score on the HateXplain dataset by 7%. For the Social Media Attributions\ndataset of YouTube comments, we observe 5.2% increase in F1-metric. The\nproposed framework is implemented with PyTorch and provided open-source on\nGitHub.\n",
    "link": "http://arxiv.org/abs/2401.16638v1"
  },
  {
    "title": "Improving Reinforcement Learning from Human Feedback with Efficient\n  Reward Model Ensemble",
    "authors": "Shun Zhang, Zhenfang Chen, Sunli Chen, Yikang Shen, Zhiqing Sun, Chuang Gan",
    "abstract": "  Reinforcement Learning from Human Feedback (RLHF) is a widely adopted\napproach for aligning large language models with human values. However, RLHF\nrelies on a reward model that is trained with a limited amount of human\npreference data, which could lead to inaccurate predictions. As a result, RLHF\nmay produce outputs that are misaligned with human values. To mitigate this\nissue, we contribute a reward ensemble method that allows the reward model to\nmake more accurate predictions. As using an ensemble of large language\nmodel-based reward models can be computationally and resource-expensive, we\nexplore efficient ensemble methods including linear-layer ensemble and\nLoRA-based ensemble. Empirically, we run Best-of-$n$ and Proximal Policy\nOptimization with our ensembled reward models, and verify that our ensemble\nmethods help improve the alignment performance of RLHF outputs.\n",
    "link": "http://arxiv.org/abs/2401.16635v1"
  },
  {
    "title": "I came, I saw, I certified: some perspectives on the safety assurance of\n  cyber-physical systems",
    "authors": "Mithila Sivakumar, Alvine B. Belle, Kimya Khakzad Shahandashti, Oluwafemi Odu, Hadi Hemmati, Segla Kpodjedo, Song Wang, Opeyemi O. Adesina",
    "abstract": "  The execution failure of cyber-physical systems (e.g., autonomous driving\nsystems, unmanned aerial systems, and robotic systems) could result in the loss\nof life, severe injuries, large-scale environmental damage, property\ndestruction, and major economic loss. Hence, such systems usually require a\nstrong justification that they will effectively support critical requirements\n(e.g., safety, security, and reliability) for which they were designed. Thus,\nit is often mandatory to develop compelling assurance cases to support that\njustification and allow regulatory bodies to certify such systems. In such\ncontexts, detecting assurance deficits, relying on patterns to improve the\nstructure of assurance cases, improving existing assurance case notations, and\n(semi-)automating the generation of assurance cases are key to develop\ncompelling assurance cases and foster consumer acceptance. We therefore explore\nchallenges related to such assurance enablers and outline some potential\ndirections that could be explored to tackle them.\n",
    "link": "http://arxiv.org/abs/2401.16633v1"
  }
]